{
  "source": "arxiv",
  "query": "Cycle Generative Adversarial Networks",
  "fetched_at": "2025-11-21T18:06:43.853074",
  "title": "Quaternion Generative Adversarial Networks",
  "url": "http://arxiv.org/abs/2104.09630v2",
  "content": "Quaternion Generative Adversarial Networks\nEleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nAbstract LatestGenerativeAdversarialNetworks(GANs)aregatheringoutstanding\nresults through a large-scale training, thus employing models composed of millions\nof parameters requiring extensive computational capabilities. Building such huge\nmodels undermines their replicability and increases the training instability. More-\nover, multi-channel data, such as images or audio, are usually processed by real-\nvalued convolutional networks that \ufb02atten and concatenate the input, often losing\nintra-channel spatial relations. To address these issues related to complexity and\ninformation loss, we propose a family of quaternion-valued generative adversarial\nnetworks (QGANs). QGANs exploit the properties of quaternion algebra, e.g., the\nHamiltonproduct,thatallowstoprocesschannelsasasingleentityandcaptureinter-\nnallatentrelations,whilereducingbyafactorof4theoverallnumberofparameters.\nWe show how to design QGANs and to extend the proposed approach even to ad-\nvancedmodels.WecomparetheproposedQGANswithreal-valuedcounterpartson\nseveral image generation benchmarks. Results show that QGANs are able to obtain\nbetter FID scores than real-valued GANs and to generate visually pleasing images.\nFurthermore, QGANs save up to75% of the training parameters. We believe these\nresults may pave the way to novel, more accessible, GANs capable of improving\nperformance and saving computational resources.\n1 Introduction\nGenerativemodelsincludinggenerativeadversarialnetworks(GANs)[10]andvari-\national autoecoders (VAEs) [24] have been recently spectators of an increasing\nwidespread development due to the massive availability of large datasets covering\nAuthors are with the Department of Information Engineering, Electronics and Telecommuni-\ncations (DIET), Sapienza University of Rome, Via Eudossiana 18, 00184 Rome, Italy, e-mail:\n{eleonora.grassucci, danilo.comminiello}@uniroma1.it. This work has been supported by \u201cPro-\ngettidiRicercaGrandi\u201dofSapienzaUniversityofRomeundergrantnumberRG11916B88E1942F.\n1\narXiv:2104.09630v2  [cs.LG]  27 Jul 2021\n\n2 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\na large range of applications. The demand to learn such complex data distributions\nleads to de\ufb01ne models far from the original approach of a simple GAN, which was\ncharacterizedbyfullyconnectedlayersandevaluatedonbenchmarkdatasetssuchas\ntheMNIST[10].MultiplepathwayshavebeencoveredtoimproveGANsgeneration\nability. A \ufb01rst branch aims at stabilizing the training process which is notoriously\nunstable, often leading to a lack of convergence. This includes constraining the dis-\ncriminator network to be 1-Lipschitz by introducing a gradient penalty in the loss\nfunction, normalizing the spectral norm of the network weights or adding a consis-\ntency regularization [1, 16, 26, 41]. Other signi\ufb01cant improvements are gained by\narchitecturalinnovationssuchasself-attentionmodules,\ufb02exibleactivationfunctions\nor style-based generator [22, 14, 40, 21]. A crucial improvement in the quality of\nimagegenerationhasbeenbroughtbybroadlyscalingupthenetworksandinvolving\nwiderbatchsizes[2,23,34].Indeed,BigGANclosedthevisualqualitygapbetween\nGANs generated images and real-world samples in ImageNet [2]. Most of the latest\nGANs are somehow inspired to it.\nHowever,theseimpressiveresultscomeatthecostofhugemodelswithhundredof\nmillions of free parameters which require large computational resources. This dras-\nticallyreducestheaccessibilityandthedi\ufb00usionofthesekindofmodels.Moreover,\nGANsarenotoriousfragilemodels,thusthetrainingwiththisamountofparameters\nmay result in unstable or less handy process. Furthermore, when dealing with mul-\ntidimensionalinputs,suchasimages,3Daudio,multi-sensorsignalsorhuman-pose\nestimation, among others, real-valued networks break the original structure of the\ninputs. Channels are processed as independent entities and just concatenated in a\ntensor without exploiting any intra-channel correlation.\nIn order to address these limitations, neural networks in hypercomplex domains\nhavebeenproposed.Amongthem,quaternionneuralnetworks(QNNs)leveragethe\nproperties of the non-commutative quaternion algebra to de\ufb01ne lower-complexity\nmodels and preserve relations among channels. Indeed, QNNs process channels\ntogetherasasingleentity,thusmaintainingtheoriginalinputdesignandcorrelation.\nDue to this feature, QNNs are able to capture internal relations while saving up to\nthe75% offreeparametersthankstohypercomplex-valuedoperations,includingthe\nHamilton product.\nEncouragedbythepromisingresultsofothergenerativemodelsinthequaternion\ndomain [13, 12] and the need to make deep GANs more accessible, we introduce\nthe family of quaternion generative adversarial networks (QGANs). QGANs are\ncompletely de\ufb01ned in the quaternion domain and, among other properties, they\nexploit the quaternion convolutions derived from the hypercomplex algebra [28,\n29, 8, 6] to improve the generation ability of the model while reducing the overall\nnumberofparameters.A\ufb01rstattempttointroducequaternionconvolutionsinGANs\nhas been recently made in [35]. Here, we de\ufb01ne the core-blocks of the quaternion\ngenerative adversarial framework that we use to formulate a vanilla QGAN. Then,\nwe explain how to derive more advanced QGANs to prove the superior generation\nabilityoftheproposedapproachinmultipleimagegenerationbenchmarks.Weshow\nthat the quaternion spectral normalized GAN (QSNGAN) is able to earn a better\nFID and a more pleasant visual quality of the generated images with respect to its\n\nQuaternion Generative Adversarial Networks 3\nreal-valued counterpart thanks to the quaternion inner operations. Moreover, the\nproposed QSNGAN has just25% the number of free parameters with respect to the\nreal-valued SNGAN.\nWe believe that these theoretical statements and empirical results lay the founda-\ntions for novel deep GANs in hypercomplex domains capable of grasping internal\ninputrelationswhilescalingdowncomputationalrequirements,thussavingmemory\nand being more accessible. To the best of our knowledge, this is the \ufb01rst time that\na generative adversarial framework has been completely de\ufb01ned in a hypercomplex\ndomain.\nThe contribution of this chapter is threefold:\ni) weintroducethefamilyofquaterniongenerativeadversarialnetworks(QGANs)\nproving their enhanced generation ability and lower-complexity with respect to\nits real-valued counterpart on di\ufb00erent benchmark datasets/one.sup;\nii) we de\ufb01ne the theoretically correct approach to apply the quaternion batch nor-\nmalization (QBN) and rede\ufb01ne existing approaches as its approximations;\niii) we propose and de\ufb01ne the spectral normalization in the quaternion domain\n(QSN) proving its e\ufb03cacy on two image generation benchmarks.\nThe chapter is organized as follows. Section 2 presents the fundamental prop-\nerties of quaternion algebra, while Section 3 describes the quaternion adversarial\nframework and the quaternion-valued core blocks used in QGANs. Section 4 lays\nthe foundations for the quaternion generative adversarial networks and presents a\nsimple quaternion vanilla GAN and a more advanced and complex QGAN model.\nSection 5 proves the e\ufb00ectiveness of the presented QGANs on a thorough empirical\nevaluation, and, \ufb01nally, conclusions are drawn in Section 6.\n2 Quaternion Algebra\nQuaternions are hypercomplex numbers of rank4, being a direct non-commutative\nextension of complex-valued numbers. The quaternion domainH lies in a four-\ndimensional associative normed division algebra over real numbers, belonging to\ntheclassofCli\ufb00ordalgebras[38].Aquaternionisde\ufb01nedasthecompositionofone\nscalar element and three imaginary ones:\n\ud835\udc5e= \ud835\udc5e0 \u00b8\ud835\udc5e1\u02c6\ud835\udea4\u00b8\ud835\udc5e2 \u02c6\ud835\udea5\u00b8\ud835\udc5e3 \u02c6\ud835\udf05= \ud835\udc5e0 \u00b8q (1)\nwith\ud835\udc5e0\u0096 \ud835\udc5e1\u0096 \ud835\udc5e2\u0096 \ud835\udc5e3 2R andbeing \u02c6\ud835\udea4= \u00b91\u00960\u00960\u00ba\u0096 \u02c6\ud835\udea5 = \u00b90\u00961\u00960\u00ba\u0096 \u02c6\ud835\udf05= \u00b90\u00960\u00961\u00baunitaxis\nvectors representing the orthonormal basis inR3. Apure quaternionis a quaternion\nwithoutitsscalarpart \ud835\udc5e0,resultinginthevector q = \ud835\udc5e1\u02c6\ud835\udea4\u00b8\ud835\udc5e2 \u02c6\ud835\udea5\u00b8\ud835\udc5e3 \u02c6\ud835\udf05.Asforcomplex\nnumbers, also the quaternion algebra relies upon the relations among the imaginary\ncomponents:\n/one.supThe implementation of the QGANs is available online at https://github.com/eleGAN23/QGAN\n\n4 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\n\u02c6\ud835\udea42 = \u02c6\ud835\udea52 = \u02c6\ud835\udf052 = \u00001 (2)\n\u02c6\ud835\udea4\u02c6\ud835\udea5 = \u02c6\ud835\udea4\u0002\u02c6\ud835\udea5 = \u02c6\ud835\udf05; \u02c6\ud835\udea5\u02c6\ud835\udf05= \u02c6\ud835\udea5\u0002\u02c6\ud835\udf05= \u02c6\ud835\udea4; \u02c6\ud835\udf05\u02c6\ud835\udea4= \u02c6\ud835\udf05\u0002\u02c6\ud835\udea4= \u02c6\ud835\udea5 (3)\nWhile the scalar product of two quaternions\ud835\udc5e and \ud835\udc5d is simply de\ufb01ned as the\nelement-wise product\ud835\udc5e\u0001\ud835\udc5d = \ud835\udc5e0 \ud835\udc5d0 \u00b8\ud835\udc5e1 \ud835\udc5d1 \u00b8\ud835\udc5e2 \ud835\udc5d2 \u00b8\ud835\udc5e3 \ud835\udc5d3, quaternion vector multi-\nplication, denoted with\u0002, is not commutative, i.e.,\u02c6\ud835\udea4\u02c6\ud835\udea5 \u2260 \u02c6\ud835\udea5\u02c6\ud835\udea4. In fact:\n\u02c6\ud835\udea4\u02c6\ud835\udea5 = \u0000\u02c6\ud835\udea5\u02c6\ud835\udea4; \u02c6\ud835\udea5\u02c6\ud835\udf05= \u0000\u02c6\ud835\udf05\u02c6\ud835\udea5; \u02c6\ud835\udf05\u02c6\ud835\udea4= \u0000\u02c6\ud835\udea4\u02c6\ud835\udf05\u0095\nDuetothenon-commutativeproperty,weneedtointroducethequaternionprod-\nuct,commonlyknownasHamiltonproduct.WewillseethatHamiltonproductplays\na crucial role in neural networks. It is de\ufb01ned as:\n\ud835\udc5e\ud835\udc5d = \u00b9\ud835\udc5e0 \u00b8\ud835\udc5e1\u02c6\ud835\udea4\u00b8\ud835\udc5e2 \u02c6\ud835\udea5\u00b8\ud835\udc5e3 \u02c6\ud835\udf05\u00ba\u00b9\ud835\udc5d0 \u00b8\ud835\udc5d1\u02c6\ud835\udea4\u00b8\ud835\udc5d2 \u02c6\ud835\udea5\u00b8\ud835\udc5d3 \u02c6\ud835\udf05\u00ba\n= \u00b9\ud835\udc5e0 \ud835\udc5d0 \u0000\ud835\udc5e1 \ud835\udc5d1 \u0000\ud835\udc5e2 \ud835\udc5d2 \u0000\ud835\udc5e3 \ud835\udc5d3\u00ba\n\u00b8\u00b9\ud835\udc5e0 \ud835\udc5d1 \u00b8\ud835\udc5e1 \ud835\udc5d0 \u00b8\ud835\udc5e2 \ud835\udc5d3 \u0000\ud835\udc5e3 \ud835\udc5d2\u00ba\u02c6\ud835\udea4\n\u00b8\u00b9\ud835\udc5e0 \ud835\udc5d2 \u0000\ud835\udc5e1 \ud835\udc5d3 \u00b8\ud835\udc5e2 \ud835\udc5d0 \u00b8\ud835\udc5e3 \ud835\udc5d1\u00ba\u02c6\ud835\udea5\n\u00b8\u00b9\ud835\udc5e0 \ud835\udc5d3 \u00b8\ud835\udc5e1 \ud835\udc5d2 \u0000\ud835\udc5e2 \ud835\udc5d1 \u00b8\ud835\udc5e3 \ud835\udc5d0\u00ba\u02c6\ud835\udf05\u0095\n(4)\nThe above product can be rewritten in a more concise form as:\n\ud835\udc5e\ud835\udc5d = \ud835\udc5e0 \ud835\udc5d0 \u0000q \u0001p \u00b8\ud835\udc5e0p \u00b8\ud835\udc5d0q \u00b8q \u0002p\u0096 (5)\nwhere \ud835\udc5e0 \ud835\udc5d0 \u0000q \u0001p is the scalar element of the new quaternion in output and\n\ud835\udc5e0p \u00b8\ud835\udc5d0q \u00b8q \u0002p is instead the vector part of the quaternion. From (5) it is easy to\nde\ufb01ne a concise form of product for pure quaternions too:\nqp = \u0000q \u0001p \u00b8q \u0002p\u0095 (6)\nwhere the scalar product is the same as before for full quaternions and the vector\nproduct isq \u0002p = \u00b9\ud835\udc5e2 \ud835\udc5d3 \u0000\ud835\udc5e3 \ud835\udc5d2\u00ba\u02c6\ud835\udea4\u00b8\u00b9\ud835\udc5e3 \ud835\udc5d1 \u0000\ud835\udc5e1 \ud835\udc5d3\u00ba\u02c6\ud835\udea5\u00b8\u00b9\ud835\udc5e1 \ud835\udc5d2 \u0000\ud835\udc5e2 \ud835\udc5d1\u00ba\u02c6\ud835\udf05.\nSimilarly to complex numbers, the complex conjugate of a quaternion can be\nde\ufb01ned as:\n\ud835\udc5e\u0003= \ud835\udc5e0 \u0000\ud835\udc5e1\u02c6\ud835\udea4\u0000\ud835\udc5e2 \u02c6\ud835\udea5\u0000\ud835\udc5e3 \u02c6\ud835\udf05= \ud835\udc5e0 \u0000q (7)\nAlso the norm is de\ufb01ned and it is equal toj\ud835\udc5ej= p\ud835\udc5e\ud835\udc5e\u0003=\n\u221a\ufe03\n\ud835\udc5e2\n0 \u00b8\ud835\udc5e2\n1 \u00b8\ud835\udc5e2\n2 \u00b8\ud835\udc5e2\n3 that is\ntheeuclideannormin R4.Indeed, \ud835\udc5eissaidtobea unit quaternionif j\ud835\udc5ej= 1,aswell\nas apure unit quaternionif \ud835\udc5e2 = \u00001. Moreover, a quaternion\ud835\udc5eis endowed with an\ninverse determined by:\n\ud835\udc5e\u00001 = \ud835\udc5e\u0003\nj\ud835\udc5ej2 \u0095\nNote that for unit quaternions, the relation\ud835\udc5e\u0003= \ud835\udc5e\u00001 holds.\nA quaternion has also a polar form:\n\nQuaternion Generative Adversarial Networks 5\n\ud835\udc5e= j\ud835\udc5ej\u00b9cos \u00b9\ud835\udf03\u00ba\u00b8v sin \u00b9\ud835\udf03\u00ba\u00ba= j\ud835\udc5ej\ud835\udc52v\ud835\udf03 (8)\nwhere\ud835\udf03 2R istheargumentofthequaternion, cos \u00b9\ud835\udf03\u00ba= \ud835\udc5e0\u009dk\ud835\udc5ek,sin \u00b9\ud835\udf03\u00ba= k\ud835\udc5ek\u009dk\ud835\udc5ek\nandv = \ud835\udc5e\u009dk\ud835\udc5ekis a pure unit quaternion.\nFollowing,quaternionsshowinterestinglypropertieswhentheycanbeinterpreted\nas points and hyperplanes inR4. Among them, we \ufb01nd involutions, which are\ngenerally de\ufb01ned as self-inverse mappings or mappings that are their own inverse.\nQuaternions have an in\ufb01nite number of involutions [7] that can be generalized by\nthe formula:\n\ud835\udc5ev = \u0000v\ud835\udc5ev (9)\nwhere \ud835\udc5e is an arbitrary quaternion to be involved andv is any unit vector and the\naxisoftheinvolution.Amongthein\ufb01niteinvolutions,themostrelevantonesarethe\nthree perpendicular involutions de\ufb01ned as:\n\ud835\udc5e\u02c6\ud835\udea4 = \u0000\u02c6\ud835\udea4\ud835\udc5e\u02c6\ud835\udea4= \ud835\udc5e0 \u00b8\ud835\udc5e1\u02c6\ud835\udea4\u0000\ud835\udc5e2 \u02c6\ud835\udea5\u0000\ud835\udc5e3 \u02c6\ud835\udf05\n\ud835\udc5e\u02c6\ud835\udea5 = \u0000\u02c6\ud835\udea5\ud835\udc5e\u02c6\ud835\udea5 = \ud835\udc5e0 \u0000\ud835\udc5e1\u02c6\ud835\udea4\u00b8\ud835\udc5e2 \u02c6\ud835\udea5\u0000\ud835\udc5e3 \u02c6\ud835\udf05\n\ud835\udc5e\u02c6\ud835\udf05 = \u0000\u02c6\ud835\udf05\ud835\udc5e\u02c6\ud835\udf05= \ud835\udc5e0 \u0000\ud835\udc5e1\u02c6\ud835\udea4\u0000\ud835\udc5e2 \u02c6\ud835\udea5\u00b8\ud835\udc5e3 \u02c6\ud835\udf05\n(10)\nwhich are the \ufb01rst involutions identi\ufb01ed [5] and they are crucial for the study of the\nsecond-order statistics of a quaternion signal, as we will see in the next section.\n3 Generative Learning in the Quaternion Domain\nIn this section, we introduce the quaternion adversarial approach as well as the\nfundamentalquaternion-valuedoperationsemployedtode\ufb01nethefamilyofQGANs\nin next sections. It is worth noting that in a quaternion neural network each element\nis a quaternion, including inputs, weights, biases and outputs.\n3.1 The Quaternion Adversarial Framework\nGenerative adversarial networks are built upon a minimax game between the gen-\nerator network (\ud835\udc3a) and the discriminator one (\ud835\udc37), as a special case of the concept\ninitially proposed to implement arti\ufb01cial curiosity [32, 33]. They are trained in an\nadversarial fashion through the following objective function introduced in [10]:\nmin\n\ud835\udc3a\nmax\n\ud835\udc37\n\ud835\udc49\u00b9\ud835\udc37\u0096\ud835\udc3a\u00ba= E\ud835\udc65\u0018\ud835\udc5ddata\u00b9\ud835\udc65\u00baflog \ud835\udc37\u00b9\ud835\udc65\u00bag\u00b8E\ud835\udc67\u0018\ud835\udc5d\ud835\udc67 \u00b9\ud835\udc67\u00baflog\u00b91 \u0000\ud835\udc37\u00b9\ud835\udc3a\u00b9\ud835\udc67\u00ba\u00ba\u00bag (11)\n\n6 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nwhere \ud835\udc5ddata is the real data distribution and\ud835\udc5d\ud835\udc67 is the noise distribution. The two\ntermsintheobjectivearetwocross-entropies[15].Indeed,the\ufb01rsttermisthecross-\nentropy between\u00bb1 0 \u00bcT and \u00bb\ud835\udc37\u00b9\ud835\udc65\u00ba 1 \u0000\ud835\udc37\u00b9\ud835\udc65\u00ba\u00bcT, whereas the second term is the\ncross-entropy between\u00bb0 1 \u00bcT and \u00bb\ud835\udc37\u00b9\ud835\udc3a\u00b9\ud835\udc67\u00ba\u00ba 1 \u0000\ud835\udc37\u00b9\ud835\udc3a\u00b9\ud835\udc67\u00ba\u00ba\u00bcT. In order to intro-\nducethefamilyofQGANs,\ufb01rstweneedtodelineatethisadversarialapproachinthe\nhypercomplex domain. Thus, we de\ufb01ne the cross-entropy function for quaternions\nwhich has to take the four components into account, as suggested in [28] for the\nquaternion mean squared error, by replacing real numbers with hypercomplex num-\nbersandcomputingtheoperationselement-wise.Thus,thequaternioncross-entropy\n(QCE) between the target quaternion\ud835\udc5e and the estimated one\u02dc\ud835\udc5e can be de\ufb01ned as\nfollows:\nQCE\u00b9\ud835\udc5e\u0096 \u02dc\ud835\udc5e\u00ba= 1\n\ud835\udc41\n\ud835\udc41\u2211\ufe01\n\ud835\udc5b=1\n\u0002\n\ud835\udc5e0 log\u00b9\u02dc\ud835\udc5e0\u00ba\u00b8\u00b9 1 \u0000\ud835\udc5e0\u00balog\u00b91 \u0000\u02dc\ud835\udc5e0\u00ba\n\u00b8\ud835\udc5e1 log\u00b9\u02dc\ud835\udc5e1\u00ba\u00b8\u00b9 1 \u0000\ud835\udc5e1\u00balog\u00b91 \u0000\u02dc\ud835\udc5e1\u00ba\n\u00b8\ud835\udc5e2 log\u00b9\u02dc\ud835\udc5e2\u00ba\u00b8\u00b9 1 \u0000\ud835\udc5e2\u00balog\u00b91 \u0000\u02dc\ud835\udc5e2\u00ba\n\u00b8\ud835\udc5e3 log\u00b9\u02dc\ud835\udc5e3\u00ba\u00b8\u00b9 1 \u0000\ud835\udc5e3\u00balog\u00b91 \u0000\u02dc\ud835\udc5e3\u00ba\n\u0003\n\u0095\n(12)\nMore in general, several objective functions proposed to train GANs can be\nrede\ufb01ned in the quaternion domain. Among the most common ones, we \ufb01nd the\nWasserstein distance with a gradient penalty that enforces the Lipschitz continuity\nof the discriminator, which is de\ufb01ned as follows [1, 16]:\n\ud835\udc49\u00b9\ud835\udc37\u0096\ud835\udc3a\u00ba= E\ud835\udc65\u0018\ud835\udc5ddata f\ud835\udc37\u00b9\ud835\udc65\u00bag\u0000E\ud835\udc67\u0018\ud835\udc5d\u00b9\ud835\udc67\u00baf\ud835\udc37\u00b9\ud835\udc3a\u00b9\ud835\udc67\u00ba\u00bag\u0000\ud835\udf06E\u02c6\ud835\udc65\u0018\ud835\udc5d\u02c6\ud835\udc65\n\b\n\u00b9jjr\u02c6\ud835\udc65\ud835\udc37\u00b9\u02c6\ud835\udc65\u00bajj2 \u00001\u00ba2\t\n(13)\nwhere the last term is the gradient penalty that is a regularization technique for the\ndiscriminator.\nOther works [26, 3] consider instead the hinge loss, which is given, respectively\nfor the discriminator and the generator, by:\n\ud835\udc49\u00b9\ud835\udc37\u0096 \u02c6\ud835\udc3a\u00ba= E\ud835\udc65\u0018\ud835\udc5ddata\u00b9\ud835\udc65\u00bafmin\u00b90\u0096 \u00001 \u00b8\ud835\udc37\u00b9\ud835\udc65\u00ba\u00bag\u00b8E\ud835\udc67\u0018\ud835\udc5d\ud835\udc67 \u00b9\ud835\udc67\u00bafmin\u00b90\u0096 \u00001 \u0000\ud835\udc37\u00b9\ud835\udc3a\u00b9\ud835\udc67\u00ba\u00ba\u00bag\u0096\n(14)\n\ud835\udc49\u00b9\u02c6\ud835\udc37\u0096\ud835\udc3a\u00ba= \u0000E\ud835\udc67\u0018\ud835\udc5d\ud835\udc67 \u00b9\ud835\udc67\u00ba\n\b \u02c6\ud835\udc37\u00b9\ud835\udc3a\u00b9\ud835\udc67\u00ba\u00ba\u00ba\n\t\n\u0095 (15)\nBeing(13)and(14)thecompositionofexpectedvaluesandcross-entropies,both\nthede\ufb01nitionsoftheWassersteinlossandofthehingelossinthequaterniondomain\nare straightforwardly derived by following the procedure shown for the adversarial\nloss in (11).\n\nQuaternion Generative Adversarial Networks 7\n3.2 Quaternion Fully Connected Layers\nIn real-valued neural networks, fully connected layers are generally de\ufb01ned as:\nyr = \ud835\udf19\u00b9Wrxr \u00b8br\u00ba (16)\nwhereWrxr performsthemultiplicationbetweentheweightmatrix Wr andtheinput\nxr, br is the bias and\ud835\udf19\u00b9\u0001\u00bais any activation function. In order to de\ufb01ne the same\noperation in the quaternion domain, we represent the quaternion weight matrix as\nW = W0 \u00b8W1\u02c6\ud835\udea4\u00b8W2 \u02c6\ud835\udea5\u00b8W3 \u02c6\ud835\udf05, the quaternion input asx = x0 \u00b8x1\u02c6\ud835\udea4\u00b8x2 \u02c6\ud835\udea5\u00b8x3 \u02c6\ud835\udf05and\nthequaternionbiasas b = b0 \u00b8b1\u02c6\ud835\udea4\u00b8b2 \u02c6\ud835\udea5\u00b8b3 \u02c6\ud835\udf05.Therefore, Wx in(16),isperformed\nby a vector multiplication between two quaternions, i.e., by the Hamilton product\nW \nx:\nW \nx = \u00b9W0x0 \u0000W1x1 \u0000W2x2 \u0000W3x3\u00ba\n\u00b8\u00b9W1x0 \u00b8W0x1 \u0000W3x2 \u00b8W2x3\u00ba\u02c6\ud835\udea4\n\u00b8\u00b9W2x0 \u00b8W3x1 \u00b8W0x2 \u0000W1x3\u00ba\u02c6\ud835\udea5\n\u00b8\u00b9W3x0 \u0000W2x1 \u00b8W1x2 \u00b8W0x3\u00ba\u02c6\ud835\udf05\u0095\n(17)\nNote thatW has dimensionality1\n4 jWrjsince it is composed of four submatrices\nW0\u0096W1\u0096W2 andW3 eachonewith 1\u009d16 thedimensionof Wr.Thisisakeyfeature\nof QNNs since the results of the quaternion layer with productW \nx has the\nsame output dimension of the real-valued layer built uponWrxr but with1\u009d4 the\nnumber of parameters to train. Note also that the submatrices are shared over each\ncomponentofthequaternioninput.Thesharingallowstheweightstocaptureinternal\nrelations among quaternion elements since each charcteristic in a component will\nhaveanin\ufb02uenceintheothercomponentsthroughthecommonweights.Inthisway\nthe relations among components are preserved and captured by the weights of the\nnetwork which is able to process inputs without losing intra-channel information.\nThebias b isthenaddedwithasumcomponentbycomponent.Finally,inQNNsthe\nactivation functions are applied to the input element-wise resulting in the so called\nsplit activation functions. That is, suppose to consider a common Recti\ufb01ed Linear\nUnit (ReLU) activation functionand the quaternionz = W \nx \u00b8b, the \ufb01nal resulty\nof the layer will be:\ny = ReLU\u00b9z0\u00ba\u00b8ReLU\u00b9z1\u00ba\u02c6\ud835\udea4\u00b8ReLU\u00b9z2\u00ba\u02c6\ud835\udea5\u00b8ReLU\u00b9z3\u00ba\u02c6\ud835\udf05\u0095 (18)\n3.3 Quaternion Convolutional Layers\nConvolutional layers are generally applied to multichannel inputs, such as images.\nSupposing to deal with color images, real-valued neural networks break the struc-\nture of the input and concatenates the red, green and blue (RGB) channels in a\n\n8 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\ntensor. Quaternion-valued convolutions, instead, preserve the correlations among\nthe channels and encapsulates the image in a quaternion as [28, 27, 39]:\nx = 0 \u00b8\ud835\udc45\u02c6\ud835\udea4\u00b8\ud835\udc3a\u02c6\ud835\udea5\u00b8\ud835\udc35\u02c6\ud835\udf05 (19)\nThe image channels are the real coe\ufb03cients of the imaginary units while the scalar\npart is set to0. Encapsulating channels in a quaternion allows to treat them as a\nsingle entity and thus to preserve intra-channels relations. A visual explanation of\nthe quaternion representation of color images is depicted in Fig. 1.\nOriginal image\nReal-valued image\nQuaternion-valued image\nReal-valued \nCNN \nQuaternion-valued \nQCNN \nFig. 1 Visualexplanationofan \ud835\udc45\u0096\ud835\udc3a\u0096\ud835\udc35 imageprocessedbyrealandquaternion-valuednetworks.\nOn the left, the original three-channels image. The image can be processed in two ways: i) As a\ntensor of independent channels by a standard real-valued convolutional network as on the top of\nthe \ufb01gure. ii) As a single entity, encapsulating it in a quaternion, and considering internal relations\namong channels as quaternion-valued convolutional network does in the bottom of the \ufb01gure. It is\nworthnotinghowthereal-valuednetworkdoesnotconsideranycorrelationamongchannelswhile\nquaternion ones preserve the relations among channels.\nSimilarly to the de\ufb01nition of fully connected layers in the previous section, let us\nconsider now a real-valued convolutional layer delineated by:\ny = \ud835\udf19\u00b9Wr \u0003xr \u00b8br\u00ba (20)\nwhere \u0003is the convolution operator. Quaternion convolutional layers are built with\nthe same procedure depicted for fully connected layers thus considering the Hamil-\n\nQuaternion Generative Adversarial Networks 9\nton product instead of the standard vector multiplication. That is, the convolution\noperatorWr \u0003xr is replaced for quaternion weights and inputs with\nW \u0003x = \u00b9W0 \u0003x0 \u0000W1 \u0003x1 \u0000W2 \u0003x2 \u0000W3 \u0003x3\u00ba\n\u00b8\u00b9W1 \u0003x0 \u00b8W0 \u0003x1 \u0000W3 \u0003x2 \u00b8W2 \u0003x3\u00ba\u02c6\ud835\udea4\n\u00b8\u00b9W2 \u0003x0 \u00b8W3 \u0003x1 \u00b8W0 \u0003x2 \u0000W1 \u0003x3\u00ba\u02c6\ud835\udea5\n\u00b8\u00b9W3 \u0003x0 \u0000W2 \u0003x1 \u00b8W1 \u0003x2 \u00b8W0 \u0003x3\u00ba\u02c6\ud835\udf05\u0095\n(21)\nA visual explanation of the operation is shown in \ufb01g.2. While real-valued convolu-\ntional layer has to learn each \ufb01lter independently, quaternion convolution allow the\nsharing of \ufb01lters, thus reducing the number of free parameters to train.\nNote that in convolutional networks the sharing weights are crucial to properly\nprocess channels. Indeed, the RGB channels of an image interact with each other\nby resulting in combined colors, such as yellow or violet, through a representation\nof pixels in the color space. Nonetheless, real-valued networks are not able to catch\nthese interactions since they process input channels separately, while QCNNs not\nonly preserves the input design but also capture these relations through the sharing\nof weights. Actually, QCNNs perform a double learning: the convolution operator\nhas the task of learning external relations among the pixels of the image, while the\nHamilton product accomplishes the learning among the channels. Furthermore, as\nfor linear layers, QCNNs are built with1\u009d4 the number of parameters with respect\nto their real-valued counterpart.\n3.4 Quaternion Pooling Layers\nMany neural networks make use of pooling layers, such as max pooling or average\npooling, to extract high-level information and reduce input dimensions. As done\nbefore for previous layers in the quaternion domain, also this set of operations can\nbe rede\ufb01ned in the quaternion domain.\nThe simplest examples of pooling in the hypercomplex domain are average and\nsum poolings. Indeed, applying these operations to each quaternion component,\nas done for split activation function, will not a\ufb00ect the \ufb01nal result [39]. A di\ufb00erent\napproachmustbede\ufb01ned,instead,formaxpooling.Indeed,themaximumofasingle\ncomponent is not guaranteed by the maximum of all the other components. In order\nto address this issue, a guidance matrix has to be introduced. As in [39], the matrix\nis built through the quaternion amplitude and keeps trace of the maximum position,\nwhichisthenmappedbacktotheoriginalquaternionmatrixinordertoproceedwith\nthe pooling computation. However, max pooling operations are rarely employed in\nGANs, thus we only make use of average and sum pooling in our experiments.\n\n10 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\noutput channels = 8\ninput channels = 4\nReal-valued filters Quaternion-valued filters \nQuaternion \nparameters to learn: \nHamilton rule\nReal-valued  \nparameters to learn:\nthat is, each filter\nindependently\nHamilton rule\nFig. 2 Real and quaternion convolution \ufb01lters for a layer\ud835\udc59with4 channels in input and8 channels\nin output. On the left, the real-valued network has to learn each \ufb01lter independently, thus resulting\nin4 \u00028 = 32 \ufb01lterstolearn.Ontheright,thequaternion\ufb01ltersareadjustedfollowingtheHamilton\nproduct rule in (21) and shared among the4 input components. As a result, the dimension of the\nweightmatrix W isthesameas Wr,butthequaternion\ufb01lterstolearnarejust 4 \u00022 = 8,thatis,the\n25% of the real-valued \ufb01lters. The so-composed \ufb01lters are then employed to perform convolution.\n3.5 Quaternion Batch Normalization\nIntroduced in [20], batch normalization (BN) has immediately became an ever-\npresent module in neural networks. The idea behind BN is to normalize inputs\nto have zero mean and unit variance. This normalization helps the generalization\nability of the network among di\ufb00erent batches of training data and between train\nandtestdatadistribution.Moreover,reducingtheinternalcovariateshiftremarkably\nimproves the training speed, thus leading to a faster convergence of the model.\n\nQuaternion Generative Adversarial Networks 11\nFor these reasons, also QNNs are endowed with batch normalization. However,\ndi\ufb00erent versions of this method were proposed in literature. An elegant whitening\nprocedurebasedonthestandardcovarincematrixisintroducedin[8].Inthatpaper,\nthe Cholesky decomposition is used to compute the square root of the inverse of\nthe covariance matrix, which is often intractable. The authors asserts that approach\nensures zero mean, unit variance and decorrelation among components. However,\nthe covariance matrix is not able to recover the complete second-order statistics in\nthequaterniondomain[4]andthedecompositionrequiresheavymatrixcalculations\nand computational time [19]. Another remarkable approach is introduced in [36],\nwhere the input is standardized computing the average of the variance of each\ncomponent. Nevertheless, describing the second-order statistics of a signal in the\nquaternion domain needs meticulous computations and the approach in [36] is an\napproximation of the complete variance. Notwithstanding the approximation, this\nmethod allows to notably reduce computational time.\nThe proper theoretically procedure to reach a centered, decorrelated and unit-\nvariance quaternion signal would be represented by performing a whitening proce-\ndure. Ideally, we should consider the covariance matrix and then decompose it to\nwhiten the input in order to avoid computing the square root of the inverse which is\noftenunfeasible.However,duetotheinteractionsamongcomponents,second-order\nstatistics for quaternion random variables are not completely described by the stan-\ndardcovariancematrix[4].Forthisreason,theaugmentedcovariancematrixshould\nbeconsideredinstead.Suchmatrixisaugmentedwiththecomplementarycovariance\nmatrices Cqq\ud835\udc56 \u0096 Cqq\ud835\udc57 \u0096 Cqq\ud835\udc58 that are the covariance matrices of the quaternion with\nits three perpendicular involutionsq\ud835\udc56\u0096q\ud835\udc57\u0096q\ud835\udc58. Thus, the augmented covariance ma-\ntrix,whichcompletelycharacterizesthesecond-orderinformationoftheaugmented\nquaternion vector\u02dcq, is de\ufb01ned as:\n\u02dcCqq = E\n\b\u02dcq\u02dcqH\t\n=\n266666664\nCqq Cqq\u02c6\ud835\udea4 Cqq\u02c6\ud835\udea5 Cqq \u02c6\ud835\udf05\nCH\nqq\u02c6\ud835\udea4 Cq\u02c6\ud835\udea4q\u02c6\ud835\udea4 Cq\u02c6\ud835\udea4q\u02c6\ud835\udea5 Cq\u02c6\ud835\udea4q \u02c6\ud835\udf05\nCH\nqq\u02c6\ud835\udea5 Cq\u02c6\ud835\udea5q\u02c6\ud835\udea4 Cq\u02c6\ud835\udea5q\u02c6\ud835\udea5 Cq\u02c6\ud835\udea5q \u02c6\ud835\udf05\nCH\nqq \u02c6\ud835\udf05 Cq \u02c6\ud835\udf05 q\u02c6\ud835\udea4 Cq \u02c6\ud835\udf05 q\u02c6\ud835\udea5 Cq \u02c6\ud835\udf05 q \u02c6\ud835\udf05\n377777775\n(22)\nwhere \u00b9\u0001\u00baH is the conjugate transpose operator. The formulation in (22) recovers the\ncompletestatisticalinformationofageneralquaternionsignal.Thus,thetheoretically\nprocedure should be delineated as:\nx = \u02dcC\u00001\u009d2\nqq \u00b9x \u0000Efxg\u00ba (23)\norsubstitutingtheinversesquareroot \u02dcC\u00001\u009d2\nqq withadecompositionofit.However,the\nconstruction of the augmented covariance matrix may be quite di\ufb03cult and compu-\ntationalexpensiveduetothecomputationofeachsub-covariancematrix.Moreover,\n\u02dcC\u00001\u009d2\nqq includes skew-symmetric sub-matrices [4], which make the decomposition\nmore di\ufb03cult.\nInordertosimplifythecalculationof (22)andmakeitmorefeasibleforpractical\napplications, a particular case can be considered by leveraging theQ-properness\n\n12 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nproperty[37,4,13].The Q-propernessentailsthatthequaternionsignalisnotcorre-\nlated with its involutions, implying vanishing complementary covariance matrices,\ni.e., Cqq\ud835\udc56 = Cqq\ud835\udc57 = Cqq\ud835\udc58 = 0. Also, forQ-proper random variables the following\nrelation holds:\nvar fq\ud835\udc50g= E\n\b\nq2\n\ud835\udc50\n\t\n= \ud835\udf0e2\u0096 \ud835\udc50 = f0\u00961\u00962\u00963g (24)\nThus, considering aQ-proper quaternion, the covariance in (22) becomes:\n\u02dcCqq = E\n\b\u02dcq\u02dcqH\t\n=\n26666664\nCqq 0 0 0\n0 C q\u02c6\ud835\udea4q\u02c6\ud835\udea4 0 0\n0 0 C q\u02c6\ud835\udea5q\u02c6\ud835\udea5 0\n0 0 0 C q \u02c6\ud835\udf05 q \u02c6\ud835\udf05\n37777775\n= 4\ud835\udf0e2I (25)\nAssuming Q-properness for a random variable saves a lot of calculations and\ncomputationalcosts.Notwithstandingthetheoreticalcorrectnessoftheabovede\ufb01ned\napproach, quaternion batch normalization (QBN) techniques adopted so far in the\nliterature relies in some approximations.\nWe assume the input signal isQ-proper, thus we consider the covariance in (25)\nand build the normalization as follows:\nx = x \u0000\ud835\udf07\ud835\udc5e\n\u221a\ufe01\nvar fxg\u00b8\ud835\udf16\n= x \u0000\ud835\udf07\ud835\udc5e\np\n4\ud835\udf0e2 \u00b8\ud835\udf16\n(26)\nwhere \ud835\udf07\ud835\udc5e is the quaternion input mean value, which is a quaternion itself, and it is\nde\ufb01ned as:\n\ud835\udf07\ud835\udc5e = 1\n\ud835\udc41\n\ud835\udc41\u2211\ufe01\n\ud835\udc5b=1\n\ud835\udc5e0\u0096\ud835\udc5b \u00b8\ud835\udc5e1\u0096\ud835\udc5b\u02c6\ud835\udea4\u00b8\ud835\udc5e2\u0096\ud835\udc5b \u02c6\ud835\udea5\u00b8\ud835\udc5e3\u0096\ud835\udc5b\u02c6\ud835\udf05= \u00af\ud835\udc5e0 \u00b8\u00af\ud835\udc5e1\u02c6\ud835\udea4\u00b8\u00af\ud835\udc5e2 \u02c6\ud835\udea5\u00b8\u00af\ud835\udc5e3 \u02c6\ud835\udf05\u0095 (27)\nThe \ufb01nal output is computed as follows:\nQBN\u00b9x\u00ba= \ud835\udefex \u00b8\ud835\udefd (28)\nwhere \ud835\udefdis a shifting quaternion parameter and\ud835\udefeis a scalar parameter.\nInconclusion,theQBNproposedby[8]isanelegantapproximation,nevertheless\nitisnotabletocatchthecompletesecond-orderstatisticsinformation,whilerequiring\nheavycomputations[19].Thus,webelievethatconsidering Q-propersignals,which\nare indeed very frequent, is a good approximation which also extremely reduces the\ncomputationalrequirements.Forourexperiments,weadoptthemethodrepresented\nby (28).\n3.6 Quaternion Spectral Normalization\nAmong the wide variety of proposed techniques to stabilize GANs traning, the\nspectral normalization (SN) [26] is one of the most widespread method. Previously,\n\nQuaternion Generative Adversarial Networks 13\nthe crucial importance of having a Lipschitz-bounded discriminator function was\nintroduced in [1, 16]. Lately, it was proved that no restriction on the discriminator\nspace leads to thegradient uninformativenessproblem [42]. This means that the\ngradient of the optimal discriminative function has no information about the real\ndistribution, thus providing useless feedbacks to the generator. Forcing a function\nto be Lipschitz continuous means controlling how fast it increases and bound the\ngradients, thus mitigating gradient explosions [42, 11]. In [1], a method based on\nweight clipping was proposed to force the discriminator to be 1-Lipschitz. Later,\nsuchapproachhasbeenimprovedbyaddingagradientpenalty(GP)thatconstraints\nthe gradient norm to be at most 1 [16]. The latter method is reproposed in several\nstate-of-the-artGANsandcombinedwithotherregularizationtechniquestoimprove\nperformance, as suggest [25]. However, being built on the gradients with respect to\nthe inputs, the gradient penalty cannot impose a regularization outside the support\nofthefakeand realdatadistribution.Moreover,itrequires consistentcomputations.\nThe spectral normalization, instead, directly operates on the weights of the network\nbeingfreeofthesupportlimitanditscomputationsisfasterthanothermethods[26].\nIt aims at controlling the Lipschitz constant of the discriminator by constraining the\nspectral norm of each layer.\nA generic function\ud835\udc53 is \ud835\udc3e-Lipschitz continuous if, for any two points\ud835\udc651, \ud835\udc652, the\nfollowing property holds:\nk\ud835\udc53 \u00b9\ud835\udc651\u00ba\u0000\ud835\udc53 \u00b9\ud835\udc652\u00bak\nj\ud835\udc651 \u0000\ud835\udc652j \u0014\ud835\udc3e (29)\nbeing k\u0001kthe \ud835\udc592 norm. The Lipschitz norm k\ud835\udc53kLip of a function \ud835\udc53 is equal to\nsup\ud835\udc65\ud835\udf0e\u00b9r\ud835\udc53\u00b9\ud835\udc65\u00ba\u00ba, where\ud835\udf0e\u00b9\u0001\u00bais the spectral norm of the matrix in input, that is, the\nlargest singular value of the matrix.\nFor a generic linear layer\ud835\udc53\u00b9\u210e\u00ba= Wx \u00b8b, the Lipschitz norm is:\nk\ud835\udc53kLip = sup\n\u210e\n\ud835\udf0e\u00b9r\ud835\udc53\u00b9\u210e\u00ba\u00ba= sup\n\u210e\n\ud835\udf0e\u00b9W\u00ba= \ud835\udf0e\u00b9W\u00ba (30)\nAssuming the Lipschitz norm of each layer activation being equal to 1, constraint\nthat is satis\ufb01ed for many popular activation functions including ReLU and Leaky\nReLU [26], we can apply the Lipschitz bound to the whole network by following\nk\ud835\udc531 \u000e\ud835\udc532 kLip \u0014k\ud835\udc531 kLip \u0001k\ud835\udc532 kLip.\nFinally, the SN is de\ufb01ned as\n\u00af\ud835\udc4a\ud835\udc46\ud835\udc41 \u00b9W\u00ba= W\n\ud835\udf0e\u00b9W\u00ba (31)\nanditensuresthattheweightmatrix W alwayssatis\ufb01estheconstraint \ud835\udf0e\u00b9W\u00ba= 1.In\n[26] the authors underline that applying the original singular value decomposition\nalgorithmtocompute \ud835\udf0e\u00b9W\u00bamayresultinanextremelyheavyalgorithm.Toaddress\nthecomputationalcomplexity,theysuggesttoestimatethelargestsingularvaluevia\nthe power iteration method.\nIn order to control the Lipschitz constraint in a QGAN, in this section we\nexplore two methods to de\ufb01ne the spectral normalization in the quaternion do-\n\n14 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nmain. A \ufb01rst approach aims at normalizing the weightsW by operating on each\nsubmatrix W0\u0096 W1\u0096 W2\u0096 W3 independently, by computing the spectral norm\nseparately. That is, through the power iteration method as above, we compute\n\ud835\udf0e0 \u00b9W0\u00ba\u0096 \ud835\udf0e1 \u00b9W1\u00ba\u0096 \ud835\udf0e2 \u00b9W2\u00ba\u0096 \ud835\udf0e3 \u00b9W3\u00baand then normalize each submatrix with\nthe corresponding norm. This method forces each submatrix to have spectral norm\nequal to 1. However, it never takes the whole weight matrixW into account. More-\nover,therelationsamongthecomponentsofthequaternionmatrixisnotconsidered,\nlosing the characteristic property of QNNs.\nThesecondmethod,similarlytothereal-valuedSN,normalizesthewholematrix\nW together,byimposingtheconstrainttothecompletematrixandnottothesingular\nsubmatrices.Therefore,thespectralnormiscomputedbytakingthecompleteweight\nmatrixintoaccountandconsideringtherelationsamongthequaternioncomponents.\nHowever, while the spectral norm is computed as in (30), the normalization step is\napplied di\ufb00erently from the SN in (31). Instead of normalizing the whole matrix as\nin (31), being the weight matrixW designed by a composition of the submatrices\nW0\u0096 W1\u0096 W2\u0096 W3, we can leverage this quaternion setup to save computational\ncosts and normalize each submatrixW0\u0096 W1\u0096 W2\u0096 W3. The normalized subma-\ntrices \u00afW0\u0096\ud835\udc44\ud835\udc46\ud835\udc41 \u0096 \u00afW1\u0096\ud835\udc44\ud835\udc46\ud835\udc41 \u0096 \u00afW2\u0096\ud835\udc44\ud835\udc46\ud835\udc41 \u0096 \u00afW3\u0096\ud835\udc44\ud835\udc46\ud835\udc41 will result in a normalized weight\nmatrix \u00af\ud835\udc4a\ud835\udc44\ud835\udc46\ud835\udc41 \u00b9W\u00bawithamoree\ufb03cientcomputationthannormalizingthefullmatrix\nW.\nAn empirical comparison between the two methods is reported in Section 5. We\ninvestigate the two techniques in a plain QGAN and prove that the latter approach\nis stabler and gains better performance in both the datasets considered. We deem\nit more appropriate both theoretically and empirically and we use it in our further\nexperiments. From now on, we refer to such approach as the quaternion spectral\nnormalization (QSN).\n3.7 Quaternion Weight Initialization\nWeight initialization has often a crucial role in networks convergence and in the\nreduction of the risk of vanishing or exploding gradients [9]. This procedure be-\ncomes even more important when dealing with quaternion weights. Indeed, due to\nthe interactions among the elements of the quaternion, the initialization cannot be\nrandomnorcomponent-aware.Forthesereasons,anappropriateinitializationhasto\nbe introduced.\nFirst,consideraweightmatrix W withE fjWjg= 0.Theinitializationisbasedon\nanormalizedpurequaternion \ud835\udc62generatedforeachweightsubmatrixfromauniform\ndistribution in \u00bb0\u00961\u00bc. By using the polar form of a quaternion, we can de\ufb01ne the\ninitialization of the weight matrix as\nW = jWj\ud835\udc52\ud835\udc62\ud835\udf03 = jWj\u00b9cos\u00b9\ud835\udf03\u00ba\u00b8\ud835\udc62sin\u00b9\ud835\udf03\u00ba\u00ba (32)\nwhere each matrix component is initialized as\n\nQuaternion Generative Adversarial Networks 15\nW0 = \ud835\udf19cos\u00b9\ud835\udf03\u00ba\nW1 = \ud835\udf19\ud835\udc621 sin\u00b9\ud835\udf03\u00ba\nW2 = \ud835\udf19\ud835\udc622 sin\u00b9\ud835\udf03\u00ba\nW3 = \ud835\udf19\ud835\udc623 sin\u00b9\ud835\udf03\u00ba\n(33)\nwhere the angle\ud835\udf03 is randomly generated in the interval\u00bb\u0000\ud835\udf0b\u0096\ud835\udf0b\u00bcand \ud835\udf19is randomly\nsampledintheintervalofthestandarddeviationaroundzero \u00bb\u0000\ud835\udf0e\u0096\ud835\udf0e\u00bc.Thestandard\ndeviation is set according to the initialization method chosen, either [9] or [17]. In\nthe\ufb01rstcase,weset \ud835\udf0e= 1\u009d\n\u221a\ufe01\n2\u00b9\ud835\udc5b\ud835\udc56\ud835\udc5b \u00b8\ud835\udc5b\ud835\udc5c\ud835\udc62\ud835\udc61\u00bawhereasinthelatterweset \ud835\udf0e= 1\u009dp2\ud835\udc5b\ud835\udc56\ud835\udc5b.\nIn both the equations,\ud835\udc5b\ud835\udc56\ud835\udc5b is the number of neurons in the input layer and\ud835\udc5b\ud835\udc5c\ud835\udc62\ud835\udc61 the\nnumber of neurons in the output layer. The variance ofW can be written as:\nvar fWg= E\n\b\njWj2\t\n\u0000EfjWjg2 \u0095 (34)\nHowever, similarly to the QBN in the previous section, in order to reduce the\ncomputations,thecomponentE fjWjg2 canbeconsideredequalto 0 [29,28].Thisis\nequivalenttoconsideringa Q-properquaternionsignalwhoseaugmentedcovariance\nmatrix has o\ufb00-diagonal elements equal to0 and trace equal to4\ud835\udf0e2. Consequently,\nthe variance is computed by considering only the \ufb01rst term of (34) as:\nvar fWg= E\n\b\njWj2\t\n= 4\ud835\udf0e2 (35)\n3.8 Training\nTheforwardphaseofaQNNisthesameasitsreal-valuedcounterpart.Therefore,the\ninput\ufb02owsfromthe\ufb01rsttothelastlayerofthenetwork.Itmaybeinterestingtonote\nthat in eq. (17) the order of the weight and the input can be inverted, thus changing\nthe output of the product, resulting in an inverted QNN [28, 29]. For what concerns\nthe backward phase, it worth mentioning that the gradient of a general quaternion\nlossfunction Liscomputedforeachcomponentofthequaternionweightmatrix W\nas in the ensuing equation:\n\ud835\udeffL\n\ud835\udeffW = \ud835\udeffL\n\ud835\udeffW0\n\u00b8 \ud835\udeffL\n\ud835\udeffW1\n\u02c6\ud835\udea4\u00b8 \ud835\udeffL\n\ud835\udeffW2\n\u02c6\ud835\udea5\u00b8 \ud835\udeffL\n\ud835\udeffW3\n\u02c6\ud835\udf05\u0095 (36)\nThen,thegradientispropagatedbackfollowingthechainrule.Indeed,asde\ufb01ned\nin[28],thebackpropagationofquaternionneuralnetworksisjustanextensionofthe\nmethod for their real-valued counterpart. Consequently, QNNs can be easily trained\nas real-valued networks via backpropagation.\n\n16 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\n4 GAN Architectures in the Quaternion Domain\nThe previous section described the main blocks and the framework to build and\ntrain a GAN in the quaternion domain. In this section we go further, presenting the\ncomplete de\ufb01nition of a plain QGAN in Subsection 4.1 and of an advanced state-\nof-the-art QGAN composed of complex blocks in Subsection 4.2. First, in order\nto setting up a QGAN, each input, weight, bias and output has to be manipulated\nto become a quaternion. Therefore, weight matrices are initialized as composed\nby the four submatrices, similarly to (17) and (21). Real-valued operations such as\nmultiplications or convolutions in the networks are replaced with their quaternion\ncounterparts, completing the rede\ufb01nition of the layers in the quaternion domain.\nThe input is handled as a quaternion and processed as a single entity. For images, a\npure quaternion is considered as in (19), while for other kind of multidimensional\nsignals, the scalar part is considered too. The initialization of the weights is then\nappliedfollowingthedescriptioninSection3.7.Thisaccuratede\ufb01nitionofQGANs\ngrants to design a model with a fewer number of free parameters with respect to\nthe same real-valued model and consequently to save memory and computational\nrequirements.\n4.1 Vanilla QGAN\nIn the original GAN [10], both the generator (\ud835\udc3a) and the discriminator (\ud835\udc37) are\nde\ufb01ned by fully connected layers. Due to the limited expressivity of this design\nwith complex data such as images, in [30] the authors propose to replace dense\nlayers with more suitable operations for this kind of data and to build\ud835\udc3a and \ud835\udc37 by\nstacking several convolutional layers. State-of-the-art GANs are based on the deep\nconvolutional GAN (DCGAN) [30]. In particular, the DCGAN increases the spatial\ndimensionalitybymeansoftransposedconvolutionsinthegeneratoranddecreasesit\nin the discriminator with convolutions. Furthermore, this architecture de\ufb01nes batch\nnormalizationineverylayerexceptforthelastlayerof \ud835\udc3aandforthe\ufb01rstlayerof \ud835\udc37,\nin order to let the networks learn the correct statistics of the data distribution.\nBy rede\ufb01ning the DCGAN in the quaternion domain (QDCGAN) it is possible\nto explore the potential of the quaternion algebra in a simple GAN framework. The\nQDCGAN generator is de\ufb01ned by an initial quaternion fully connected layer and\nthen by interleaving quaternion transposed convolutions with quaternion batch nor-\nmalizationandsplitReLUactivationfunctionsexceptforthelastlayerwhichendsup\nwithasplitTanhfunction.Thediscriminatorhasthesamestructureofthegenerator\nbutwithquaterniontransposedconvolutionsreplacedbyquaternionconvolutionsto\ndecrease the dimensionality and with a \ufb01nal fully connected quaternion layer that\nreturns as output the real/fake decision by means of a sigmoid split activation. The\nQDCGAN, as its real-valued counterpart, optimizes the original loss in (11).\n\nQuaternion Generative Adversarial Networks 17\nQTranConv \nQBN\nsplit ReLU\nQTranConv \nsplit Tanh\nQuaternion Generator\nQuaternion Discriminator\nQFC layerQFC layer\nsplit Sigm\nQNoise Input\nFake\nTrue\nQTranConv \nQBN\nsplit ReLU\nQTranConv \nQBN\nsplit ReLU\nsplit LReLU\nQBN\nQConv\nsplit LReLU\nQConv\nsplit LReLU\nQBN\nQConv\nsplit LReLU\nQBN\nQConv\nFig. 3 QuaternionVanillaGANarchitecture.Eachparameterincludinginputs,weightsandoutputs\nisaquaternion.Thegenerator(greennetwork)takesaquaternionnoisesignalandgeneratesabatch\nof quaternion images with four channels. The discriminator tries to distinguish between fake and\nreal quaternion samples exploiting the properties of quaternion algebra.\n4.2 Advanced QGAN\nTheabovepresentedVanillaQGANisjustaplainexampletogiveageneralideaon\nhow to build GANs in the quaternion domain. In this section, we consider a more\nadvanced model, the spectral normalized GAN (SNGAN) [26] and we present the\nsteps to de\ufb01ne its quaternion counterpart.\nThequaternionspectralnormalizedGAN(QSNGAN)istrainedinanadversarial\nfashion through the hinge loss de\ufb01ned in (14) and (15) for the discriminator and\ngenerator respectively, as suggested in [26, 3]. The overall architecture of the model\nis inspired by [3]. Both the generator and discriminator networks are characterized\nbyquaternionconvolutionallayersinordertoleveragethepropertiesoftheHamilton\nproduct. To mitigate the vanishing gradient problem and obtain better performance,\na series of residual blocks with upsampling in the generator and downsampling in\nthedisciminatorcanbeadopted[26].Aschemeoftheresidualblockoftheproposed\nQSNGAN is depicted in Fig. 4. The discriminative network plays a crucial role in\nGANs training, thus it is more complex with respect to the generator network. It\ntakesininputthetwosetsofquaternionimageswithfourchannelsina\ufb01rstresidual\nblock,asillustratedinFig.5.Theoutputoftheblockisthedecisiononwhetherthey\ncome from the fake or real distribution.\nIn order to guarantee a fair comparison with the SNGAN, we consider a real-\nvalued noise signal in input to the generator and handle it with an initial real-valued\nfullyconnectedlayer.Theoutputofthe\ufb01rstlayeristhenencapsulatedinaquaternion\n\n18 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nQBN\nQBN\nsplit ReLU\nQConv\nsplit ReLU\nQConv\nQConv\nUpsampling\nAvgPool\nUpsampling AvgPool\nFig. 4 Quaternion residual block (QResBlock) architecture inspired by [26] and rede\ufb01ned in the\nquaterniondomain.QBNisomittedinthediscriminatornetworkandreplacedbyQSN.Greyblocks\nmeans they are used exclusively in teh generator or in the discriminator. The generator considers\nthe umpsampling steps in the residual and in the shortcut pass while the discriminator the average\npooling ones, except for the last residual block of the discriminator which keep the dimension\ninvariant.\nsplit ReLU\nQConv\nQConv\nAvgPool\nQConv AvgPool\nFig. 5Firstdiscriminatorquaternionresidualblock(FirstQResBlock)withquaternionconvolutions\nand average pooling layers to downsample the input.\nsignal with a procedure similar to the one considered in Subection 3.3 to handle\ncolored images. The signal is then processed by the quaternion generator up to\nthe last layer, which generates the four-channel fake image. The original SNGAN\nconsiders batch normalization in the generator and spectral normalization in the\ndiscriminator. We keep the same structure and consider the proposed QBN in (28)\nfor the \ufb01rst network and the QSN introduced in Section 3.6 for the discriminator. In\nparticular, we exploit the QSN with spectral norm computed over the whole weight\nmatrix, which is theoretically better and ensures stabler results.\nThede\ufb01nitionoftheSNGANinthequaterniondomainallowstosaveparameters,\nas we will explore in the next section. Moreover, the QSNGAN, processing the\nchannelsasasingleentitythroughthequaternionconvolutionsbasedontheHamilton\nproduct,isabletocapturetherelationsamongthemandtocaptureanyintra-channel\ninformation, which the SNGAN, conversely, loses. The latter property turns into\nan improved generation ability by the QSNGAN that properly grasps the real data\ndistribution. The architecture of the proposed QSNGAN is reported in Fig. 6. In the\nscheme, the forward phase \ufb02ows from left to right for the top network (quaternion\ngenerator) and from right to left for the second network (quaternion discriminator).\n\nQuaternion Generative Adversarial Networks 19\nFake\nTrue\nNoise input\nQResBlock\nupsample\nQuaternion Generator\nQBN\nsplit ReLU\nQConv\nsplit Tanh\nQResBlock\nupsample\nFC layer\nQResBlock\nupsample\nQResBlock\nupsample\nQResBlock\nupsample\nQuaternion Discriminator\nQResBlock\ndownsample\nQResBlock\nSum pooling\nsplit ReLU\nSigmoid\nFC layer\nFirst\nQResBlock\nQResBlock\ndownsample\nQResBlock\ndownsample\nQResBlock\ndownsample\nFig. 6 QSNGAN architecture schema. The generator network (top) takes in input a real-valued\nsignal,processesitwithaafullyconnectedlayerandthenencapsulatesitinaquaternionsignal.The\nresidualblocksaredepictedinFig.4.Thegeneratoroutputsaquaternion-valuedsampleofimages\nthat,togetherwithasamplefromtherealdistribution,goestotheinputofthediscriminatornetwork\n(bottom). It handles the samples through a series of residual blocks (the \ufb01rst one is illustrutade in\nFig. 5, the other ones in Fig. 4) up to the last layer which outputs the real or fake decision.\n4.3 Evaluation metrics\nIn order to evaluate the performance of the generative networks, we consider two\nobjective metrics, the Fr\u00e9chet Inception Distance (FID) [18] as main metric, as\nit is more consistent with human evaluations, and the Inception Score (IS) [31].\nThe Fr\u00e9chet inception distance embeds the generated and the real samples into\nthe Inception convolutional features and models the two distributions as Gaussian\nsignals evaluating the empirical means\ud835\udf07\ud835\udc54\u0096\ud835\udf07data and covariancesC\ud835\udc54\u0096Cdata and then\ncomputes the Fr\u00e9chet distance as:\nFID\u00b9\ud835\udc5d\ud835\udc54\u0096\ud835\udc5ddata\u00ba= jj\ud835\udf07\ud835\udc54 \u0000\ud835\udf07datajj\u00b8 Tr\u00b9C\ud835\udc54 \u00b8Cdata \u00002\u00b9C\ud835\udc54Cdata\u00ba1\u009d2 (37)\nwhereTr \u00b9\u0001\u00barefersto thetrace operation.Being theFIDa distancebetween realand\nfake distributions, the lower the FID value, the better the generated samples.\nInstead, the IS considers the inception model to get the conditional distribution\n\ud835\udc5d\u00b9\ud835\udc66j\ud835\udc65\u00baof the generated samples. IS expects the conditional distribution to have\nlow entropy since the images represent meaningful objects, while the marginal\ndistribution \ud835\udc5d\u00b9\ud835\udc66\u00bashould have high entropy due to the diversity among the samples.\nIt is de\ufb01ned as:\nIS\u00b9\ud835\udc5d\ud835\udc54\u00ba= exp\n\u0010\nE\ud835\udc65\u0018\ud835\udc5d\ud835\udc54 fKL\u00bb\ud835\udc5d\u00b9\ud835\udc66j\ud835\udc65\u00bajj\ud835\udc5d\u00b9\ud835\udc66\u00ba\u00bcg\n\u0011\n(38)\n\n20 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nwhere KL is the Kullback-Leibler divergence. Conversely to the FID, higher IS\nvalues stands for better generated samples. However, IS has some drawbacks since\nit does not consider the true data distribution and, moreover, it is not able to detect\nmode collapse, thus we consider the FID score as main metric and the IS in support\nto it.\n5 Experimental Evaluation\nInordertoevaluatethee\ufb00ectivenessofourproposedapproach,weconductacollec-\ntionofexperimentsontheunsupervisedimagegenerationtask.Wetaketwodatasets\ninto account: the CelebA-HQ [21], which contains 27k images for training and 3k\nimages for testing, and the 102 Oxford Flowers, which contains approximately 7k\nimagesfortrainingandafewlessthen1kimagesfortesting.Wereshapethesamples\nof both the dataset to128 \u0002128 and then test the real-valued SNGAN and the pro-\nposed QSNGAN. We use the Adam optimizer and keep the same hyper-parameters\n\ufb01xed as in [26], i.e., learning rate equal to0\u00950002, and the optimizer parameters\nequalto \ud835\udefd1 = 0\u00950, \ud835\udefd2 = 0\u00959.Wejustvarythenumberofcriticiterations,considering\ntwo experiments with critic iterations equal to 1 and then equal to 5 in order to\nbetterinvestigatethebehaviorofourQSNGAN,whichmayhaveadi\ufb00erentbalance\nbetweengeneratoranddiscriminatornetworkswithrespecttotheSNGAN.Inevery\nexperiment, we \ufb01x the batch size to 64 and we perform 100k training iterations for\nthe CelebA-HQ and 50k for the 102 Oxford Flowers. We have also considered to\nendowtheSNGANandtheQSNGANwithagradientpenalty,asin(13),butwedid\nnot notice any improvement in the experiments, thus meaning that both the SN and\nthe QSN adequately control the discriminator to be Lipschitz continuous.\nThe QSNGAN generator is a quaternion convolutional network as in Fig. 6. The\ninitial fully connected layer, which takes the noise of size 128 in input, is composed\nof 4 \u00024 \u00021024 neurons. The following quaternion residual blocks illustrated in\nFig. 4 stack 1024, 512, 256, 128 and 64 \ufb01lters. This means that, as an example,\nthe \ufb01rst residual block is built by interleaving QBNs, split ReLUs and quaternion\nconvolutions with 1024 kernels and an upsampling module with scale factor equal\nto 2. Further, at the end of the last residual connection, we stack a QBN, a split\nReLU activation function and a \ufb01nal quaternion convolutional layer of dimension\n64tore\ufb01netheoutputimage,whichisthenpassedtoasplitTanhfunctiontobound\nit in the interval\u00bb\u00001\u00961\u00bc. For each quaternion convolution, we \ufb01x the kernel size to\n3 and the stride and the padding to 1. Conversely, the shortcut in the residual block\nis composed of an upsampling module and a quaternion convolution with kernel\nsize equal to 1 and null padding. The network built through this procedure has less\nthan 10M of free parameters with respect to the 32M parameters of its real-valued\ncounterpart. This means that the checkpoint for inference saves more than the70%\nof disk memory, as shown in Table 1.\nThe QSNGAN discriminator is still a quaternion convolutional network as in\nFig. 6, but it is slightly more complex. At the beginning, the real images are en-\n\nQuaternion Generative Adversarial Networks 21\nTable 1 Summary of number of networks parameters and memory requirements for real-valued\nSNGAN and its quaternion-valued counterpart QSNGAN models for CelebA-HQ. The proposed\nmethod saves more than the70% of total free parameters and memory disk for model checkpoints.\nModel #Params G #Params D #Params Tot Disk Memory \u0003\nSNGAN 32,150,787 29,022,213 61,173,000 \u0018115 GB\nQSNGAN 9,631,204 7,264,901 16,896,105 \u001835 GB\n\u0003Generator checkpoint for inference.\ncapsulated in a quaternion as depicted in Subsection 3.3, resulting in a batch of\nfour-channel images. Obviously, the images generated by the generator network are\nalready comprised of four channels and de\ufb01ned as quaternions.\nThe \ufb01rst residual block of the discriminator in Fig. 5 is a spectrally-normalized\nquaternionconvolutionblockwith64 3\u00023 \ufb01ltersandsplitReLUactivationfunctions.\nTheshortcut,instead,asforthegeneratornetwork,isa 1 \u00021 quaternionconvolution\nwith padding equal to 0. In this case, however, both the residual and the shortcut\npart ends with a2 \u00022 split average pooling. The images \ufb02ow then to a stack of\n\ufb01ve residual blocks built as in Fig. 4 with, respectively, 128, 256, 512, 1024 and\n1024 \ufb01lters. Nevertheless, the residual section of each block has a split average\npooling to operate downsampling and the shortcut is comprised of a quaternion\nconvolution and another average pooling. The downsampling procedure is applied\nin each residual block except for the last one, which is a re\ufb01ner and leaves the\ndimensionalityunchanged.EveryweightisnormalizedthroughtheQSNintroduced\ninSubsection3.6.Thecon\ufb01gurationsforkernelsize,strideandpaddingarethesame\nof the generator. At the end of the residual block stack, we apply a split ReLU and a\nglobal sum pooling before passing the batch to the \ufb01nal spectrally-normalized fully\nconnected layer which, by means of a sigmoid, returns the real/fake decision. As\nfor the generator, also the quaternion discriminator allows to save parameters while\nlearningtheinternalrelationsamongchannels.ThissavingisunderlinedinTable1,\nwhich reports the exact number of parameters for the quaternion model and the\nreal-valuedone.ThequaternionGANcanobtainequalorbetterresultswhentrained\nwithlessparameterssinceitleveragesthepropertiesofquaternionalgebra,including\nthe Hamilton product, that allow to capture also the relations among channels and\ncatchmoreinformationontheinput.Consequently,thetrainingprocedureneedsless\nparameters to learn the real distribution and to generate images from it.\nThe objective evaluation is reported in Table 2. We perform the computations of\nFID and IS on the test images (3k for the CelebA-HQ and slightly less than 1k for\nthe 102 Oxford Flowers). As shown in Table 2, the proposed method stands out in\nthegenerationofsamplesfromboththedatasetaccordingtothemetricsconsidered.\nMoreover, the two QSNGANs with critic iterations 1 and 5 score a lower FID\nwith respect to the best con\ufb01guration of the SNGAN model. The proposed method\nperforms better with one critic per generator iterations, while the real-valued model\nfails with this con\ufb01guration. Overall, the QSNGAN seems to be more robust to the\nchoiceofthecriticiterationswithrespecttotheSNGAN,whichismorefragile.The\n\n22 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nTable 2 Results summary for the128 \u0002128 CelebA-HQ and 102 Oxford Flowers datasets. The\nproposed QSNGAN obtains a lower FID in each dataset considered. The vlaues of the IS support\ntheFIDresults.Accordingtotheobjectivemetrics,theproposedQSNGANgeneratesmorevisually\npleasant and diverse samples with respect to the real-valued baseline counterpart. The QSNGAN\nseemstobemorerobusttothechoiceofthehyper-parameterregardingthediscriminatoriterations\n(Critic iter) while the real-valued model fails when changing the original setting which \ufb01xes the\nparameter equal to 5.\nFID # IS \"\nModel Critic iter CelebA-HQ 102 Oxford Flowers CelebA-HQ 102 Oxford Flowers\nSNGAN 1 \u00a1200\u0003 \u00a1200\u0003 \u009f2.000 \u0003 2.797\u00060.196\n5 34.483 165.058 2.032 \u00060.062 2.977\u00060.146\nQSNGAN 1 29.417 175.484 2.249 \u00060.164 2.754\u00060.256\n5 33.068 115.838 2.026\u00060.082 3.000 \u00060.141\n\u0003Discriminator collapses and training fails, thus metrics results are not comparable.\nIS strengthen the results obtained with the FID, as it reports higher scores for the\nproposed method in every dataset.\nThe visual inspection of the generated samples underlines the improved ability\nof our QSNGAN. Figure 7 and Figure 8 show a randomly selected128 \u0002128\nbatch of generated images for the real-valued SNGAN and the proposed QSNGAN,\nrespectively.Ononehand,SNGANseemstobequiteunstableandpronetotheinput\nnoise, thus alternating some good quality images with bad generated ones. Overall,\ntheSNGANisnotalwaysabletodistinguishthebackgroundfromsomepartsofthe\ncharacter, sometimes confusing attributes such as the neck or the hair as part of the\nenvironment, and letting them vanishing. On the other hand, the QSNGAN sample\nin Fig. 8 shows visually pleasant images, with a clear distinction between subject\nand background. It also shows a higher de\ufb01nition of faces attributes, including the\nmostdi\ufb03cultones,suchaseyebrows,beardorskinshades.Inaddition,colorsseem\nto be more vivid and samples are diverse in terms of pose, genre, expression, and\nhair color, among others. Concerning the second dataset, the generated samples for\nthe SNGAN are shown in Fig. 9, while the batch from the QSNGAN is reported\nin Fig. 10. As it is clear from Table 2, the results for this dataset are preliminary\nbut encouraging. Even in this case the proposed approach gains a lower FID and\na higher IS than the real-valued model. Additionally, in SNGAN samples pixels\nare evident and often misleading, thus confusing the \ufb02ower object with the colored\nbackground. On the other hand, the images generated from our QSNGAN contain\nmoredistinctsubjects.Furthermore,theproposedmethodbettercatcheseverycolor\nshadethankstothequaternionalgebraproperties,whichallowthenetworklearning\ninternal relations among channels without losing intra-channel information.\nIn conclusion, the proposed quaternion-valued QSNGAN shows an improved\nability in capturing the real data distribution by leveraging the quaternion algebra\nproperties in each experiment we conduct. It can generate better and more vivid\nsamples according to visual inspections and to objective metrics with respect to its\nreal-valued counterpart. Furthermore, the proposed method has less than the30%\n\nQuaternion Generative Adversarial Networks 23\nFig. 7 Randomlygeneratedsamplesfromthereal-valuedSNGANontheCelebA-HQdatasetafter\n100k training iterations. Sometimes this model fails to detect border attributes such as hair and\nneck which may fade on the background. Indeed, only few samples seem to be visually pleasant\nwhile in some other cases the network fails to generate likable images.\nFig. 8 Randomly generated samples from our QSNGAN on the CelebA-HQ dataset after 100k\ntraining iterations. These images are part of the test samples which gained a FID of 29.417 and IS\n2.249\u00060.164.Theproposedmethodisabletogeneratevisuallypleasantimages,welldistinguishing\nthebackgroundfromtheface.Moreover,wedonotobservemodecollapseassampleshavedi\ufb00erent\nattributes such as genre, hair color, pose and smile, among others.\nof free parameters with respect to the SNGAN which also has worse generation\nperformance.\n\n24 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nFig. 9 Randomly generated samples from the SNGAN model on the 102 Oxford Flowers dataset\nafter 50k training iterations. SNGAN misleads some pixels in the images and depicted objects are\nnot always distinguishable.\nFig. 10 Randomly generated samples from the proposed QSNGAN on the 102 Oxford Flowers\ndataset after 50k training iterations. Flowers contain many di\ufb00erent colors shades and most of the\nobjects are clearly de\ufb01ned. This set of \ufb01gures sow the improved generation ability of our proposed\nmethod with respect to its real-valued counterpart.\n5.1 Evaluation of Spectral Normalization Methods\nThis section reports the tests we conduct to evaluate the two quaternion spectral\nnormalization methods described in Subsection 3.6. In order to investigate the per-\n\nQuaternion Generative Adversarial Networks 25\nformance of the normalizing approaches, we validate two smaller models with re-\nspect to the ones introduced in the previous subsection on the CIFAR10 and STL10\ndatasets.CIFAR10contains50k 32\u000232 imagesfortrainingand10kfortestingwhile\nSTL10 has 105k48 \u000248 images in the train split and 8k in the test one.\nWeexaminethreedi\ufb00erentcon\ufb01gurations:the\ufb01rstonedoesnotinvolveanyQSN\nmethod, thus the discriminator network is not constrained to be 1-Lipscithz. We\nrun this experiment in order to check the e\ufb00ectiveness of the spectral normalization\nmethodsthatwepropose.Thesecondcon\ufb01gurationappliesasplitcomputationofthe\nspectral norm for each quaternion component and normalize each weight submatrix\nW0\u0096 W1\u0096 W2\u0096 W3 independently.Thelastapproachcomputesthespectralnormof\nthe whole weight matrix and uses it to normalize each component. Respectively, we\nrefer to these methods as No QSN, QSN Split and QSN Full.\nTo assess the performance, we build the same SNGANs presented in [26] by\nrede\ufb01ning them in the quaternion domain. We adopt the quaternion core residual\nblocks we de\ufb01ne in the previous section and in Fig. 4, while reducing the model\ndimension.ForCIFAR10,wesetupageneratorwiththeinitiallinearlayer 4\u00024\u0002256\nandthenpileupthreequaternionresidualblocks,eachonewith256\ufb01lters.Asbefore,\nweendupwithastackofQBN,splitReLUandaquaternionconvolutionwitha\ufb01nal\nsplit Tanh to generate the32 \u000232 images in the range\u00bb\u00001\u00961\u00bc. The discriminator, in\nwhich the QSN methods act in each layer, begins with a \ufb01rst residual block (Fig. 5)\nwith128\ufb01ltersandthenproceedswiththreeblockscomposedof128kernels.Asin\nFig. 6, the network ends with a global sum pooling and a fully connected layer with\nsigmoid to output the decision probability. The so-de\ufb01ned QSNGAN for CIFAR10\nis comprised of less than 2M parameters. It is worth noting that the real-valued\ncounterpart presented in [26] has more than 5M of free parameters.\nThemodeltogeneratethe 48 \u000248 STL10imagesisdeeperthanthepreviousone\nand is composed of 5,545,188 parameters. The structure is the same but it contains\naninitiallayerof 6\u00026\u0002512 andthentheresidualblockswith256,128and64\ufb01lters.\nThe \ufb01nal re\ufb01ner quaternion convolutional layers has 64 kernels. The discriminator,\ninstead, has one residual blocks more than the model for CIFAR10 and the \ufb01lters\nare, respectively from the \ufb01rst to the last block, 64, 128, 256, 512, 1024 with a \ufb01nal\n512 fully connected layer with sigmoid.\nAs we can see in Table 3, the unbounded model with no QSN fails in generating\nimages from both CIFAR10 and STL10. Indeed, the FID is much higher than the\nother approaches. This proves the e\ufb00ectiveness of the proposed QSN full method\nwhich computes the spectral norm of each layer taking all the components into\naccount. As a matter of fact, the proposed approach is capable to generate improved\nquality images in every experiment we conduct.\n6 Conclusions\nIn this paper we introduce the family of quaternion-valued GANs (QGANs) that\nleveragesthepropertiesofquaternionalgebra.Wehaverigorouslyde\ufb01nedeachcore\n\n26 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nTable 3 Summary results for comparison of the two quaternion spectral normalization methods\ndepicted in Section 3. We consider the SNGAN proposed in [26] as baseline to de\ufb01ne two simple\nmodels in the quaternion domain and then test the di\ufb00erent QSN approaches. QSN Split refers\nto the \ufb01rst method that normalizes the submatrices independently while QSN Full stands for the\nnormalization of the whole weight matrix together. No QSN is a model without any spectral\nnormalizationmethod.Whilethelatterfails,theQSNFullgeneratesbetterimagesaccordingtothe\nFID in both datasets.\nFID # IS \"\nCon\ufb01g CIFAR10 STL10 CIFAR10 STL10\nNo QSN 70.312 91.567 4.031 \u00061.327 4.744 \u00060.643\nQSN Split 35.417 75.112 4.7128 \u00061.270 4.455 \u00060.092\nQSN Full 31.966 59.611 4.317 \u00060.951 4.987 \u00060.485\nblockemployedtobuildtheproposedQGANs,includingthequaternionadversarial\nframework. Moreover, we have provided a meticulous experimental evaluation on\ndi\ufb00erent image generation benchmarks to prove the e\ufb00ectiveness of our method.\nWe have shown that the proposed QGAN has an improved generation ability with\nrespect to the real-valued counterpart, according to the FID and IS metrics and to a\nvisualinspection.Moreover,ourmethodsavesuptothe 75% offreeparameters.We\nbelieve that these results lay the foundations for novel deep GANs, thus capturing\nhigherlevelsofinputinformationandbettergraspingtherealdatadistribution,while\nsigni\ufb01cantly reducing the overall number of parameters.\nReferences\n1. Arjovsky,M.,Chintala,S.,Bottou,L.:WassersteinGAN. arXivpreprint:arXiv:1701.07875v3\n(2017)\n2. Brock,A.,Donahue,J.,Simonyan,K.:LargescaleGANtrainingforhigh\ufb01delitynaturalimage\nsynthesis. Int. Conf. on Learning Representations (ICLR) (2019)\n3. Chen, T., Zhai, X., Ritter, M., Lucic, M., Houlsby, N.: Self-supervised GANs via auxiliary\nrotation loss. In: IEEE/CVF Int. Conf. on Computer Vision and Pattern Recognition (CVPR),\npp. 12146\u201312155 (2019)\n4. Cheong Took, C., Mandic, D.P.: Augmented second-order statistics of quaternion random\nsignals. Signal Process.91(2), 214\u2013224 (2011)\n5. Chernov,V.:Discreteorthogonaltransformswithdatarepresentationincompositionalgebras.\nProc. Scandinavian Conf. on Image Analysis pp. 357\u2013364 (1995)\n6. Comminiello, D., Lella, M., Scardapane, S., Uncini, A.: Quaternion convolutional neural\nnetworks for detection and localization of 3D sound events. In: IEEE Int. Conf. on Acoust.,\nSpeech and Signal Process. (ICASSP), pp. 8533\u20138537. Brighton, UK (2019)\n7. Ell, T.A., Sangwine, S.J.: Quaternion involutions and anti-involutions. Comput. Math. Appl.\n53(1), 137\u2013143 (2007)\n8. Gaudet, C., Maida, A.: Deep quaternion networks. In: IEEE Int. Joint Conf. on Neural Netw.\n(\u0132CNN). Rio de Janeiro, Brazil (2018)\n9. Glorot, X., Bengio, Y.: Understanding the di\ufb03culty of training deep feedforward neural net-\nworks. In: Int. Conf. on arti\ufb01cial intelligence and statistics, pp. 249\u2013256 (2010)\n\nQuaternion Generative Adversarial Networks 27\n10. Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville,\nA.,Bengio,Y.:Generativeadversarialnets. In:27thInt.Conf.onNeuralInformationProcess-\ning Systems (NIPS), vol. 2, pp. 2672\u20132680. MIT Press, Cambridge, MA, USA (2014)\n11. Gouk,H.,Frank,E.,Pfahringer,B.,Cree,M.J.:Regularisationofneuralnetworksbyenforcing\nLipschitz continuity. Mach. Learn.110(2), 393\u2013416 (2021)\n12. Grassucci, E., Comminiello, D., Uncini, A.: An information-theoretic perspective on proper\nquaternion variational autoencoders. Entropy23(7) (2021)\n13. Grassucci, E., Comminiello, D., Uncini, A.: A quaternion-valued variational autoencoder. In:\nIEEE Int. Conf. on Acoust., Speech and Signal Process. (ICASSP). Toronto, Canada (2021)\n14. Grassucci, E., Scardapane, S., Comminiello, D., Uncini, A.: Flexible generative adversarial\nnetworks with non-parametric activation functions. In: Progress in Arti\ufb01cial Intelligence and\nNeural Systems, vol. 184. Smart Innovation, Systems and Technologies, Springer (2021)\n15. Gui, J., Sun, Z., Wen, Y., Tao, D., Ye, J.p.: A review on generative adversarial networks:\nAlgorithms, theory, and applications. arXiv preprint: arXiv:2001.06937v1 (2020)\n16. Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A.C.: Improved training of\nWasserstein GANs. In: Advances in Neural Information Processing Systems (NIPS) (2017)\n17. He, K., Zhang, X., Ren, S., Sun, J.: Delving deep into recti\ufb01ers: Surpassing human-level\nperformance on imagenet classi\ufb01cation. In: IEEE/CVF Int. Conf. on Computer Vision and\nPattern Recognition (CVPR), pp. 1026\u20131034 (2015)\n18. Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Hochreiter, S.: GANs trained by a two\ntime-scaleupdateruleconvergetoalocalNashequilibrium. In:NeuralInformationProcessing\nSystems (NIPS), pp. 6626\u20136637 (2017)\n19. Ho\ufb00mann,J.,Schmitt,S.,Osindero,S.,Simonyan,K.,Elsen,E.:AlgebraNets. arXivpreprint:\narXiv:2006.07360v2 (2020)\n20. Io\ufb00e, S., Szegedy, C.: Batch normalization: Accelerating deep network training by reducing\ninternal covariate shift. In: Int. Conf. on Machine Learning (ICML), p. 448\u2013456. JMLR.org\n(2015)\n21. Karras,T.,Aila,T.,Laine,S.,Lehtinen,J.:ProgressivegrowingofGANsforimprovedquality,\nstability, and variation. In: Int. Conf. on Learning Representations (ICLR) (2018)\n22. Karras, T., Laine, S., Aila, T.: A style-based generator architecture for generative adversarial\nnetworks.In:IEEEConf.onComputerVisionandPatternRecognition,CVPR,pp.4401\u20134410.\nComputer Vision Foundation / IEEE (2019)\n23. Karras, T., Laine, S., Aittala, M., Hellsten, J., Lehtinen, J., Aila, T.: Analyzing and improving\nthe image quality of stylegan. In: 2020 IEEE/CVF Conf. on Computer Vision and Pattern\nRecognition (CVPR), pp. 8107\u20138116. IEEE (2020)\n24. Kingma, D.P., Welling, M.: Auto-encoding variational Bayes. arXiv Preprint:\narXiv:1312.6114v10 pp. 1\u201314 (2014)\n25. Kurach,K.,Lucic,M.,Zhai,X.,Michalski,M.,Gelly,S.:Alarge-scalestudyonregularization\nand normalization in GANs. In: Int. Conf. on Machine Learning (ICML) (2019)\n26. Miyato, T., Kataoka, T., Koyama, M., Yoshida, Y.: Spectral normalization for generative\nadversarial networks. arXiv preprint: arXiv:1802.05957v1 (2018)\n27. Parcollet, T., Morchid, M., Linar\u00e8s, G.: Quaternion convolutional neural networks for het-\nerogeneous image processing. In: IEEE Int. Conf. on Acoust., Speech and Signal Process.\n(ICASSP), pp. 8514\u20138518. Brighton, UK (2019)\n28. Parcollet, T., Morchid, M., Linar\u00e8s, G.: A survey of quaternion neural networks. Artif. Intell.\nRev. (2019)\n29. Parcollet, T., Ravanelli, M., Morchid, M., Linar\u00e8s, G., Trabelsi, C., De Mori, R., Bengio, Y.:\nQuaternionrecurrentneuralnetworks. In:Int.Conf.onLearningRepresentations(ICLR),pp.\n1\u201319. New Orleans, LA (2019)\n30. Radford, A., Metz, L., Chintala, S.: Unsupervised representation learning with deep convolu-\ntional generative adversarial networks. arXiv preprint: arXiv:1511.06434v2 (2016)\n31. Salimans, T., Goodfellow, I.J., Zaremba, W., Cheung, V., Radford, A., Chen, X.: Improved\ntechniques for training GANs. In: Neural Information Processing Systems (NIPS), pp. 2234\u2013\n2242 (2016)\n\n28 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\n32. Schmidhuber, J.: A possibility for implementing curiosity and boredom in model-building\nneural controllers. In: Proc. of the First Int. Conf. on Simulation of Adaptive Behavior on\nFrom Animals to Animats, pp. 222\u2014-227. MIT Press, Cambridge, MA, USA (1991)\n33. Schmidhuber,J.:Generativeadversarialnetworksarespecialcasesofarti\ufb01cialcuriosity(1990)\nand also closely related to predictability minimization (1991). Neural Networks127, 58\u201366\n(2020)\n34. Sch\u00f6nfeld,E.,Schiele,B.,Khoreva,A.:AU-Netbaseddiscriminatorforgenerativeadversarial\nnetworks. In: IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR), pp.\n8207\u20138216 (2020)\n35. S\ufb01kas, G., Giotis, A.P., Retsinas, G., Nikou, C.: Quaternion generative adversarial networks\nforinscriptiondetectioninbyzantinemonuments. In:PatternRecognition.ICPRInternational\nWorkshops and Challenges, pp. 171\u2013184. Springer International Publishing (2021)\n36. Vecchi,R.,Scardapane,S.,Comminiello,D.,Uncini,A.:Compressingdeep-quaternionneural\nnetworks with targeted regularisation. CAAI Trans. Intell. Technol.5(3), 172\u2013176 (2020)\n37. V\u00eca,J.,Ram\u00ecrez,D.,Santamar\u00eca,I.:Properandwidelylinearprocessingofquaternionrandom\nvectors. IEEE Trans. Inf. Theory56(7), 3502\u20133515 (2010)\n38. Ward, J.P.: Quaternions and Caley Numbers. Algebra ans Applications,Mathematics and Its\nApplications, vol. 403. Kluwer Academic Publishers (1997)\n39. Yin,Q.,Wang,J.,Luo,X.,Zhai,J.,Jha,S.K.,Shi,Y.:Quaternionconvolutionalneuralnetwork\nfor color image classi\ufb01cation and forensics. IEEE Access7, 20293\u201320301 (2019)\n40. Zhang, H., Goodfellow, I.J., Metaxas, D.N., Odena, A.: Self-attention generative adversarial\nnetworks. In: Int. Conf. on Machine Learning (ICML),Proceedings of Machine Learning\nResearch, vol. 97, pp. 7354\u20137363. PMLR (2019)\n41. Zhang,H.,Zhang,Z.,Odena,A.,Lee,H.:Consistencyregularizationforgenerativeadversarial\nnetworks. In: Int. Conf. on Machine Learning (ICML) (2020)\n42. Zhou, Z., Liang, J., Song, Y., Yu, L., Wang, H., Zhang, W., Yu, Y., Zhang, Z.: Lipschitz\ngenerative adversarial nets. In: Int. Conf. on Machine Learning (ICML),Proceedings of\nMachine Learning Research, vol. 97, pp. 7584\u20137593. PMLR (2019)",
  "authors": [
    "Eleonora Grassucci",
    "Edoardo Cicero",
    "Danilo Comminiello"
  ],
  "summary": "Latest Generative Adversarial Networks (GANs) are gathering outstanding results through a large-scale training, thus employing models composed of millions of parameters requiring extensive computational capabilities. Building such huge models undermines their replicability and increases the training instability. Moreover, multi-channel data, such as images or audio, are usually processed by realvalued convolutional networks that flatten and concatenate the input, often losing intra-channel spatial relations. To address these issues related to complexity and information loss, we propose a family of quaternion-valued generative adversarial networks (QGANs). QGANs exploit the properties of quaternion algebra, e.g., the Hamilton product, that allows to process channels as a single entity and capture internal latent relations, while reducing by a factor of 4 the overall number of parameters. We show how to design QGANs and to extend the proposed approach even to advanced models.We compare the proposed QGANs with real-valued counterparts on several image generation benchmarks. Results show that QGANs are able to obtain better FID scores than real-valued GANs and to generate visually pleasing images. Furthermore, QGANs save up to 75% of the training parameters. We believe these results may pave the way to novel, more accessible, GANs capable of improving performance and saving computational resources.",
  "pdf_url": "https://arxiv.org/pdf/2104.09630v2",
  "entry_id": "http://arxiv.org/abs/2104.09630v2",
  "published": "2021-04-19",
  "updated": "2021-07-27",
  "comment": "Accepted as a Chapter for the SPRINGER book \"Generative Adversarial Learning: Architectures and Applications\"",
  "journal_ref": "Generative Adversarial Learning: Architectures and Applications. Intelligent Systems Reference Library, vol 217. Springer, Cham, Feb. 2022",
  "doi": "10.1007/978-3-030-91390-8_4",
  "primary_category": "cs.LG",
  "categories": [
    "cs.LG",
    "cs.AI",
    "cs.CV",
    "eess.IV"
  ],
  "links": [
    {
      "href": "https://arxiv.org/abs/2104.09630v2",
      "rel": "alternate",
      "title": null
    },
    {
      "href": "https://arxiv.org/pdf/2104.09630v2",
      "rel": "related",
      "title": "pdf"
    },
    {
      "href": "https://doi.org/10.1007/978-3-030-91390-8_4",
      "rel": "related",
      "title": "doi"
    }
  ],
  "full_text": "Quaternion Generative Adversarial Networks\nEleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nAbstract LatestGenerativeAdversarialNetworks(GANs)aregatheringoutstanding\nresults through a large-scale training, thus employing models composed of millions\nof parameters requiring extensive computational capabilities. Building such huge\nmodels undermines their replicability and increases the training instability. More-\nover, multi-channel data, such as images or audio, are usually processed by real-\nvalued convolutional networks that \ufb02atten and concatenate the input, often losing\nintra-channel spatial relations. To address these issues related to complexity and\ninformation loss, we propose a family of quaternion-valued generative adversarial\nnetworks (QGANs). QGANs exploit the properties of quaternion algebra, e.g., the\nHamiltonproduct,thatallowstoprocesschannelsasasingleentityandcaptureinter-\nnallatentrelations,whilereducingbyafactorof4theoverallnumberofparameters.\nWe show how to design QGANs and to extend the proposed approach even to ad-\nvancedmodels.WecomparetheproposedQGANswithreal-valuedcounterpartson\nseveral image generation benchmarks. Results show that QGANs are able to obtain\nbetter FID scores than real-valued GANs and to generate visually pleasing images.\nFurthermore, QGANs save up to75% of the training parameters. We believe these\nresults may pave the way to novel, more accessible, GANs capable of improving\nperformance and saving computational resources.\n1 Introduction\nGenerativemodelsincludinggenerativeadversarialnetworks(GANs)[10]andvari-\national autoecoders (VAEs) [24] have been recently spectators of an increasing\nwidespread development due to the massive availability of large datasets covering\nAuthors are with the Department of Information Engineering, Electronics and Telecommuni-\ncations (DIET), Sapienza University of Rome, Via Eudossiana 18, 00184 Rome, Italy, e-mail:\n{eleonora.grassucci, danilo.comminiello}@uniroma1.it. This work has been supported by \u201cPro-\ngettidiRicercaGrandi\u201dofSapienzaUniversityofRomeundergrantnumberRG11916B88E1942F.\n1\narXiv:2104.09630v2  [cs.LG]  27 Jul 2021\n\n2 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\na large range of applications. The demand to learn such complex data distributions\nleads to de\ufb01ne models far from the original approach of a simple GAN, which was\ncharacterizedbyfullyconnectedlayersandevaluatedonbenchmarkdatasetssuchas\ntheMNIST[10].MultiplepathwayshavebeencoveredtoimproveGANsgeneration\nability. A \ufb01rst branch aims at stabilizing the training process which is notoriously\nunstable, often leading to a lack of convergence. This includes constraining the dis-\ncriminator network to be 1-Lipschitz by introducing a gradient penalty in the loss\nfunction, normalizing the spectral norm of the network weights or adding a consis-\ntency regularization [1, 16, 26, 41]. Other signi\ufb01cant improvements are gained by\narchitecturalinnovationssuchasself-attentionmodules,\ufb02exibleactivationfunctions\nor style-based generator [22, 14, 40, 21]. A crucial improvement in the quality of\nimagegenerationhasbeenbroughtbybroadlyscalingupthenetworksandinvolving\nwiderbatchsizes[2,23,34].Indeed,BigGANclosedthevisualqualitygapbetween\nGANs generated images and real-world samples in ImageNet [2]. Most of the latest\nGANs are somehow inspired to it.\nHowever,theseimpressiveresultscomeatthecostofhugemodelswithhundredof\nmillions of free parameters which require large computational resources. This dras-\nticallyreducestheaccessibilityandthedi\ufb00usionofthesekindofmodels.Moreover,\nGANsarenotoriousfragilemodels,thusthetrainingwiththisamountofparameters\nmay result in unstable or less handy process. Furthermore, when dealing with mul-\ntidimensionalinputs,suchasimages,3Daudio,multi-sensorsignalsorhuman-pose\nestimation, among others, real-valued networks break the original structure of the\ninputs. Channels are processed as independent entities and just concatenated in a\ntensor without exploiting any intra-channel correlation.\nIn order to address these limitations, neural networks in hypercomplex domains\nhavebeenproposed.Amongthem,quaternionneuralnetworks(QNNs)leveragethe\nproperties of the non-commutative quaternion algebra to de\ufb01ne lower-complexity\nmodels and preserve relations among channels. Indeed, QNNs process channels\ntogetherasasingleentity,thusmaintainingtheoriginalinputdesignandcorrelation.\nDue to this feature, QNNs are able to capture internal relations while saving up to\nthe75% offreeparametersthankstohypercomplex-valuedoperations,includingthe\nHamilton product.\nEncouragedbythepromisingresultsofothergenerativemodelsinthequaternion\ndomain [13, 12] and the need to make deep GANs more accessible, we introduce\nthe family of quaternion generative adversarial networks (QGANs). QGANs are\ncompletely de\ufb01ned in the quaternion domain and, among other properties, they\nexploit the quaternion convolutions derived from the hypercomplex algebra [28,\n29, 8, 6] to improve the generation ability of the model while reducing the overall\nnumberofparameters.A\ufb01rstattempttointroducequaternionconvolutionsinGANs\nhas been recently made in [35]. Here, we de\ufb01ne the core-blocks of the quaternion\ngenerative adversarial framework that we use to formulate a vanilla QGAN. Then,\nwe explain how to derive more advanced QGANs to prove the superior generation\nabilityoftheproposedapproachinmultipleimagegenerationbenchmarks.Weshow\nthat the quaternion spectral normalized GAN (QSNGAN) is able to earn a better\nFID and a more pleasant visual quality of the generated images with respect to its\n\nQuaternion Generative Adversarial Networks 3\nreal-valued counterpart thanks to the quaternion inner operations. Moreover, the\nproposed QSNGAN has just25% the number of free parameters with respect to the\nreal-valued SNGAN.\nWe believe that these theoretical statements and empirical results lay the founda-\ntions for novel deep GANs in hypercomplex domains capable of grasping internal\ninputrelationswhilescalingdowncomputationalrequirements,thussavingmemory\nand being more accessible. To the best of our knowledge, this is the \ufb01rst time that\na generative adversarial framework has been completely de\ufb01ned in a hypercomplex\ndomain.\nThe contribution of this chapter is threefold:\ni) weintroducethefamilyofquaterniongenerativeadversarialnetworks(QGANs)\nproving their enhanced generation ability and lower-complexity with respect to\nits real-valued counterpart on di\ufb00erent benchmark datasets/one.sup;\nii) we de\ufb01ne the theoretically correct approach to apply the quaternion batch nor-\nmalization (QBN) and rede\ufb01ne existing approaches as its approximations;\niii) we propose and de\ufb01ne the spectral normalization in the quaternion domain\n(QSN) proving its e\ufb03cacy on two image generation benchmarks.\nThe chapter is organized as follows. Section 2 presents the fundamental prop-\nerties of quaternion algebra, while Section 3 describes the quaternion adversarial\nframework and the quaternion-valued core blocks used in QGANs. Section 4 lays\nthe foundations for the quaternion generative adversarial networks and presents a\nsimple quaternion vanilla GAN and a more advanced and complex QGAN model.\nSection 5 proves the e\ufb00ectiveness of the presented QGANs on a thorough empirical\nevaluation, and, \ufb01nally, conclusions are drawn in Section 6.\n2 Quaternion Algebra\nQuaternions are hypercomplex numbers of rank4, being a direct non-commutative\nextension of complex-valued numbers. The quaternion domainH lies in a four-\ndimensional associative normed division algebra over real numbers, belonging to\ntheclassofCli\ufb00ordalgebras[38].Aquaternionisde\ufb01nedasthecompositionofone\nscalar element and three imaginary ones:\n\ud835\udc5e= \ud835\udc5e0 \u00b8\ud835\udc5e1\u02c6\ud835\udea4\u00b8\ud835\udc5e2 \u02c6\ud835\udea5\u00b8\ud835\udc5e3 \u02c6\ud835\udf05= \ud835\udc5e0 \u00b8q (1)\nwith\ud835\udc5e0\u0096 \ud835\udc5e1\u0096 \ud835\udc5e2\u0096 \ud835\udc5e3 2R andbeing \u02c6\ud835\udea4= \u00b91\u00960\u00960\u00ba\u0096 \u02c6\ud835\udea5 = \u00b90\u00961\u00960\u00ba\u0096 \u02c6\ud835\udf05= \u00b90\u00960\u00961\u00baunitaxis\nvectors representing the orthonormal basis inR3. Apure quaternionis a quaternion\nwithoutitsscalarpart \ud835\udc5e0,resultinginthevector q = \ud835\udc5e1\u02c6\ud835\udea4\u00b8\ud835\udc5e2 \u02c6\ud835\udea5\u00b8\ud835\udc5e3 \u02c6\ud835\udf05.Asforcomplex\nnumbers, also the quaternion algebra relies upon the relations among the imaginary\ncomponents:\n/one.supThe implementation of the QGANs is available online at https://github.com/eleGAN23/QGAN\n\n4 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\n\u02c6\ud835\udea42 = \u02c6\ud835\udea52 = \u02c6\ud835\udf052 = \u00001 (2)\n\u02c6\ud835\udea4\u02c6\ud835\udea5 = \u02c6\ud835\udea4\u0002\u02c6\ud835\udea5 = \u02c6\ud835\udf05; \u02c6\ud835\udea5\u02c6\ud835\udf05= \u02c6\ud835\udea5\u0002\u02c6\ud835\udf05= \u02c6\ud835\udea4; \u02c6\ud835\udf05\u02c6\ud835\udea4= \u02c6\ud835\udf05\u0002\u02c6\ud835\udea4= \u02c6\ud835\udea5 (3)\nWhile the scalar product of two quaternions\ud835\udc5e and \ud835\udc5d is simply de\ufb01ned as the\nelement-wise product\ud835\udc5e\u0001\ud835\udc5d = \ud835\udc5e0 \ud835\udc5d0 \u00b8\ud835\udc5e1 \ud835\udc5d1 \u00b8\ud835\udc5e2 \ud835\udc5d2 \u00b8\ud835\udc5e3 \ud835\udc5d3, quaternion vector multi-\nplication, denoted with\u0002, is not commutative, i.e.,\u02c6\ud835\udea4\u02c6\ud835\udea5 \u2260 \u02c6\ud835\udea5\u02c6\ud835\udea4. In fact:\n\u02c6\ud835\udea4\u02c6\ud835\udea5 = \u0000\u02c6\ud835\udea5\u02c6\ud835\udea4; \u02c6\ud835\udea5\u02c6\ud835\udf05= \u0000\u02c6\ud835\udf05\u02c6\ud835\udea5; \u02c6\ud835\udf05\u02c6\ud835\udea4= \u0000\u02c6\ud835\udea4\u02c6\ud835\udf05\u0095\nDuetothenon-commutativeproperty,weneedtointroducethequaternionprod-\nuct,commonlyknownasHamiltonproduct.WewillseethatHamiltonproductplays\na crucial role in neural networks. It is de\ufb01ned as:\n\ud835\udc5e\ud835\udc5d = \u00b9\ud835\udc5e0 \u00b8\ud835\udc5e1\u02c6\ud835\udea4\u00b8\ud835\udc5e2 \u02c6\ud835\udea5\u00b8\ud835\udc5e3 \u02c6\ud835\udf05\u00ba\u00b9\ud835\udc5d0 \u00b8\ud835\udc5d1\u02c6\ud835\udea4\u00b8\ud835\udc5d2 \u02c6\ud835\udea5\u00b8\ud835\udc5d3 \u02c6\ud835\udf05\u00ba\n= \u00b9\ud835\udc5e0 \ud835\udc5d0 \u0000\ud835\udc5e1 \ud835\udc5d1 \u0000\ud835\udc5e2 \ud835\udc5d2 \u0000\ud835\udc5e3 \ud835\udc5d3\u00ba\n\u00b8\u00b9\ud835\udc5e0 \ud835\udc5d1 \u00b8\ud835\udc5e1 \ud835\udc5d0 \u00b8\ud835\udc5e2 \ud835\udc5d3 \u0000\ud835\udc5e3 \ud835\udc5d2\u00ba\u02c6\ud835\udea4\n\u00b8\u00b9\ud835\udc5e0 \ud835\udc5d2 \u0000\ud835\udc5e1 \ud835\udc5d3 \u00b8\ud835\udc5e2 \ud835\udc5d0 \u00b8\ud835\udc5e3 \ud835\udc5d1\u00ba\u02c6\ud835\udea5\n\u00b8\u00b9\ud835\udc5e0 \ud835\udc5d3 \u00b8\ud835\udc5e1 \ud835\udc5d2 \u0000\ud835\udc5e2 \ud835\udc5d1 \u00b8\ud835\udc5e3 \ud835\udc5d0\u00ba\u02c6\ud835\udf05\u0095\n(4)\nThe above product can be rewritten in a more concise form as:\n\ud835\udc5e\ud835\udc5d = \ud835\udc5e0 \ud835\udc5d0 \u0000q \u0001p \u00b8\ud835\udc5e0p \u00b8\ud835\udc5d0q \u00b8q \u0002p\u0096 (5)\nwhere \ud835\udc5e0 \ud835\udc5d0 \u0000q \u0001p is the scalar element of the new quaternion in output and\n\ud835\udc5e0p \u00b8\ud835\udc5d0q \u00b8q \u0002p is instead the vector part of the quaternion. From (5) it is easy to\nde\ufb01ne a concise form of product for pure quaternions too:\nqp = \u0000q \u0001p \u00b8q \u0002p\u0095 (6)\nwhere the scalar product is the same as before for full quaternions and the vector\nproduct isq \u0002p = \u00b9\ud835\udc5e2 \ud835\udc5d3 \u0000\ud835\udc5e3 \ud835\udc5d2\u00ba\u02c6\ud835\udea4\u00b8\u00b9\ud835\udc5e3 \ud835\udc5d1 \u0000\ud835\udc5e1 \ud835\udc5d3\u00ba\u02c6\ud835\udea5\u00b8\u00b9\ud835\udc5e1 \ud835\udc5d2 \u0000\ud835\udc5e2 \ud835\udc5d1\u00ba\u02c6\ud835\udf05.\nSimilarly to complex numbers, the complex conjugate of a quaternion can be\nde\ufb01ned as:\n\ud835\udc5e\u0003= \ud835\udc5e0 \u0000\ud835\udc5e1\u02c6\ud835\udea4\u0000\ud835\udc5e2 \u02c6\ud835\udea5\u0000\ud835\udc5e3 \u02c6\ud835\udf05= \ud835\udc5e0 \u0000q (7)\nAlso the norm is de\ufb01ned and it is equal toj\ud835\udc5ej= p\ud835\udc5e\ud835\udc5e\u0003=\n\u221a\ufe03\n\ud835\udc5e2\n0 \u00b8\ud835\udc5e2\n1 \u00b8\ud835\udc5e2\n2 \u00b8\ud835\udc5e2\n3 that is\ntheeuclideannormin R4.Indeed, \ud835\udc5eissaidtobea unit quaternionif j\ud835\udc5ej= 1,aswell\nas apure unit quaternionif \ud835\udc5e2 = \u00001. Moreover, a quaternion\ud835\udc5eis endowed with an\ninverse determined by:\n\ud835\udc5e\u00001 = \ud835\udc5e\u0003\nj\ud835\udc5ej2 \u0095\nNote that for unit quaternions, the relation\ud835\udc5e\u0003= \ud835\udc5e\u00001 holds.\nA quaternion has also a polar form:\n\nQuaternion Generative Adversarial Networks 5\n\ud835\udc5e= j\ud835\udc5ej\u00b9cos \u00b9\ud835\udf03\u00ba\u00b8v sin \u00b9\ud835\udf03\u00ba\u00ba= j\ud835\udc5ej\ud835\udc52v\ud835\udf03 (8)\nwhere\ud835\udf03 2R istheargumentofthequaternion, cos \u00b9\ud835\udf03\u00ba= \ud835\udc5e0\u009dk\ud835\udc5ek,sin \u00b9\ud835\udf03\u00ba= k\ud835\udc5ek\u009dk\ud835\udc5ek\nandv = \ud835\udc5e\u009dk\ud835\udc5ekis a pure unit quaternion.\nFollowing,quaternionsshowinterestinglypropertieswhentheycanbeinterpreted\nas points and hyperplanes inR4. Among them, we \ufb01nd involutions, which are\ngenerally de\ufb01ned as self-inverse mappings or mappings that are their own inverse.\nQuaternions have an in\ufb01nite number of involutions [7] that can be generalized by\nthe formula:\n\ud835\udc5ev = \u0000v\ud835\udc5ev (9)\nwhere \ud835\udc5e is an arbitrary quaternion to be involved andv is any unit vector and the\naxisoftheinvolution.Amongthein\ufb01niteinvolutions,themostrelevantonesarethe\nthree perpendicular involutions de\ufb01ned as:\n\ud835\udc5e\u02c6\ud835\udea4 = \u0000\u02c6\ud835\udea4\ud835\udc5e\u02c6\ud835\udea4= \ud835\udc5e0 \u00b8\ud835\udc5e1\u02c6\ud835\udea4\u0000\ud835\udc5e2 \u02c6\ud835\udea5\u0000\ud835\udc5e3 \u02c6\ud835\udf05\n\ud835\udc5e\u02c6\ud835\udea5 = \u0000\u02c6\ud835\udea5\ud835\udc5e\u02c6\ud835\udea5 = \ud835\udc5e0 \u0000\ud835\udc5e1\u02c6\ud835\udea4\u00b8\ud835\udc5e2 \u02c6\ud835\udea5\u0000\ud835\udc5e3 \u02c6\ud835\udf05\n\ud835\udc5e\u02c6\ud835\udf05 = \u0000\u02c6\ud835\udf05\ud835\udc5e\u02c6\ud835\udf05= \ud835\udc5e0 \u0000\ud835\udc5e1\u02c6\ud835\udea4\u0000\ud835\udc5e2 \u02c6\ud835\udea5\u00b8\ud835\udc5e3 \u02c6\ud835\udf05\n(10)\nwhich are the \ufb01rst involutions identi\ufb01ed [5] and they are crucial for the study of the\nsecond-order statistics of a quaternion signal, as we will see in the next section.\n3 Generative Learning in the Quaternion Domain\nIn this section, we introduce the quaternion adversarial approach as well as the\nfundamentalquaternion-valuedoperationsemployedtode\ufb01nethefamilyofQGANs\nin next sections. It is worth noting that in a quaternion neural network each element\nis a quaternion, including inputs, weights, biases and outputs.\n3.1 The Quaternion Adversarial Framework\nGenerative adversarial networks are built upon a minimax game between the gen-\nerator network (\ud835\udc3a) and the discriminator one (\ud835\udc37), as a special case of the concept\ninitially proposed to implement arti\ufb01cial curiosity [32, 33]. They are trained in an\nadversarial fashion through the following objective function introduced in [10]:\nmin\n\ud835\udc3a\nmax\n\ud835\udc37\n\ud835\udc49\u00b9\ud835\udc37\u0096\ud835\udc3a\u00ba= E\ud835\udc65\u0018\ud835\udc5ddata\u00b9\ud835\udc65\u00baflog \ud835\udc37\u00b9\ud835\udc65\u00bag\u00b8E\ud835\udc67\u0018\ud835\udc5d\ud835\udc67 \u00b9\ud835\udc67\u00baflog\u00b91 \u0000\ud835\udc37\u00b9\ud835\udc3a\u00b9\ud835\udc67\u00ba\u00ba\u00bag (11)\n\n6 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nwhere \ud835\udc5ddata is the real data distribution and\ud835\udc5d\ud835\udc67 is the noise distribution. The two\ntermsintheobjectivearetwocross-entropies[15].Indeed,the\ufb01rsttermisthecross-\nentropy between\u00bb1 0 \u00bcT and \u00bb\ud835\udc37\u00b9\ud835\udc65\u00ba 1 \u0000\ud835\udc37\u00b9\ud835\udc65\u00ba\u00bcT, whereas the second term is the\ncross-entropy between\u00bb0 1 \u00bcT and \u00bb\ud835\udc37\u00b9\ud835\udc3a\u00b9\ud835\udc67\u00ba\u00ba 1 \u0000\ud835\udc37\u00b9\ud835\udc3a\u00b9\ud835\udc67\u00ba\u00ba\u00bcT. In order to intro-\nducethefamilyofQGANs,\ufb01rstweneedtodelineatethisadversarialapproachinthe\nhypercomplex domain. Thus, we de\ufb01ne the cross-entropy function for quaternions\nwhich has to take the four components into account, as suggested in [28] for the\nquaternion mean squared error, by replacing real numbers with hypercomplex num-\nbersandcomputingtheoperationselement-wise.Thus,thequaternioncross-entropy\n(QCE) between the target quaternion\ud835\udc5e and the estimated one\u02dc\ud835\udc5e can be de\ufb01ned as\nfollows:\nQCE\u00b9\ud835\udc5e\u0096 \u02dc\ud835\udc5e\u00ba= 1\n\ud835\udc41\n\ud835\udc41\u2211\ufe01\n\ud835\udc5b=1\n\u0002\n\ud835\udc5e0 log\u00b9\u02dc\ud835\udc5e0\u00ba\u00b8\u00b9 1 \u0000\ud835\udc5e0\u00balog\u00b91 \u0000\u02dc\ud835\udc5e0\u00ba\n\u00b8\ud835\udc5e1 log\u00b9\u02dc\ud835\udc5e1\u00ba\u00b8\u00b9 1 \u0000\ud835\udc5e1\u00balog\u00b91 \u0000\u02dc\ud835\udc5e1\u00ba\n\u00b8\ud835\udc5e2 log\u00b9\u02dc\ud835\udc5e2\u00ba\u00b8\u00b9 1 \u0000\ud835\udc5e2\u00balog\u00b91 \u0000\u02dc\ud835\udc5e2\u00ba\n\u00b8\ud835\udc5e3 log\u00b9\u02dc\ud835\udc5e3\u00ba\u00b8\u00b9 1 \u0000\ud835\udc5e3\u00balog\u00b91 \u0000\u02dc\ud835\udc5e3\u00ba\n\u0003\n\u0095\n(12)\nMore in general, several objective functions proposed to train GANs can be\nrede\ufb01ned in the quaternion domain. Among the most common ones, we \ufb01nd the\nWasserstein distance with a gradient penalty that enforces the Lipschitz continuity\nof the discriminator, which is de\ufb01ned as follows [1, 16]:\n\ud835\udc49\u00b9\ud835\udc37\u0096\ud835\udc3a\u00ba= E\ud835\udc65\u0018\ud835\udc5ddata f\ud835\udc37\u00b9\ud835\udc65\u00bag\u0000E\ud835\udc67\u0018\ud835\udc5d\u00b9\ud835\udc67\u00baf\ud835\udc37\u00b9\ud835\udc3a\u00b9\ud835\udc67\u00ba\u00bag\u0000\ud835\udf06E\u02c6\ud835\udc65\u0018\ud835\udc5d\u02c6\ud835\udc65\n\b\n\u00b9jjr\u02c6\ud835\udc65\ud835\udc37\u00b9\u02c6\ud835\udc65\u00bajj2 \u00001\u00ba2\t\n(13)\nwhere the last term is the gradient penalty that is a regularization technique for the\ndiscriminator.\nOther works [26, 3] consider instead the hinge loss, which is given, respectively\nfor the discriminator and the generator, by:\n\ud835\udc49\u00b9\ud835\udc37\u0096 \u02c6\ud835\udc3a\u00ba= E\ud835\udc65\u0018\ud835\udc5ddata\u00b9\ud835\udc65\u00bafmin\u00b90\u0096 \u00001 \u00b8\ud835\udc37\u00b9\ud835\udc65\u00ba\u00bag\u00b8E\ud835\udc67\u0018\ud835\udc5d\ud835\udc67 \u00b9\ud835\udc67\u00bafmin\u00b90\u0096 \u00001 \u0000\ud835\udc37\u00b9\ud835\udc3a\u00b9\ud835\udc67\u00ba\u00ba\u00bag\u0096\n(14)\n\ud835\udc49\u00b9\u02c6\ud835\udc37\u0096\ud835\udc3a\u00ba= \u0000E\ud835\udc67\u0018\ud835\udc5d\ud835\udc67 \u00b9\ud835\udc67\u00ba\n\b \u02c6\ud835\udc37\u00b9\ud835\udc3a\u00b9\ud835\udc67\u00ba\u00ba\u00ba\n\t\n\u0095 (15)\nBeing(13)and(14)thecompositionofexpectedvaluesandcross-entropies,both\nthede\ufb01nitionsoftheWassersteinlossandofthehingelossinthequaterniondomain\nare straightforwardly derived by following the procedure shown for the adversarial\nloss in (11).\n\nQuaternion Generative Adversarial Networks 7\n3.2 Quaternion Fully Connected Layers\nIn real-valued neural networks, fully connected layers are generally de\ufb01ned as:\nyr = \ud835\udf19\u00b9Wrxr \u00b8br\u00ba (16)\nwhereWrxr performsthemultiplicationbetweentheweightmatrix Wr andtheinput\nxr, br is the bias and\ud835\udf19\u00b9\u0001\u00bais any activation function. In order to de\ufb01ne the same\noperation in the quaternion domain, we represent the quaternion weight matrix as\nW = W0 \u00b8W1\u02c6\ud835\udea4\u00b8W2 \u02c6\ud835\udea5\u00b8W3 \u02c6\ud835\udf05, the quaternion input asx = x0 \u00b8x1\u02c6\ud835\udea4\u00b8x2 \u02c6\ud835\udea5\u00b8x3 \u02c6\ud835\udf05and\nthequaternionbiasas b = b0 \u00b8b1\u02c6\ud835\udea4\u00b8b2 \u02c6\ud835\udea5\u00b8b3 \u02c6\ud835\udf05.Therefore, Wx in(16),isperformed\nby a vector multiplication between two quaternions, i.e., by the Hamilton product\nW \nx:\nW \nx = \u00b9W0x0 \u0000W1x1 \u0000W2x2 \u0000W3x3\u00ba\n\u00b8\u00b9W1x0 \u00b8W0x1 \u0000W3x2 \u00b8W2x3\u00ba\u02c6\ud835\udea4\n\u00b8\u00b9W2x0 \u00b8W3x1 \u00b8W0x2 \u0000W1x3\u00ba\u02c6\ud835\udea5\n\u00b8\u00b9W3x0 \u0000W2x1 \u00b8W1x2 \u00b8W0x3\u00ba\u02c6\ud835\udf05\u0095\n(17)\nNote thatW has dimensionality1\n4 jWrjsince it is composed of four submatrices\nW0\u0096W1\u0096W2 andW3 eachonewith 1\u009d16 thedimensionof Wr.Thisisakeyfeature\nof QNNs since the results of the quaternion layer with productW \nx has the\nsame output dimension of the real-valued layer built uponWrxr but with1\u009d4 the\nnumber of parameters to train. Note also that the submatrices are shared over each\ncomponentofthequaternioninput.Thesharingallowstheweightstocaptureinternal\nrelations among quaternion elements since each charcteristic in a component will\nhaveanin\ufb02uenceintheothercomponentsthroughthecommonweights.Inthisway\nthe relations among components are preserved and captured by the weights of the\nnetwork which is able to process inputs without losing intra-channel information.\nThebias b isthenaddedwithasumcomponentbycomponent.Finally,inQNNsthe\nactivation functions are applied to the input element-wise resulting in the so called\nsplit activation functions. That is, suppose to consider a common Recti\ufb01ed Linear\nUnit (ReLU) activation functionand the quaternionz = W \nx \u00b8b, the \ufb01nal resulty\nof the layer will be:\ny = ReLU\u00b9z0\u00ba\u00b8ReLU\u00b9z1\u00ba\u02c6\ud835\udea4\u00b8ReLU\u00b9z2\u00ba\u02c6\ud835\udea5\u00b8ReLU\u00b9z3\u00ba\u02c6\ud835\udf05\u0095 (18)\n3.3 Quaternion Convolutional Layers\nConvolutional layers are generally applied to multichannel inputs, such as images.\nSupposing to deal with color images, real-valued neural networks break the struc-\nture of the input and concatenates the red, green and blue (RGB) channels in a\n\n8 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\ntensor. Quaternion-valued convolutions, instead, preserve the correlations among\nthe channels and encapsulates the image in a quaternion as [28, 27, 39]:\nx = 0 \u00b8\ud835\udc45\u02c6\ud835\udea4\u00b8\ud835\udc3a\u02c6\ud835\udea5\u00b8\ud835\udc35\u02c6\ud835\udf05 (19)\nThe image channels are the real coe\ufb03cients of the imaginary units while the scalar\npart is set to0. Encapsulating channels in a quaternion allows to treat them as a\nsingle entity and thus to preserve intra-channels relations. A visual explanation of\nthe quaternion representation of color images is depicted in Fig. 1.\nOriginal image\nReal-valued image\nQuaternion-valued image\nReal-valued \nCNN \nQuaternion-valued \nQCNN \nFig. 1 Visualexplanationofan \ud835\udc45\u0096\ud835\udc3a\u0096\ud835\udc35 imageprocessedbyrealandquaternion-valuednetworks.\nOn the left, the original three-channels image. The image can be processed in two ways: i) As a\ntensor of independent channels by a standard real-valued convolutional network as on the top of\nthe \ufb01gure. ii) As a single entity, encapsulating it in a quaternion, and considering internal relations\namong channels as quaternion-valued convolutional network does in the bottom of the \ufb01gure. It is\nworthnotinghowthereal-valuednetworkdoesnotconsideranycorrelationamongchannelswhile\nquaternion ones preserve the relations among channels.\nSimilarly to the de\ufb01nition of fully connected layers in the previous section, let us\nconsider now a real-valued convolutional layer delineated by:\ny = \ud835\udf19\u00b9Wr \u0003xr \u00b8br\u00ba (20)\nwhere \u0003is the convolution operator. Quaternion convolutional layers are built with\nthe same procedure depicted for fully connected layers thus considering the Hamil-\n\nQuaternion Generative Adversarial Networks 9\nton product instead of the standard vector multiplication. That is, the convolution\noperatorWr \u0003xr is replaced for quaternion weights and inputs with\nW \u0003x = \u00b9W0 \u0003x0 \u0000W1 \u0003x1 \u0000W2 \u0003x2 \u0000W3 \u0003x3\u00ba\n\u00b8\u00b9W1 \u0003x0 \u00b8W0 \u0003x1 \u0000W3 \u0003x2 \u00b8W2 \u0003x3\u00ba\u02c6\ud835\udea4\n\u00b8\u00b9W2 \u0003x0 \u00b8W3 \u0003x1 \u00b8W0 \u0003x2 \u0000W1 \u0003x3\u00ba\u02c6\ud835\udea5\n\u00b8\u00b9W3 \u0003x0 \u0000W2 \u0003x1 \u00b8W1 \u0003x2 \u00b8W0 \u0003x3\u00ba\u02c6\ud835\udf05\u0095\n(21)\nA visual explanation of the operation is shown in \ufb01g.2. While real-valued convolu-\ntional layer has to learn each \ufb01lter independently, quaternion convolution allow the\nsharing of \ufb01lters, thus reducing the number of free parameters to train.\nNote that in convolutional networks the sharing weights are crucial to properly\nprocess channels. Indeed, the RGB channels of an image interact with each other\nby resulting in combined colors, such as yellow or violet, through a representation\nof pixels in the color space. Nonetheless, real-valued networks are not able to catch\nthese interactions since they process input channels separately, while QCNNs not\nonly preserves the input design but also capture these relations through the sharing\nof weights. Actually, QCNNs perform a double learning: the convolution operator\nhas the task of learning external relations among the pixels of the image, while the\nHamilton product accomplishes the learning among the channels. Furthermore, as\nfor linear layers, QCNNs are built with1\u009d4 the number of parameters with respect\nto their real-valued counterpart.\n3.4 Quaternion Pooling Layers\nMany neural networks make use of pooling layers, such as max pooling or average\npooling, to extract high-level information and reduce input dimensions. As done\nbefore for previous layers in the quaternion domain, also this set of operations can\nbe rede\ufb01ned in the quaternion domain.\nThe simplest examples of pooling in the hypercomplex domain are average and\nsum poolings. Indeed, applying these operations to each quaternion component,\nas done for split activation function, will not a\ufb00ect the \ufb01nal result [39]. A di\ufb00erent\napproachmustbede\ufb01ned,instead,formaxpooling.Indeed,themaximumofasingle\ncomponent is not guaranteed by the maximum of all the other components. In order\nto address this issue, a guidance matrix has to be introduced. As in [39], the matrix\nis built through the quaternion amplitude and keeps trace of the maximum position,\nwhichisthenmappedbacktotheoriginalquaternionmatrixinordertoproceedwith\nthe pooling computation. However, max pooling operations are rarely employed in\nGANs, thus we only make use of average and sum pooling in our experiments.\n\n10 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\noutput channels = 8\ninput channels = 4\nReal-valued filters Quaternion-valued filters \nQuaternion \nparameters to learn: \nHamilton rule\nReal-valued  \nparameters to learn:\nthat is, each filter\nindependently\nHamilton rule\nFig. 2 Real and quaternion convolution \ufb01lters for a layer\ud835\udc59with4 channels in input and8 channels\nin output. On the left, the real-valued network has to learn each \ufb01lter independently, thus resulting\nin4 \u00028 = 32 \ufb01lterstolearn.Ontheright,thequaternion\ufb01ltersareadjustedfollowingtheHamilton\nproduct rule in (21) and shared among the4 input components. As a result, the dimension of the\nweightmatrix W isthesameas Wr,butthequaternion\ufb01lterstolearnarejust 4 \u00022 = 8,thatis,the\n25% of the real-valued \ufb01lters. The so-composed \ufb01lters are then employed to perform convolution.\n3.5 Quaternion Batch Normalization\nIntroduced in [20], batch normalization (BN) has immediately became an ever-\npresent module in neural networks. The idea behind BN is to normalize inputs\nto have zero mean and unit variance. This normalization helps the generalization\nability of the network among di\ufb00erent batches of training data and between train\nandtestdatadistribution.Moreover,reducingtheinternalcovariateshiftremarkably\nimproves the training speed, thus leading to a faster convergence of the model.\n\nQuaternion Generative Adversarial Networks 11\nFor these reasons, also QNNs are endowed with batch normalization. However,\ndi\ufb00erent versions of this method were proposed in literature. An elegant whitening\nprocedurebasedonthestandardcovarincematrixisintroducedin[8].Inthatpaper,\nthe Cholesky decomposition is used to compute the square root of the inverse of\nthe covariance matrix, which is often intractable. The authors asserts that approach\nensures zero mean, unit variance and decorrelation among components. However,\nthe covariance matrix is not able to recover the complete second-order statistics in\nthequaterniondomain[4]andthedecompositionrequiresheavymatrixcalculations\nand computational time [19]. Another remarkable approach is introduced in [36],\nwhere the input is standardized computing the average of the variance of each\ncomponent. Nevertheless, describing the second-order statistics of a signal in the\nquaternion domain needs meticulous computations and the approach in [36] is an\napproximation of the complete variance. Notwithstanding the approximation, this\nmethod allows to notably reduce computational time.\nThe proper theoretically procedure to reach a centered, decorrelated and unit-\nvariance quaternion signal would be represented by performing a whitening proce-\ndure. Ideally, we should consider the covariance matrix and then decompose it to\nwhiten the input in order to avoid computing the square root of the inverse which is\noftenunfeasible.However,duetotheinteractionsamongcomponents,second-order\nstatistics for quaternion random variables are not completely described by the stan-\ndardcovariancematrix[4].Forthisreason,theaugmentedcovariancematrixshould\nbeconsideredinstead.Suchmatrixisaugmentedwiththecomplementarycovariance\nmatrices Cqq\ud835\udc56 \u0096 Cqq\ud835\udc57 \u0096 Cqq\ud835\udc58 that are the covariance matrices of the quaternion with\nits three perpendicular involutionsq\ud835\udc56\u0096q\ud835\udc57\u0096q\ud835\udc58. Thus, the augmented covariance ma-\ntrix,whichcompletelycharacterizesthesecond-orderinformationoftheaugmented\nquaternion vector\u02dcq, is de\ufb01ned as:\n\u02dcCqq = E\n\b\u02dcq\u02dcqH\t\n=\n266666664\nCqq Cqq\u02c6\ud835\udea4 Cqq\u02c6\ud835\udea5 Cqq \u02c6\ud835\udf05\nCH\nqq\u02c6\ud835\udea4 Cq\u02c6\ud835\udea4q\u02c6\ud835\udea4 Cq\u02c6\ud835\udea4q\u02c6\ud835\udea5 Cq\u02c6\ud835\udea4q \u02c6\ud835\udf05\nCH\nqq\u02c6\ud835\udea5 Cq\u02c6\ud835\udea5q\u02c6\ud835\udea4 Cq\u02c6\ud835\udea5q\u02c6\ud835\udea5 Cq\u02c6\ud835\udea5q \u02c6\ud835\udf05\nCH\nqq \u02c6\ud835\udf05 Cq \u02c6\ud835\udf05 q\u02c6\ud835\udea4 Cq \u02c6\ud835\udf05 q\u02c6\ud835\udea5 Cq \u02c6\ud835\udf05 q \u02c6\ud835\udf05\n377777775\n(22)\nwhere \u00b9\u0001\u00baH is the conjugate transpose operator. The formulation in (22) recovers the\ncompletestatisticalinformationofageneralquaternionsignal.Thus,thetheoretically\nprocedure should be delineated as:\nx = \u02dcC\u00001\u009d2\nqq \u00b9x \u0000Efxg\u00ba (23)\norsubstitutingtheinversesquareroot \u02dcC\u00001\u009d2\nqq withadecompositionofit.However,the\nconstruction of the augmented covariance matrix may be quite di\ufb03cult and compu-\ntationalexpensiveduetothecomputationofeachsub-covariancematrix.Moreover,\n\u02dcC\u00001\u009d2\nqq includes skew-symmetric sub-matrices [4], which make the decomposition\nmore di\ufb03cult.\nInordertosimplifythecalculationof (22)andmakeitmorefeasibleforpractical\napplications, a particular case can be considered by leveraging theQ-properness\n\n12 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nproperty[37,4,13].The Q-propernessentailsthatthequaternionsignalisnotcorre-\nlated with its involutions, implying vanishing complementary covariance matrices,\ni.e., Cqq\ud835\udc56 = Cqq\ud835\udc57 = Cqq\ud835\udc58 = 0. Also, forQ-proper random variables the following\nrelation holds:\nvar fq\ud835\udc50g= E\n\b\nq2\n\ud835\udc50\n\t\n= \ud835\udf0e2\u0096 \ud835\udc50 = f0\u00961\u00962\u00963g (24)\nThus, considering aQ-proper quaternion, the covariance in (22) becomes:\n\u02dcCqq = E\n\b\u02dcq\u02dcqH\t\n=\n26666664\nCqq 0 0 0\n0 C q\u02c6\ud835\udea4q\u02c6\ud835\udea4 0 0\n0 0 C q\u02c6\ud835\udea5q\u02c6\ud835\udea5 0\n0 0 0 C q \u02c6\ud835\udf05 q \u02c6\ud835\udf05\n37777775\n= 4\ud835\udf0e2I (25)\nAssuming Q-properness for a random variable saves a lot of calculations and\ncomputationalcosts.Notwithstandingthetheoreticalcorrectnessoftheabovede\ufb01ned\napproach, quaternion batch normalization (QBN) techniques adopted so far in the\nliterature relies in some approximations.\nWe assume the input signal isQ-proper, thus we consider the covariance in (25)\nand build the normalization as follows:\nx = x \u0000\ud835\udf07\ud835\udc5e\n\u221a\ufe01\nvar fxg\u00b8\ud835\udf16\n= x \u0000\ud835\udf07\ud835\udc5e\np\n4\ud835\udf0e2 \u00b8\ud835\udf16\n(26)\nwhere \ud835\udf07\ud835\udc5e is the quaternion input mean value, which is a quaternion itself, and it is\nde\ufb01ned as:\n\ud835\udf07\ud835\udc5e = 1\n\ud835\udc41\n\ud835\udc41\u2211\ufe01\n\ud835\udc5b=1\n\ud835\udc5e0\u0096\ud835\udc5b \u00b8\ud835\udc5e1\u0096\ud835\udc5b\u02c6\ud835\udea4\u00b8\ud835\udc5e2\u0096\ud835\udc5b \u02c6\ud835\udea5\u00b8\ud835\udc5e3\u0096\ud835\udc5b\u02c6\ud835\udf05= \u00af\ud835\udc5e0 \u00b8\u00af\ud835\udc5e1\u02c6\ud835\udea4\u00b8\u00af\ud835\udc5e2 \u02c6\ud835\udea5\u00b8\u00af\ud835\udc5e3 \u02c6\ud835\udf05\u0095 (27)\nThe \ufb01nal output is computed as follows:\nQBN\u00b9x\u00ba= \ud835\udefex \u00b8\ud835\udefd (28)\nwhere \ud835\udefdis a shifting quaternion parameter and\ud835\udefeis a scalar parameter.\nInconclusion,theQBNproposedby[8]isanelegantapproximation,nevertheless\nitisnotabletocatchthecompletesecond-orderstatisticsinformation,whilerequiring\nheavycomputations[19].Thus,webelievethatconsidering Q-propersignals,which\nare indeed very frequent, is a good approximation which also extremely reduces the\ncomputationalrequirements.Forourexperiments,weadoptthemethodrepresented\nby (28).\n3.6 Quaternion Spectral Normalization\nAmong the wide variety of proposed techniques to stabilize GANs traning, the\nspectral normalization (SN) [26] is one of the most widespread method. Previously,\n\nQuaternion Generative Adversarial Networks 13\nthe crucial importance of having a Lipschitz-bounded discriminator function was\nintroduced in [1, 16]. Lately, it was proved that no restriction on the discriminator\nspace leads to thegradient uninformativenessproblem [42]. This means that the\ngradient of the optimal discriminative function has no information about the real\ndistribution, thus providing useless feedbacks to the generator. Forcing a function\nto be Lipschitz continuous means controlling how fast it increases and bound the\ngradients, thus mitigating gradient explosions [42, 11]. In [1], a method based on\nweight clipping was proposed to force the discriminator to be 1-Lipschitz. Later,\nsuchapproachhasbeenimprovedbyaddingagradientpenalty(GP)thatconstraints\nthe gradient norm to be at most 1 [16]. The latter method is reproposed in several\nstate-of-the-artGANsandcombinedwithotherregularizationtechniquestoimprove\nperformance, as suggest [25]. However, being built on the gradients with respect to\nthe inputs, the gradient penalty cannot impose a regularization outside the support\nofthefakeand realdatadistribution.Moreover,itrequires consistentcomputations.\nThe spectral normalization, instead, directly operates on the weights of the network\nbeingfreeofthesupportlimitanditscomputationsisfasterthanothermethods[26].\nIt aims at controlling the Lipschitz constant of the discriminator by constraining the\nspectral norm of each layer.\nA generic function\ud835\udc53 is \ud835\udc3e-Lipschitz continuous if, for any two points\ud835\udc651, \ud835\udc652, the\nfollowing property holds:\nk\ud835\udc53 \u00b9\ud835\udc651\u00ba\u0000\ud835\udc53 \u00b9\ud835\udc652\u00bak\nj\ud835\udc651 \u0000\ud835\udc652j \u0014\ud835\udc3e (29)\nbeing k\u0001kthe \ud835\udc592 norm. The Lipschitz norm k\ud835\udc53kLip of a function \ud835\udc53 is equal to\nsup\ud835\udc65\ud835\udf0e\u00b9r\ud835\udc53\u00b9\ud835\udc65\u00ba\u00ba, where\ud835\udf0e\u00b9\u0001\u00bais the spectral norm of the matrix in input, that is, the\nlargest singular value of the matrix.\nFor a generic linear layer\ud835\udc53\u00b9\u210e\u00ba= Wx \u00b8b, the Lipschitz norm is:\nk\ud835\udc53kLip = sup\n\u210e\n\ud835\udf0e\u00b9r\ud835\udc53\u00b9\u210e\u00ba\u00ba= sup\n\u210e\n\ud835\udf0e\u00b9W\u00ba= \ud835\udf0e\u00b9W\u00ba (30)\nAssuming the Lipschitz norm of each layer activation being equal to 1, constraint\nthat is satis\ufb01ed for many popular activation functions including ReLU and Leaky\nReLU [26], we can apply the Lipschitz bound to the whole network by following\nk\ud835\udc531 \u000e\ud835\udc532 kLip \u0014k\ud835\udc531 kLip \u0001k\ud835\udc532 kLip.\nFinally, the SN is de\ufb01ned as\n\u00af\ud835\udc4a\ud835\udc46\ud835\udc41 \u00b9W\u00ba= W\n\ud835\udf0e\u00b9W\u00ba (31)\nanditensuresthattheweightmatrix W alwayssatis\ufb01estheconstraint \ud835\udf0e\u00b9W\u00ba= 1.In\n[26] the authors underline that applying the original singular value decomposition\nalgorithmtocompute \ud835\udf0e\u00b9W\u00bamayresultinanextremelyheavyalgorithm.Toaddress\nthecomputationalcomplexity,theysuggesttoestimatethelargestsingularvaluevia\nthe power iteration method.\nIn order to control the Lipschitz constraint in a QGAN, in this section we\nexplore two methods to de\ufb01ne the spectral normalization in the quaternion do-\n\n14 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nmain. A \ufb01rst approach aims at normalizing the weightsW by operating on each\nsubmatrix W0\u0096 W1\u0096 W2\u0096 W3 independently, by computing the spectral norm\nseparately. That is, through the power iteration method as above, we compute\n\ud835\udf0e0 \u00b9W0\u00ba\u0096 \ud835\udf0e1 \u00b9W1\u00ba\u0096 \ud835\udf0e2 \u00b9W2\u00ba\u0096 \ud835\udf0e3 \u00b9W3\u00baand then normalize each submatrix with\nthe corresponding norm. This method forces each submatrix to have spectral norm\nequal to 1. However, it never takes the whole weight matrixW into account. More-\nover,therelationsamongthecomponentsofthequaternionmatrixisnotconsidered,\nlosing the characteristic property of QNNs.\nThesecondmethod,similarlytothereal-valuedSN,normalizesthewholematrix\nW together,byimposingtheconstrainttothecompletematrixandnottothesingular\nsubmatrices.Therefore,thespectralnormiscomputedbytakingthecompleteweight\nmatrixintoaccountandconsideringtherelationsamongthequaternioncomponents.\nHowever, while the spectral norm is computed as in (30), the normalization step is\napplied di\ufb00erently from the SN in (31). Instead of normalizing the whole matrix as\nin (31), being the weight matrixW designed by a composition of the submatrices\nW0\u0096 W1\u0096 W2\u0096 W3, we can leverage this quaternion setup to save computational\ncosts and normalize each submatrixW0\u0096 W1\u0096 W2\u0096 W3. The normalized subma-\ntrices \u00afW0\u0096\ud835\udc44\ud835\udc46\ud835\udc41 \u0096 \u00afW1\u0096\ud835\udc44\ud835\udc46\ud835\udc41 \u0096 \u00afW2\u0096\ud835\udc44\ud835\udc46\ud835\udc41 \u0096 \u00afW3\u0096\ud835\udc44\ud835\udc46\ud835\udc41 will result in a normalized weight\nmatrix \u00af\ud835\udc4a\ud835\udc44\ud835\udc46\ud835\udc41 \u00b9W\u00bawithamoree\ufb03cientcomputationthannormalizingthefullmatrix\nW.\nAn empirical comparison between the two methods is reported in Section 5. We\ninvestigate the two techniques in a plain QGAN and prove that the latter approach\nis stabler and gains better performance in both the datasets considered. We deem\nit more appropriate both theoretically and empirically and we use it in our further\nexperiments. From now on, we refer to such approach as the quaternion spectral\nnormalization (QSN).\n3.7 Quaternion Weight Initialization\nWeight initialization has often a crucial role in networks convergence and in the\nreduction of the risk of vanishing or exploding gradients [9]. This procedure be-\ncomes even more important when dealing with quaternion weights. Indeed, due to\nthe interactions among the elements of the quaternion, the initialization cannot be\nrandomnorcomponent-aware.Forthesereasons,anappropriateinitializationhasto\nbe introduced.\nFirst,consideraweightmatrix W withE fjWjg= 0.Theinitializationisbasedon\nanormalizedpurequaternion \ud835\udc62generatedforeachweightsubmatrixfromauniform\ndistribution in \u00bb0\u00961\u00bc. By using the polar form of a quaternion, we can de\ufb01ne the\ninitialization of the weight matrix as\nW = jWj\ud835\udc52\ud835\udc62\ud835\udf03 = jWj\u00b9cos\u00b9\ud835\udf03\u00ba\u00b8\ud835\udc62sin\u00b9\ud835\udf03\u00ba\u00ba (32)\nwhere each matrix component is initialized as\n\nQuaternion Generative Adversarial Networks 15\nW0 = \ud835\udf19cos\u00b9\ud835\udf03\u00ba\nW1 = \ud835\udf19\ud835\udc621 sin\u00b9\ud835\udf03\u00ba\nW2 = \ud835\udf19\ud835\udc622 sin\u00b9\ud835\udf03\u00ba\nW3 = \ud835\udf19\ud835\udc623 sin\u00b9\ud835\udf03\u00ba\n(33)\nwhere the angle\ud835\udf03 is randomly generated in the interval\u00bb\u0000\ud835\udf0b\u0096\ud835\udf0b\u00bcand \ud835\udf19is randomly\nsampledintheintervalofthestandarddeviationaroundzero \u00bb\u0000\ud835\udf0e\u0096\ud835\udf0e\u00bc.Thestandard\ndeviation is set according to the initialization method chosen, either [9] or [17]. In\nthe\ufb01rstcase,weset \ud835\udf0e= 1\u009d\n\u221a\ufe01\n2\u00b9\ud835\udc5b\ud835\udc56\ud835\udc5b \u00b8\ud835\udc5b\ud835\udc5c\ud835\udc62\ud835\udc61\u00bawhereasinthelatterweset \ud835\udf0e= 1\u009dp2\ud835\udc5b\ud835\udc56\ud835\udc5b.\nIn both the equations,\ud835\udc5b\ud835\udc56\ud835\udc5b is the number of neurons in the input layer and\ud835\udc5b\ud835\udc5c\ud835\udc62\ud835\udc61 the\nnumber of neurons in the output layer. The variance ofW can be written as:\nvar fWg= E\n\b\njWj2\t\n\u0000EfjWjg2 \u0095 (34)\nHowever, similarly to the QBN in the previous section, in order to reduce the\ncomputations,thecomponentE fjWjg2 canbeconsideredequalto 0 [29,28].Thisis\nequivalenttoconsideringa Q-properquaternionsignalwhoseaugmentedcovariance\nmatrix has o\ufb00-diagonal elements equal to0 and trace equal to4\ud835\udf0e2. Consequently,\nthe variance is computed by considering only the \ufb01rst term of (34) as:\nvar fWg= E\n\b\njWj2\t\n= 4\ud835\udf0e2 (35)\n3.8 Training\nTheforwardphaseofaQNNisthesameasitsreal-valuedcounterpart.Therefore,the\ninput\ufb02owsfromthe\ufb01rsttothelastlayerofthenetwork.Itmaybeinterestingtonote\nthat in eq. (17) the order of the weight and the input can be inverted, thus changing\nthe output of the product, resulting in an inverted QNN [28, 29]. For what concerns\nthe backward phase, it worth mentioning that the gradient of a general quaternion\nlossfunction Liscomputedforeachcomponentofthequaternionweightmatrix W\nas in the ensuing equation:\n\ud835\udeffL\n\ud835\udeffW = \ud835\udeffL\n\ud835\udeffW0\n\u00b8 \ud835\udeffL\n\ud835\udeffW1\n\u02c6\ud835\udea4\u00b8 \ud835\udeffL\n\ud835\udeffW2\n\u02c6\ud835\udea5\u00b8 \ud835\udeffL\n\ud835\udeffW3\n\u02c6\ud835\udf05\u0095 (36)\nThen,thegradientispropagatedbackfollowingthechainrule.Indeed,asde\ufb01ned\nin[28],thebackpropagationofquaternionneuralnetworksisjustanextensionofthe\nmethod for their real-valued counterpart. Consequently, QNNs can be easily trained\nas real-valued networks via backpropagation.\n\n16 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\n4 GAN Architectures in the Quaternion Domain\nThe previous section described the main blocks and the framework to build and\ntrain a GAN in the quaternion domain. In this section we go further, presenting the\ncomplete de\ufb01nition of a plain QGAN in Subsection 4.1 and of an advanced state-\nof-the-art QGAN composed of complex blocks in Subsection 4.2. First, in order\nto setting up a QGAN, each input, weight, bias and output has to be manipulated\nto become a quaternion. Therefore, weight matrices are initialized as composed\nby the four submatrices, similarly to (17) and (21). Real-valued operations such as\nmultiplications or convolutions in the networks are replaced with their quaternion\ncounterparts, completing the rede\ufb01nition of the layers in the quaternion domain.\nThe input is handled as a quaternion and processed as a single entity. For images, a\npure quaternion is considered as in (19), while for other kind of multidimensional\nsignals, the scalar part is considered too. The initialization of the weights is then\nappliedfollowingthedescriptioninSection3.7.Thisaccuratede\ufb01nitionofQGANs\ngrants to design a model with a fewer number of free parameters with respect to\nthe same real-valued model and consequently to save memory and computational\nrequirements.\n4.1 Vanilla QGAN\nIn the original GAN [10], both the generator (\ud835\udc3a) and the discriminator (\ud835\udc37) are\nde\ufb01ned by fully connected layers. Due to the limited expressivity of this design\nwith complex data such as images, in [30] the authors propose to replace dense\nlayers with more suitable operations for this kind of data and to build\ud835\udc3a and \ud835\udc37 by\nstacking several convolutional layers. State-of-the-art GANs are based on the deep\nconvolutional GAN (DCGAN) [30]. In particular, the DCGAN increases the spatial\ndimensionalitybymeansoftransposedconvolutionsinthegeneratoranddecreasesit\nin the discriminator with convolutions. Furthermore, this architecture de\ufb01nes batch\nnormalizationineverylayerexceptforthelastlayerof \ud835\udc3aandforthe\ufb01rstlayerof \ud835\udc37,\nin order to let the networks learn the correct statistics of the data distribution.\nBy rede\ufb01ning the DCGAN in the quaternion domain (QDCGAN) it is possible\nto explore the potential of the quaternion algebra in a simple GAN framework. The\nQDCGAN generator is de\ufb01ned by an initial quaternion fully connected layer and\nthen by interleaving quaternion transposed convolutions with quaternion batch nor-\nmalizationandsplitReLUactivationfunctionsexceptforthelastlayerwhichendsup\nwithasplitTanhfunction.Thediscriminatorhasthesamestructureofthegenerator\nbutwithquaterniontransposedconvolutionsreplacedbyquaternionconvolutionsto\ndecrease the dimensionality and with a \ufb01nal fully connected quaternion layer that\nreturns as output the real/fake decision by means of a sigmoid split activation. The\nQDCGAN, as its real-valued counterpart, optimizes the original loss in (11).\n\nQuaternion Generative Adversarial Networks 17\nQTranConv \nQBN\nsplit ReLU\nQTranConv \nsplit Tanh\nQuaternion Generator\nQuaternion Discriminator\nQFC layerQFC layer\nsplit Sigm\nQNoise Input\nFake\nTrue\nQTranConv \nQBN\nsplit ReLU\nQTranConv \nQBN\nsplit ReLU\nsplit LReLU\nQBN\nQConv\nsplit LReLU\nQConv\nsplit LReLU\nQBN\nQConv\nsplit LReLU\nQBN\nQConv\nFig. 3 QuaternionVanillaGANarchitecture.Eachparameterincludinginputs,weightsandoutputs\nisaquaternion.Thegenerator(greennetwork)takesaquaternionnoisesignalandgeneratesabatch\nof quaternion images with four channels. The discriminator tries to distinguish between fake and\nreal quaternion samples exploiting the properties of quaternion algebra.\n4.2 Advanced QGAN\nTheabovepresentedVanillaQGANisjustaplainexampletogiveageneralideaon\nhow to build GANs in the quaternion domain. In this section, we consider a more\nadvanced model, the spectral normalized GAN (SNGAN) [26] and we present the\nsteps to de\ufb01ne its quaternion counterpart.\nThequaternionspectralnormalizedGAN(QSNGAN)istrainedinanadversarial\nfashion through the hinge loss de\ufb01ned in (14) and (15) for the discriminator and\ngenerator respectively, as suggested in [26, 3]. The overall architecture of the model\nis inspired by [3]. Both the generator and discriminator networks are characterized\nbyquaternionconvolutionallayersinordertoleveragethepropertiesoftheHamilton\nproduct. To mitigate the vanishing gradient problem and obtain better performance,\na series of residual blocks with upsampling in the generator and downsampling in\nthedisciminatorcanbeadopted[26].Aschemeoftheresidualblockoftheproposed\nQSNGAN is depicted in Fig. 4. The discriminative network plays a crucial role in\nGANs training, thus it is more complex with respect to the generator network. It\ntakesininputthetwosetsofquaternionimageswithfourchannelsina\ufb01rstresidual\nblock,asillustratedinFig.5.Theoutputoftheblockisthedecisiononwhetherthey\ncome from the fake or real distribution.\nIn order to guarantee a fair comparison with the SNGAN, we consider a real-\nvalued noise signal in input to the generator and handle it with an initial real-valued\nfullyconnectedlayer.Theoutputofthe\ufb01rstlayeristhenencapsulatedinaquaternion\n\n18 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nQBN\nQBN\nsplit ReLU\nQConv\nsplit ReLU\nQConv\nQConv\nUpsampling\nAvgPool\nUpsampling AvgPool\nFig. 4 Quaternion residual block (QResBlock) architecture inspired by [26] and rede\ufb01ned in the\nquaterniondomain.QBNisomittedinthediscriminatornetworkandreplacedbyQSN.Greyblocks\nmeans they are used exclusively in teh generator or in the discriminator. The generator considers\nthe umpsampling steps in the residual and in the shortcut pass while the discriminator the average\npooling ones, except for the last residual block of the discriminator which keep the dimension\ninvariant.\nsplit ReLU\nQConv\nQConv\nAvgPool\nQConv AvgPool\nFig. 5Firstdiscriminatorquaternionresidualblock(FirstQResBlock)withquaternionconvolutions\nand average pooling layers to downsample the input.\nsignal with a procedure similar to the one considered in Subection 3.3 to handle\ncolored images. The signal is then processed by the quaternion generator up to\nthe last layer, which generates the four-channel fake image. The original SNGAN\nconsiders batch normalization in the generator and spectral normalization in the\ndiscriminator. We keep the same structure and consider the proposed QBN in (28)\nfor the \ufb01rst network and the QSN introduced in Section 3.6 for the discriminator. In\nparticular, we exploit the QSN with spectral norm computed over the whole weight\nmatrix, which is theoretically better and ensures stabler results.\nThede\ufb01nitionoftheSNGANinthequaterniondomainallowstosaveparameters,\nas we will explore in the next section. Moreover, the QSNGAN, processing the\nchannelsasasingleentitythroughthequaternionconvolutionsbasedontheHamilton\nproduct,isabletocapturetherelationsamongthemandtocaptureanyintra-channel\ninformation, which the SNGAN, conversely, loses. The latter property turns into\nan improved generation ability by the QSNGAN that properly grasps the real data\ndistribution. The architecture of the proposed QSNGAN is reported in Fig. 6. In the\nscheme, the forward phase \ufb02ows from left to right for the top network (quaternion\ngenerator) and from right to left for the second network (quaternion discriminator).\n\nQuaternion Generative Adversarial Networks 19\nFake\nTrue\nNoise input\nQResBlock\nupsample\nQuaternion Generator\nQBN\nsplit ReLU\nQConv\nsplit Tanh\nQResBlock\nupsample\nFC layer\nQResBlock\nupsample\nQResBlock\nupsample\nQResBlock\nupsample\nQuaternion Discriminator\nQResBlock\ndownsample\nQResBlock\nSum pooling\nsplit ReLU\nSigmoid\nFC layer\nFirst\nQResBlock\nQResBlock\ndownsample\nQResBlock\ndownsample\nQResBlock\ndownsample\nFig. 6 QSNGAN architecture schema. The generator network (top) takes in input a real-valued\nsignal,processesitwithaafullyconnectedlayerandthenencapsulatesitinaquaternionsignal.The\nresidualblocksaredepictedinFig.4.Thegeneratoroutputsaquaternion-valuedsampleofimages\nthat,togetherwithasamplefromtherealdistribution,goestotheinputofthediscriminatornetwork\n(bottom). It handles the samples through a series of residual blocks (the \ufb01rst one is illustrutade in\nFig. 5, the other ones in Fig. 4) up to the last layer which outputs the real or fake decision.\n4.3 Evaluation metrics\nIn order to evaluate the performance of the generative networks, we consider two\nobjective metrics, the Fr\u00e9chet Inception Distance (FID) [18] as main metric, as\nit is more consistent with human evaluations, and the Inception Score (IS) [31].\nThe Fr\u00e9chet inception distance embeds the generated and the real samples into\nthe Inception convolutional features and models the two distributions as Gaussian\nsignals evaluating the empirical means\ud835\udf07\ud835\udc54\u0096\ud835\udf07data and covariancesC\ud835\udc54\u0096Cdata and then\ncomputes the Fr\u00e9chet distance as:\nFID\u00b9\ud835\udc5d\ud835\udc54\u0096\ud835\udc5ddata\u00ba= jj\ud835\udf07\ud835\udc54 \u0000\ud835\udf07datajj\u00b8 Tr\u00b9C\ud835\udc54 \u00b8Cdata \u00002\u00b9C\ud835\udc54Cdata\u00ba1\u009d2 (37)\nwhereTr \u00b9\u0001\u00barefersto thetrace operation.Being theFIDa distancebetween realand\nfake distributions, the lower the FID value, the better the generated samples.\nInstead, the IS considers the inception model to get the conditional distribution\n\ud835\udc5d\u00b9\ud835\udc66j\ud835\udc65\u00baof the generated samples. IS expects the conditional distribution to have\nlow entropy since the images represent meaningful objects, while the marginal\ndistribution \ud835\udc5d\u00b9\ud835\udc66\u00bashould have high entropy due to the diversity among the samples.\nIt is de\ufb01ned as:\nIS\u00b9\ud835\udc5d\ud835\udc54\u00ba= exp\n\u0010\nE\ud835\udc65\u0018\ud835\udc5d\ud835\udc54 fKL\u00bb\ud835\udc5d\u00b9\ud835\udc66j\ud835\udc65\u00bajj\ud835\udc5d\u00b9\ud835\udc66\u00ba\u00bcg\n\u0011\n(38)\n\n20 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nwhere KL is the Kullback-Leibler divergence. Conversely to the FID, higher IS\nvalues stands for better generated samples. However, IS has some drawbacks since\nit does not consider the true data distribution and, moreover, it is not able to detect\nmode collapse, thus we consider the FID score as main metric and the IS in support\nto it.\n5 Experimental Evaluation\nInordertoevaluatethee\ufb00ectivenessofourproposedapproach,weconductacollec-\ntionofexperimentsontheunsupervisedimagegenerationtask.Wetaketwodatasets\ninto account: the CelebA-HQ [21], which contains 27k images for training and 3k\nimages for testing, and the 102 Oxford Flowers, which contains approximately 7k\nimagesfortrainingandafewlessthen1kimagesfortesting.Wereshapethesamples\nof both the dataset to128 \u0002128 and then test the real-valued SNGAN and the pro-\nposed QSNGAN. We use the Adam optimizer and keep the same hyper-parameters\n\ufb01xed as in [26], i.e., learning rate equal to0\u00950002, and the optimizer parameters\nequalto \ud835\udefd1 = 0\u00950, \ud835\udefd2 = 0\u00959.Wejustvarythenumberofcriticiterations,considering\ntwo experiments with critic iterations equal to 1 and then equal to 5 in order to\nbetterinvestigatethebehaviorofourQSNGAN,whichmayhaveadi\ufb00erentbalance\nbetweengeneratoranddiscriminatornetworkswithrespecttotheSNGAN.Inevery\nexperiment, we \ufb01x the batch size to 64 and we perform 100k training iterations for\nthe CelebA-HQ and 50k for the 102 Oxford Flowers. We have also considered to\nendowtheSNGANandtheQSNGANwithagradientpenalty,asin(13),butwedid\nnot notice any improvement in the experiments, thus meaning that both the SN and\nthe QSN adequately control the discriminator to be Lipschitz continuous.\nThe QSNGAN generator is a quaternion convolutional network as in Fig. 6. The\ninitial fully connected layer, which takes the noise of size 128 in input, is composed\nof 4 \u00024 \u00021024 neurons. The following quaternion residual blocks illustrated in\nFig. 4 stack 1024, 512, 256, 128 and 64 \ufb01lters. This means that, as an example,\nthe \ufb01rst residual block is built by interleaving QBNs, split ReLUs and quaternion\nconvolutions with 1024 kernels and an upsampling module with scale factor equal\nto 2. Further, at the end of the last residual connection, we stack a QBN, a split\nReLU activation function and a \ufb01nal quaternion convolutional layer of dimension\n64tore\ufb01netheoutputimage,whichisthenpassedtoasplitTanhfunctiontobound\nit in the interval\u00bb\u00001\u00961\u00bc. For each quaternion convolution, we \ufb01x the kernel size to\n3 and the stride and the padding to 1. Conversely, the shortcut in the residual block\nis composed of an upsampling module and a quaternion convolution with kernel\nsize equal to 1 and null padding. The network built through this procedure has less\nthan 10M of free parameters with respect to the 32M parameters of its real-valued\ncounterpart. This means that the checkpoint for inference saves more than the70%\nof disk memory, as shown in Table 1.\nThe QSNGAN discriminator is still a quaternion convolutional network as in\nFig. 6, but it is slightly more complex. At the beginning, the real images are en-\n\nQuaternion Generative Adversarial Networks 21\nTable 1 Summary of number of networks parameters and memory requirements for real-valued\nSNGAN and its quaternion-valued counterpart QSNGAN models for CelebA-HQ. The proposed\nmethod saves more than the70% of total free parameters and memory disk for model checkpoints.\nModel #Params G #Params D #Params Tot Disk Memory \u0003\nSNGAN 32,150,787 29,022,213 61,173,000 \u0018115 GB\nQSNGAN 9,631,204 7,264,901 16,896,105 \u001835 GB\n\u0003Generator checkpoint for inference.\ncapsulated in a quaternion as depicted in Subsection 3.3, resulting in a batch of\nfour-channel images. Obviously, the images generated by the generator network are\nalready comprised of four channels and de\ufb01ned as quaternions.\nThe \ufb01rst residual block of the discriminator in Fig. 5 is a spectrally-normalized\nquaternionconvolutionblockwith64 3\u00023 \ufb01ltersandsplitReLUactivationfunctions.\nTheshortcut,instead,asforthegeneratornetwork,isa 1 \u00021 quaternionconvolution\nwith padding equal to 0. In this case, however, both the residual and the shortcut\npart ends with a2 \u00022 split average pooling. The images \ufb02ow then to a stack of\n\ufb01ve residual blocks built as in Fig. 4 with, respectively, 128, 256, 512, 1024 and\n1024 \ufb01lters. Nevertheless, the residual section of each block has a split average\npooling to operate downsampling and the shortcut is comprised of a quaternion\nconvolution and another average pooling. The downsampling procedure is applied\nin each residual block except for the last one, which is a re\ufb01ner and leaves the\ndimensionalityunchanged.EveryweightisnormalizedthroughtheQSNintroduced\ninSubsection3.6.Thecon\ufb01gurationsforkernelsize,strideandpaddingarethesame\nof the generator. At the end of the residual block stack, we apply a split ReLU and a\nglobal sum pooling before passing the batch to the \ufb01nal spectrally-normalized fully\nconnected layer which, by means of a sigmoid, returns the real/fake decision. As\nfor the generator, also the quaternion discriminator allows to save parameters while\nlearningtheinternalrelationsamongchannels.ThissavingisunderlinedinTable1,\nwhich reports the exact number of parameters for the quaternion model and the\nreal-valuedone.ThequaternionGANcanobtainequalorbetterresultswhentrained\nwithlessparameterssinceitleveragesthepropertiesofquaternionalgebra,including\nthe Hamilton product, that allow to capture also the relations among channels and\ncatchmoreinformationontheinput.Consequently,thetrainingprocedureneedsless\nparameters to learn the real distribution and to generate images from it.\nThe objective evaluation is reported in Table 2. We perform the computations of\nFID and IS on the test images (3k for the CelebA-HQ and slightly less than 1k for\nthe 102 Oxford Flowers). As shown in Table 2, the proposed method stands out in\nthegenerationofsamplesfromboththedatasetaccordingtothemetricsconsidered.\nMoreover, the two QSNGANs with critic iterations 1 and 5 score a lower FID\nwith respect to the best con\ufb01guration of the SNGAN model. The proposed method\nperforms better with one critic per generator iterations, while the real-valued model\nfails with this con\ufb01guration. Overall, the QSNGAN seems to be more robust to the\nchoiceofthecriticiterationswithrespecttotheSNGAN,whichismorefragile.The\n\n22 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nTable 2 Results summary for the128 \u0002128 CelebA-HQ and 102 Oxford Flowers datasets. The\nproposed QSNGAN obtains a lower FID in each dataset considered. The vlaues of the IS support\ntheFIDresults.Accordingtotheobjectivemetrics,theproposedQSNGANgeneratesmorevisually\npleasant and diverse samples with respect to the real-valued baseline counterpart. The QSNGAN\nseemstobemorerobusttothechoiceofthehyper-parameterregardingthediscriminatoriterations\n(Critic iter) while the real-valued model fails when changing the original setting which \ufb01xes the\nparameter equal to 5.\nFID # IS \"\nModel Critic iter CelebA-HQ 102 Oxford Flowers CelebA-HQ 102 Oxford Flowers\nSNGAN 1 \u00a1200\u0003 \u00a1200\u0003 \u009f2.000 \u0003 2.797\u00060.196\n5 34.483 165.058 2.032 \u00060.062 2.977\u00060.146\nQSNGAN 1 29.417 175.484 2.249 \u00060.164 2.754\u00060.256\n5 33.068 115.838 2.026\u00060.082 3.000 \u00060.141\n\u0003Discriminator collapses and training fails, thus metrics results are not comparable.\nIS strengthen the results obtained with the FID, as it reports higher scores for the\nproposed method in every dataset.\nThe visual inspection of the generated samples underlines the improved ability\nof our QSNGAN. Figure 7 and Figure 8 show a randomly selected128 \u0002128\nbatch of generated images for the real-valued SNGAN and the proposed QSNGAN,\nrespectively.Ononehand,SNGANseemstobequiteunstableandpronetotheinput\nnoise, thus alternating some good quality images with bad generated ones. Overall,\ntheSNGANisnotalwaysabletodistinguishthebackgroundfromsomepartsofthe\ncharacter, sometimes confusing attributes such as the neck or the hair as part of the\nenvironment, and letting them vanishing. On the other hand, the QSNGAN sample\nin Fig. 8 shows visually pleasant images, with a clear distinction between subject\nand background. It also shows a higher de\ufb01nition of faces attributes, including the\nmostdi\ufb03cultones,suchaseyebrows,beardorskinshades.Inaddition,colorsseem\nto be more vivid and samples are diverse in terms of pose, genre, expression, and\nhair color, among others. Concerning the second dataset, the generated samples for\nthe SNGAN are shown in Fig. 9, while the batch from the QSNGAN is reported\nin Fig. 10. As it is clear from Table 2, the results for this dataset are preliminary\nbut encouraging. Even in this case the proposed approach gains a lower FID and\na higher IS than the real-valued model. Additionally, in SNGAN samples pixels\nare evident and often misleading, thus confusing the \ufb02ower object with the colored\nbackground. On the other hand, the images generated from our QSNGAN contain\nmoredistinctsubjects.Furthermore,theproposedmethodbettercatcheseverycolor\nshadethankstothequaternionalgebraproperties,whichallowthenetworklearning\ninternal relations among channels without losing intra-channel information.\nIn conclusion, the proposed quaternion-valued QSNGAN shows an improved\nability in capturing the real data distribution by leveraging the quaternion algebra\nproperties in each experiment we conduct. It can generate better and more vivid\nsamples according to visual inspections and to objective metrics with respect to its\nreal-valued counterpart. Furthermore, the proposed method has less than the30%\n\nQuaternion Generative Adversarial Networks 23\nFig. 7 Randomlygeneratedsamplesfromthereal-valuedSNGANontheCelebA-HQdatasetafter\n100k training iterations. Sometimes this model fails to detect border attributes such as hair and\nneck which may fade on the background. Indeed, only few samples seem to be visually pleasant\nwhile in some other cases the network fails to generate likable images.\nFig. 8 Randomly generated samples from our QSNGAN on the CelebA-HQ dataset after 100k\ntraining iterations. These images are part of the test samples which gained a FID of 29.417 and IS\n2.249\u00060.164.Theproposedmethodisabletogeneratevisuallypleasantimages,welldistinguishing\nthebackgroundfromtheface.Moreover,wedonotobservemodecollapseassampleshavedi\ufb00erent\nattributes such as genre, hair color, pose and smile, among others.\nof free parameters with respect to the SNGAN which also has worse generation\nperformance.\n\n24 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nFig. 9 Randomly generated samples from the SNGAN model on the 102 Oxford Flowers dataset\nafter 50k training iterations. SNGAN misleads some pixels in the images and depicted objects are\nnot always distinguishable.\nFig. 10 Randomly generated samples from the proposed QSNGAN on the 102 Oxford Flowers\ndataset after 50k training iterations. Flowers contain many di\ufb00erent colors shades and most of the\nobjects are clearly de\ufb01ned. This set of \ufb01gures sow the improved generation ability of our proposed\nmethod with respect to its real-valued counterpart.\n5.1 Evaluation of Spectral Normalization Methods\nThis section reports the tests we conduct to evaluate the two quaternion spectral\nnormalization methods described in Subsection 3.6. In order to investigate the per-\n\nQuaternion Generative Adversarial Networks 25\nformance of the normalizing approaches, we validate two smaller models with re-\nspect to the ones introduced in the previous subsection on the CIFAR10 and STL10\ndatasets.CIFAR10contains50k 32\u000232 imagesfortrainingand10kfortestingwhile\nSTL10 has 105k48 \u000248 images in the train split and 8k in the test one.\nWeexaminethreedi\ufb00erentcon\ufb01gurations:the\ufb01rstonedoesnotinvolveanyQSN\nmethod, thus the discriminator network is not constrained to be 1-Lipscithz. We\nrun this experiment in order to check the e\ufb00ectiveness of the spectral normalization\nmethodsthatwepropose.Thesecondcon\ufb01gurationappliesasplitcomputationofthe\nspectral norm for each quaternion component and normalize each weight submatrix\nW0\u0096 W1\u0096 W2\u0096 W3 independently.Thelastapproachcomputesthespectralnormof\nthe whole weight matrix and uses it to normalize each component. Respectively, we\nrefer to these methods as No QSN, QSN Split and QSN Full.\nTo assess the performance, we build the same SNGANs presented in [26] by\nrede\ufb01ning them in the quaternion domain. We adopt the quaternion core residual\nblocks we de\ufb01ne in the previous section and in Fig. 4, while reducing the model\ndimension.ForCIFAR10,wesetupageneratorwiththeinitiallinearlayer 4\u00024\u0002256\nandthenpileupthreequaternionresidualblocks,eachonewith256\ufb01lters.Asbefore,\nweendupwithastackofQBN,splitReLUandaquaternionconvolutionwitha\ufb01nal\nsplit Tanh to generate the32 \u000232 images in the range\u00bb\u00001\u00961\u00bc. The discriminator, in\nwhich the QSN methods act in each layer, begins with a \ufb01rst residual block (Fig. 5)\nwith128\ufb01ltersandthenproceedswiththreeblockscomposedof128kernels.Asin\nFig. 6, the network ends with a global sum pooling and a fully connected layer with\nsigmoid to output the decision probability. The so-de\ufb01ned QSNGAN for CIFAR10\nis comprised of less than 2M parameters. It is worth noting that the real-valued\ncounterpart presented in [26] has more than 5M of free parameters.\nThemodeltogeneratethe 48 \u000248 STL10imagesisdeeperthanthepreviousone\nand is composed of 5,545,188 parameters. The structure is the same but it contains\naninitiallayerof 6\u00026\u0002512 andthentheresidualblockswith256,128and64\ufb01lters.\nThe \ufb01nal re\ufb01ner quaternion convolutional layers has 64 kernels. The discriminator,\ninstead, has one residual blocks more than the model for CIFAR10 and the \ufb01lters\nare, respectively from the \ufb01rst to the last block, 64, 128, 256, 512, 1024 with a \ufb01nal\n512 fully connected layer with sigmoid.\nAs we can see in Table 3, the unbounded model with no QSN fails in generating\nimages from both CIFAR10 and STL10. Indeed, the FID is much higher than the\nother approaches. This proves the e\ufb00ectiveness of the proposed QSN full method\nwhich computes the spectral norm of each layer taking all the components into\naccount. As a matter of fact, the proposed approach is capable to generate improved\nquality images in every experiment we conduct.\n6 Conclusions\nIn this paper we introduce the family of quaternion-valued GANs (QGANs) that\nleveragesthepropertiesofquaternionalgebra.Wehaverigorouslyde\ufb01nedeachcore\n\n26 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\nTable 3 Summary results for comparison of the two quaternion spectral normalization methods\ndepicted in Section 3. We consider the SNGAN proposed in [26] as baseline to de\ufb01ne two simple\nmodels in the quaternion domain and then test the di\ufb00erent QSN approaches. QSN Split refers\nto the \ufb01rst method that normalizes the submatrices independently while QSN Full stands for the\nnormalization of the whole weight matrix together. No QSN is a model without any spectral\nnormalizationmethod.Whilethelatterfails,theQSNFullgeneratesbetterimagesaccordingtothe\nFID in both datasets.\nFID # IS \"\nCon\ufb01g CIFAR10 STL10 CIFAR10 STL10\nNo QSN 70.312 91.567 4.031 \u00061.327 4.744 \u00060.643\nQSN Split 35.417 75.112 4.7128 \u00061.270 4.455 \u00060.092\nQSN Full 31.966 59.611 4.317 \u00060.951 4.987 \u00060.485\nblockemployedtobuildtheproposedQGANs,includingthequaternionadversarial\nframework. Moreover, we have provided a meticulous experimental evaluation on\ndi\ufb00erent image generation benchmarks to prove the e\ufb00ectiveness of our method.\nWe have shown that the proposed QGAN has an improved generation ability with\nrespect to the real-valued counterpart, according to the FID and IS metrics and to a\nvisualinspection.Moreover,ourmethodsavesuptothe 75% offreeparameters.We\nbelieve that these results lay the foundations for novel deep GANs, thus capturing\nhigherlevelsofinputinformationandbettergraspingtherealdatadistribution,while\nsigni\ufb01cantly reducing the overall number of parameters.\nReferences\n1. Arjovsky,M.,Chintala,S.,Bottou,L.:WassersteinGAN. arXivpreprint:arXiv:1701.07875v3\n(2017)\n2. Brock,A.,Donahue,J.,Simonyan,K.:LargescaleGANtrainingforhigh\ufb01delitynaturalimage\nsynthesis. Int. Conf. on Learning Representations (ICLR) (2019)\n3. Chen, T., Zhai, X., Ritter, M., Lucic, M., Houlsby, N.: Self-supervised GANs via auxiliary\nrotation loss. In: IEEE/CVF Int. Conf. on Computer Vision and Pattern Recognition (CVPR),\npp. 12146\u201312155 (2019)\n4. Cheong Took, C., Mandic, D.P.: Augmented second-order statistics of quaternion random\nsignals. Signal Process.91(2), 214\u2013224 (2011)\n5. Chernov,V.:Discreteorthogonaltransformswithdatarepresentationincompositionalgebras.\nProc. Scandinavian Conf. on Image Analysis pp. 357\u2013364 (1995)\n6. Comminiello, D., Lella, M., Scardapane, S., Uncini, A.: Quaternion convolutional neural\nnetworks for detection and localization of 3D sound events. In: IEEE Int. Conf. on Acoust.,\nSpeech and Signal Process. (ICASSP), pp. 8533\u20138537. Brighton, UK (2019)\n7. Ell, T.A., Sangwine, S.J.: Quaternion involutions and anti-involutions. Comput. Math. Appl.\n53(1), 137\u2013143 (2007)\n8. Gaudet, C., Maida, A.: Deep quaternion networks. In: IEEE Int. Joint Conf. on Neural Netw.\n(\u0132CNN). Rio de Janeiro, Brazil (2018)\n9. Glorot, X., Bengio, Y.: Understanding the di\ufb03culty of training deep feedforward neural net-\nworks. In: Int. Conf. on arti\ufb01cial intelligence and statistics, pp. 249\u2013256 (2010)\n\nQuaternion Generative Adversarial Networks 27\n10. Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville,\nA.,Bengio,Y.:Generativeadversarialnets. In:27thInt.Conf.onNeuralInformationProcess-\ning Systems (NIPS), vol. 2, pp. 2672\u20132680. MIT Press, Cambridge, MA, USA (2014)\n11. Gouk,H.,Frank,E.,Pfahringer,B.,Cree,M.J.:Regularisationofneuralnetworksbyenforcing\nLipschitz continuity. Mach. Learn.110(2), 393\u2013416 (2021)\n12. Grassucci, E., Comminiello, D., Uncini, A.: An information-theoretic perspective on proper\nquaternion variational autoencoders. Entropy23(7) (2021)\n13. Grassucci, E., Comminiello, D., Uncini, A.: A quaternion-valued variational autoencoder. In:\nIEEE Int. Conf. on Acoust., Speech and Signal Process. (ICASSP). Toronto, Canada (2021)\n14. Grassucci, E., Scardapane, S., Comminiello, D., Uncini, A.: Flexible generative adversarial\nnetworks with non-parametric activation functions. In: Progress in Arti\ufb01cial Intelligence and\nNeural Systems, vol. 184. Smart Innovation, Systems and Technologies, Springer (2021)\n15. Gui, J., Sun, Z., Wen, Y., Tao, D., Ye, J.p.: A review on generative adversarial networks:\nAlgorithms, theory, and applications. arXiv preprint: arXiv:2001.06937v1 (2020)\n16. Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A.C.: Improved training of\nWasserstein GANs. In: Advances in Neural Information Processing Systems (NIPS) (2017)\n17. He, K., Zhang, X., Ren, S., Sun, J.: Delving deep into recti\ufb01ers: Surpassing human-level\nperformance on imagenet classi\ufb01cation. In: IEEE/CVF Int. Conf. on Computer Vision and\nPattern Recognition (CVPR), pp. 1026\u20131034 (2015)\n18. Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Hochreiter, S.: GANs trained by a two\ntime-scaleupdateruleconvergetoalocalNashequilibrium. In:NeuralInformationProcessing\nSystems (NIPS), pp. 6626\u20136637 (2017)\n19. Ho\ufb00mann,J.,Schmitt,S.,Osindero,S.,Simonyan,K.,Elsen,E.:AlgebraNets. arXivpreprint:\narXiv:2006.07360v2 (2020)\n20. Io\ufb00e, S., Szegedy, C.: Batch normalization: Accelerating deep network training by reducing\ninternal covariate shift. In: Int. Conf. on Machine Learning (ICML), p. 448\u2013456. JMLR.org\n(2015)\n21. Karras,T.,Aila,T.,Laine,S.,Lehtinen,J.:ProgressivegrowingofGANsforimprovedquality,\nstability, and variation. In: Int. Conf. on Learning Representations (ICLR) (2018)\n22. Karras, T., Laine, S., Aila, T.: A style-based generator architecture for generative adversarial\nnetworks.In:IEEEConf.onComputerVisionandPatternRecognition,CVPR,pp.4401\u20134410.\nComputer Vision Foundation / IEEE (2019)\n23. Karras, T., Laine, S., Aittala, M., Hellsten, J., Lehtinen, J., Aila, T.: Analyzing and improving\nthe image quality of stylegan. In: 2020 IEEE/CVF Conf. on Computer Vision and Pattern\nRecognition (CVPR), pp. 8107\u20138116. IEEE (2020)\n24. Kingma, D.P., Welling, M.: Auto-encoding variational Bayes. arXiv Preprint:\narXiv:1312.6114v10 pp. 1\u201314 (2014)\n25. Kurach,K.,Lucic,M.,Zhai,X.,Michalski,M.,Gelly,S.:Alarge-scalestudyonregularization\nand normalization in GANs. In: Int. Conf. on Machine Learning (ICML) (2019)\n26. Miyato, T., Kataoka, T., Koyama, M., Yoshida, Y.: Spectral normalization for generative\nadversarial networks. arXiv preprint: arXiv:1802.05957v1 (2018)\n27. Parcollet, T., Morchid, M., Linar\u00e8s, G.: Quaternion convolutional neural networks for het-\nerogeneous image processing. In: IEEE Int. Conf. on Acoust., Speech and Signal Process.\n(ICASSP), pp. 8514\u20138518. Brighton, UK (2019)\n28. Parcollet, T., Morchid, M., Linar\u00e8s, G.: A survey of quaternion neural networks. Artif. Intell.\nRev. (2019)\n29. Parcollet, T., Ravanelli, M., Morchid, M., Linar\u00e8s, G., Trabelsi, C., De Mori, R., Bengio, Y.:\nQuaternionrecurrentneuralnetworks. In:Int.Conf.onLearningRepresentations(ICLR),pp.\n1\u201319. New Orleans, LA (2019)\n30. Radford, A., Metz, L., Chintala, S.: Unsupervised representation learning with deep convolu-\ntional generative adversarial networks. arXiv preprint: arXiv:1511.06434v2 (2016)\n31. Salimans, T., Goodfellow, I.J., Zaremba, W., Cheung, V., Radford, A., Chen, X.: Improved\ntechniques for training GANs. In: Neural Information Processing Systems (NIPS), pp. 2234\u2013\n2242 (2016)\n\n28 Eleonora Grassucci, Edoardo Cicero and Danilo Comminiello\n32. Schmidhuber, J.: A possibility for implementing curiosity and boredom in model-building\nneural controllers. In: Proc. of the First Int. Conf. on Simulation of Adaptive Behavior on\nFrom Animals to Animats, pp. 222\u2014-227. MIT Press, Cambridge, MA, USA (1991)\n33. Schmidhuber,J.:Generativeadversarialnetworksarespecialcasesofarti\ufb01cialcuriosity(1990)\nand also closely related to predictability minimization (1991). Neural Networks127, 58\u201366\n(2020)\n34. Sch\u00f6nfeld,E.,Schiele,B.,Khoreva,A.:AU-Netbaseddiscriminatorforgenerativeadversarial\nnetworks. In: IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR), pp.\n8207\u20138216 (2020)\n35. S\ufb01kas, G., Giotis, A.P., Retsinas, G., Nikou, C.: Quaternion generative adversarial networks\nforinscriptiondetectioninbyzantinemonuments. In:PatternRecognition.ICPRInternational\nWorkshops and Challenges, pp. 171\u2013184. Springer International Publishing (2021)\n36. Vecchi,R.,Scardapane,S.,Comminiello,D.,Uncini,A.:Compressingdeep-quaternionneural\nnetworks with targeted regularisation. CAAI Trans. Intell. Technol.5(3), 172\u2013176 (2020)\n37. V\u00eca,J.,Ram\u00ecrez,D.,Santamar\u00eca,I.:Properandwidelylinearprocessingofquaternionrandom\nvectors. IEEE Trans. Inf. Theory56(7), 3502\u20133515 (2010)\n38. Ward, J.P.: Quaternions and Caley Numbers. Algebra ans Applications,Mathematics and Its\nApplications, vol. 403. Kluwer Academic Publishers (1997)\n39. Yin,Q.,Wang,J.,Luo,X.,Zhai,J.,Jha,S.K.,Shi,Y.:Quaternionconvolutionalneuralnetwork\nfor color image classi\ufb01cation and forensics. IEEE Access7, 20293\u201320301 (2019)\n40. Zhang, H., Goodfellow, I.J., Metaxas, D.N., Odena, A.: Self-attention generative adversarial\nnetworks. In: Int. Conf. on Machine Learning (ICML),Proceedings of Machine Learning\nResearch, vol. 97, pp. 7354\u20137363. PMLR (2019)\n41. Zhang,H.,Zhang,Z.,Odena,A.,Lee,H.:Consistencyregularizationforgenerativeadversarial\nnetworks. In: Int. Conf. on Machine Learning (ICML) (2020)\n42. Zhou, Z., Liang, J., Song, Y., Yu, L., Wang, H., Zhang, W., Yu, Y., Zhang, Z.: Lipschitz\ngenerative adversarial nets. In: Int. Conf. on Machine Learning (ICML),Proceedings of\nMachine Learning Research, vol. 97, pp. 7584\u20137593. PMLR (2019)",
  "full_text_length": 66417,
  "link_pdf": "https://arxiv.org/pdf/2104.09630v2",
  "paper_id": "2104.09630v2"
}