{
  "source": "wikipedia",
  "query": "Cycle GAN",
  "fetched_at": "2025-11-21T18:01:54.365600",
  "title": "Generative adversarial network",
  "url": "https://en.wikipedia.org/wiki/Generative_adversarial_network",
  "content": "A generative adversarial network (GAN) is a class of machine learning frameworks and a prominent framework for approaching generative artificial intelligence. The concept was initially developed by Ian Goodfellow and his colleagues in June 2014. In a GAN, two neural networks compete with each other in the form of a zero-sum game, where one agent's gain is another agent's loss.\nGiven a training set, this technique learns to generate new data with the same statistics as the training set. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics. Though originally proposed as a form of generative model for unsupervised learning, GANs have also proved useful for semi-supervised learning, fully supervised learning, and reinforcement learning.\nThe core idea of a GAN is based on the \"indirect\" training through the discriminator, another neural network that can tell how \"realistic\" the input seems, which itself is also being updated dynamically. This means that the generator is not trained to minimize the distance to a specific image, but rather to fool the discriminator. This enables the model to learn in an unsupervised manner.\nGANs are similar to mimicry in evolutionary biology, with an evolutionary arms race between both networks.\n\n\n== Definition ==\n\n\n=== Mathematical ===\nThe original GAN is defined as the following game:\nEach probability space \n  \n    \n      \n        (\n        \u03a9\n        ,\n        \n          \u03bc\n          \n            ref\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega ,\\mu _{\\text{ref}})}\n  \n defines a GAN game.\nThere are 2 players: generator and discriminator.\nThe generator's strategy set is \n  \n    \n      \n        \n          \n            P\n          \n        \n        (\n        \u03a9\n        )\n      \n    \n    {\\displaystyle {\\mathcal {P}}(\\Omega )}\n  \n, the set of all probability measures \n  \n    \n      \n        \n          \u03bc\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n on \n  \n    \n      \n        \u03a9\n      \n    \n    {\\displaystyle \\Omega }\n  \n.\nThe discriminator's strategy set is the set of Markov kernels \n  \n    \n      \n        \n          \u03bc\n          \n            D\n          \n        \n        :\n        \u03a9\n        \u2192\n        \n          \n            P\n          \n        \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle \\mu _{D}:\\Omega \\to {\\mathcal {P}}[0,1]}\n  \n, where \n  \n    \n      \n        \n          \n            P\n          \n        \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle {\\mathcal {P}}[0,1]}\n  \n is the set of probability measures on \n  \n    \n      \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle [0,1]}\n  \n.\nThe GAN game is a zero-sum game, with objective function\n  \n    \n      \n        L\n        (\n        \n          \u03bc\n          \n            G\n          \n        \n        ,\n        \n          \u03bc\n          \n            D\n          \n        \n        )\n        :=\n        \n          E\n          \n            x\n            \u223c\n            \n              \u03bc\n              \n                ref\n              \n            \n            ,\n            y\n            \u223c\n            \n              \u03bc\n              \n                D\n              \n            \n            (\n            x\n            )\n          \n        \n        \u2061\n        [\n        ln\n        \u2061\n        y\n        ]\n        +\n        \n          E\n          \n            x\n            \u223c\n            \n              \u03bc\n              \n                G\n              \n            \n            ,\n            y\n            \u223c\n            \n              \u03bc\n              \n                D\n              \n            \n            (\n            x\n            )\n          \n        \n        \u2061\n        [\n        ln\n        \u2061\n        (\n        1\n        \u2212\n        y\n        )\n        ]\n        .\n      \n    \n    {\\displaystyle L(\\mu _{G},\\mu _{D}):=\\operatorname {E} _{x\\sim \\mu _{\\text{ref}},y\\sim \\mu _{D}(x)}[\\ln y]+\\operatorname {E} _{x\\sim \\mu _{G},y\\sim \\mu _{D}(x)}[\\ln(1-y)].}\n  \n\nThe generator aims to minimize the objective, and the discriminator aims to maximize the objective.\n\nThe generator's task is to approach \n  \n    \n      \n        \n          \u03bc\n          \n            G\n          \n        \n        \u2248\n        \n          \u03bc\n          \n            ref\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}\\approx \\mu _{\\text{ref}}}\n  \n, that is, to match its own output distribution as closely as possible to the reference distribution. The discriminator's task is to output a value close to 1 when the input appears to be from the reference distribution, and to output a value close to 0 when the input looks like it came from the generator distribution.\n\n\n=== In practice ===\nThe generative network generates candidates while the discriminative network evaluates them. This creates a contest based on data distributions, where the generator learns to map from a latent space to the true data distribution, aiming to produce candidates that the discriminator cannot distinguish from real data. The discriminator's goal is to correctly identify these candidates, but as the generator improves, its task becomes more challenging, increasing the discriminator's error rate.\nA known dataset serves as the initial training data for the discriminator. Training involves presenting it with samples from the training dataset until it achieves acceptable accuracy. The generator is trained based on whether it succeeds in fooling the discriminator. Typically, the generator is seeded with randomized input that is sampled from a predefined latent space (e.g. a multivariate normal distribution). Thereafter, candidates synthesized by the generator are evaluated by the discriminator. Independent backpropagation procedures are applied to both networks so that the generator produces better samples, while the discriminator becomes more skilled at flagging synthetic samples. When used for image generation, the generator is typically a deconvolutional neural network, and the discriminator is a convolutional neural network.\n\n\n=== Relation to other statistical machine learning methods ===\nGANs are implicit generative models, which means that they do not explicitly model the likelihood function nor provide a means for finding the latent variable corresponding to a given sample, unlike alternatives such as flow-based generative model.\n\nCompared to fully visible belief networks such as WaveNet and PixelRNN and autoregressive models in general, GANs can generate one complete sample in one pass, rather than multiple passes through the network.\nCompared to Boltzmann machines and linear ICA, there is no restriction on the type of function used by the network.\nSince neural networks are universal approximators, GANs are asymptotically consistent. Variational autoencoders might be universal approximators, but it is not proven as of 2017.\n\n\n== Mathematical properties ==\n\n\n=== Measure-theoretic considerations ===\nThis section provides some of the mathematical theory behind these methods.\n\nIn modern probability theory based on measure theory, a probability space also needs to be equipped with a \u03c3-algebra. As a result, a more rigorous definition of the GAN game would make the following changes:Each probability space \n  \n    \n      \n        (\n        \u03a9\n        ,\n        \n          \n            B\n          \n        \n        ,\n        \n          \u03bc\n          \n            ref\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega ,{\\mathcal {B}},\\mu _{\\text{ref}})}\n  \n defines a GAN game.\nThe generator's strategy set is \n  \n    \n      \n        \n          \n            P\n          \n        \n        (\n        \u03a9\n        ,\n        \n          \n            B\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\mathcal {P}}(\\Omega ,{\\mathcal {B}})}\n  \n, the set of all probability measures \n  \n    \n      \n        \n          \u03bc\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n on the measure-space \n  \n    \n      \n        (\n        \u03a9\n        ,\n        \n          \n            B\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega ,{\\mathcal {B}})}\n  \n.\n\nThe discriminator's strategy set is the set of Markov kernels \n  \n    \n      \n        \n          \u03bc\n          \n            D\n          \n        \n        :\n        (\n        \u03a9\n        ,\n        \n          \n            B\n          \n        \n        )\n        \u2192\n        \n          \n            P\n          \n        \n        (\n        [\n        0\n        ,\n        1\n        ]\n        ,\n        \n          \n            B\n          \n        \n        (\n        [\n        0\n        ,\n        1\n        ]\n        )\n        )\n      \n    \n    {\\displaystyle \\mu _{D}:(\\Omega ,{\\mathcal {B}})\\to {\\mathcal {P}}([0,1],{\\mathcal {B}}([0,1]))}\n  \n, where \n  \n    \n      \n        \n          \n            B\n          \n        \n        (\n        [\n        0\n        ,\n        1\n        ]\n        )\n      \n    \n    {\\displaystyle {\\mathcal {B}}([0,1])}\n  \n is the Borel \u03c3-algebra on \n  \n    \n      \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle [0,1]}\n  \n.Since issues of measurability never arise in practice, these will not concern us further.\n\n\n=== Choice of the strategy set ===\nIn the most generic version of the GAN game described above, the strategy set for the discriminator contains all Markov kernels \n  \n    \n      \n        \n          \u03bc\n          \n            D\n          \n        \n        :\n        \u03a9\n        \u2192\n        \n          \n            P\n          \n        \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle \\mu _{D}:\\Omega \\to {\\mathcal {P}}[0,1]}\n  \n, and the strategy set for the generator contains arbitrary probability distributions \n  \n    \n      \n        \n          \u03bc\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n on \n  \n    \n      \n        \u03a9\n      \n    \n    {\\displaystyle \\Omega }\n  \n.\nHowever, as shown below, the optimal discriminator strategy against any \n  \n    \n      \n        \n          \u03bc\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n is deterministic, so there is no loss of generality in restricting the discriminator's strategies to deterministic functions \n  \n    \n      \n        D\n        :\n        \u03a9\n        \u2192\n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle D:\\Omega \\to [0,1]}\n  \n. In most applications, \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n is a deep neural network function.\nAs for the generator, while \n  \n    \n      \n        \n          \u03bc\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n could theoretically be any computable probability distribution, in practice, it is usually implemented as a pushforward: \n  \n    \n      \n        \n          \u03bc\n          \n            G\n          \n        \n        =\n        \n          \u03bc\n          \n            Z\n          \n        \n        \u2218\n        \n          G\n          \n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}=\\mu _{Z}\\circ G^{-1}}\n  \n. That is, start with a random variable \n  \n    \n      \n        z\n        \u223c\n        \n          \u03bc\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle z\\sim \\mu _{Z}}\n  \n, where \n  \n    \n      \n        \n          \u03bc\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\mu _{Z}}\n  \n is a probability distribution that is easy to compute (such as the uniform distribution, or the Gaussian distribution), then define a function \n  \n    \n      \n        G\n        :\n        \n          \u03a9\n          \n            Z\n          \n        \n        \u2192\n        \u03a9\n      \n    \n    {\\displaystyle G:\\Omega _{Z}\\to \\Omega }\n  \n. Then the distribution \n  \n    \n      \n        \n          \u03bc\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n is the distribution of \n  \n    \n      \n        G\n        (\n        z\n        )\n      \n    \n    {\\displaystyle G(z)}\n  \n.\nConsequently, the generator's strategy is usually defined as just \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n, leaving \n  \n    \n      \n        z\n        \u223c\n        \n          \u03bc\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle z\\sim \\mu _{Z}}\n  \n implicit. In this formalism, the GAN game objective is\n  \n    \n      \n        L\n        (\n        G\n        ,\n        D\n        )\n        :=\n        \n          E\n          \n            x\n            \u223c\n            \n              \u03bc\n              \n                ref\n              \n            \n          \n        \n        \u2061\n        [\n        ln\n        \u2061\n        D\n        (\n        x\n        )\n        ]\n        +\n        \n          E\n          \n            z\n            \u223c\n            \n              \u03bc\n              \n                Z\n              \n            \n          \n        \n        \u2061\n        [\n        ln\n        \u2061\n        (\n        1\n        \u2212\n        D\n        (\n        G\n        (\n        z\n        )\n        )\n        )\n        ]\n        .\n      \n    \n    {\\displaystyle L(G,D):=\\operatorname {E} _{x\\sim \\mu _{\\text{ref}}}[\\ln D(x)]+\\operatorname {E} _{z\\sim \\mu _{Z}}[\\ln(1-D(G(z)))].}\n  \n\n\n=== Generative reparametrization ===\nThe GAN architecture has two main components. One is casting optimization into a game, of form \n  \n    \n      \n        \n          min\n          \n            G\n          \n        \n        \n          max\n          \n            D\n          \n        \n        L\n        (\n        G\n        ,\n        D\n        )\n      \n    \n    {\\displaystyle \\min _{G}\\max _{D}L(G,D)}\n  \n, which is different from the usual kind of optimization, of form \n  \n    \n      \n        \n          min\n          \n            \u03b8\n          \n        \n        L\n        (\n        \u03b8\n        )\n      \n    \n    {\\displaystyle \\min _{\\theta }L(\\theta )}\n  \n. The other is the decomposition of \n  \n    \n      \n        \n          \u03bc\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n into \n  \n    \n      \n        \n          \u03bc\n          \n            Z\n          \n        \n        \u2218\n        \n          G\n          \n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle \\mu _{Z}\\circ G^{-1}}\n  \n, which can be understood as a reparametrization trick.\nTo see its significance, one must compare GAN with previous methods for learning generative models, which were plagued with \"intractable probabilistic computations that arise in maximum likelihood estimation and related strategies\".\nAt the same time, Kingma and Welling and Rezende et al. developed the same idea of reparametrization into a general stochastic backpropagation method. Among its first applications was the variational autoencoder.\n\n\n=== Move order and strategic equilibria ===\nIn the original paper, as well as most subsequent papers, it is usually assumed that the generator moves first, and the discriminator moves second, thus giving the following minimax game:\n  \n    \n      \n        \n          min\n          \n            \n              \u03bc\n              \n                G\n              \n            \n          \n        \n        \n          max\n          \n            \n              \u03bc\n              \n                D\n              \n            \n          \n        \n        L\n        (\n        \n          \u03bc\n          \n            G\n          \n        \n        ,\n        \n          \u03bc\n          \n            D\n          \n        \n        )\n        :=\n        \n          E\n          \n            x\n            \u223c\n            \n              \u03bc\n              \n                ref\n              \n            \n            ,\n            y\n            \u223c\n            \n              \u03bc\n              \n                D\n              \n            \n            (\n            x\n            )\n          \n        \n        \u2061\n        [\n        ln\n        \u2061\n        y\n        ]\n        +\n        \n          E\n          \n            x\n            \u223c\n            \n              \u03bc\n              \n                G\n              \n            \n            ,\n            y\n            \u223c\n            \n              \u03bc\n              \n                D\n              \n            \n            (\n            x\n            )\n          \n        \n        \u2061\n        [\n        ln\n        \u2061\n        (\n        1\n        \u2212\n        y\n        )\n        ]\n        .\n      \n    \n    {\\displaystyle \\min _{\\mu _{G}}\\max _{\\mu _{D}}L(\\mu _{G},\\mu _{D}):=\\operatorname {E} _{x\\sim \\mu _{\\text{ref}},y\\sim \\mu _{D}(x)}[\\ln y]+\\operatorname {E} _{x\\sim \\mu _{G},y\\sim \\mu _{D}(x)}[\\ln(1-y)].}\n  \n\nIf both the generator's and the discriminator's strategy sets are spanned by a finite number of strategies, then by the minimax theorem,\n  \n    \n      \n        \n          min\n          \n            \n              \u03bc\n              \n                G\n              \n            \n          \n        \n        \n          max\n          \n            \n              \u03bc\n              \n                D\n              \n            \n          \n        \n        L\n        (\n        \n          \u03bc\n          \n            G\n          \n        \n        ,\n        \n          \u03bc\n          \n            D\n          \n        \n        )\n        =\n        \n          max\n          \n            \n              \u03bc\n              \n                D\n              \n            \n          \n        \n        \n          min\n          \n            \n              \u03bc\n              \n                G\n              \n            \n          \n        \n        L\n        (\n        \n          \u03bc\n          \n            G\n          \n        \n        ,\n        \n          \u03bc\n          \n            D\n          \n        \n        )\n      \n    \n    {\\displaystyle \\min _{\\mu _{G}}\\max _{\\mu _{D}}L(\\mu _{G},\\mu _{D})=\\max _{\\mu _{D}}\\min _{\\mu _{G}}L(\\mu _{G},\\mu _{D})}\n  \nthat is, the move order does not matter.\nHowever, since the strategy sets are both not finitely spanned, the minimax theorem does not apply, and the idea of an \"equilibrium\" becomes delicate. To wit, there are the following different concepts of equilibrium:\n\nEquilibrium when generator moves first, and discriminator moves second:\n  \n    \n      \n        \n          \n            \n              \n                \u03bc\n                ^\n              \n            \n          \n          \n            G\n          \n        \n        \u2208\n        arg\n        \u2061\n        \n          min\n          \n            \n              \u03bc\n              \n                G\n              \n            \n          \n        \n        \n          max\n          \n            \n              \u03bc\n              \n                D\n              \n            \n          \n        \n        L\n        (\n        \n          \u03bc\n          \n            G\n          \n        \n        ,\n        \n          \u03bc\n          \n            D\n          \n        \n        )\n        ,\n        \n        \n          \n            \n              \n                \u03bc\n                ^\n              \n            \n          \n          \n            D\n          \n        \n        \u2208\n        arg\n        \u2061\n        \n          max\n          \n            \n              \u03bc\n              \n                D\n              \n            \n          \n        \n        L\n        (\n        \n          \n            \n              \n                \u03bc\n                ^\n              \n            \n          \n          \n            G\n          \n        \n        ,\n        \n          \u03bc\n          \n            D\n          \n        \n        )\n        ,\n        \n      \n    \n    {\\displaystyle {\\hat {\\mu }}_{G}\\in \\arg \\min _{\\mu _{G}}\\max _{\\mu _{D}}L(\\mu _{G},\\mu _{D}),\\quad {\\hat {\\mu }}_{D}\\in \\arg \\max _{\\mu _{D}}L({\\hat {\\mu }}_{G},\\mu _{D}),\\quad }\n  \n\nEquilibrium when discriminator moves first, and generator moves second:\n  \n    \n      \n        \n          \n            \n              \n                \u03bc\n                ^\n              \n            \n          \n          \n            D\n          \n        \n        \u2208\n        arg\n        \u2061\n        \n          max\n          \n            \n              \u03bc\n              \n                D\n              \n            \n          \n        \n        \n          min\n          \n            \n              \u03bc\n              \n                G\n              \n            \n          \n        \n        L\n        (\n        \n          \u03bc\n          \n            G\n          \n        \n        ,\n        \n          \u03bc\n          \n            D\n          \n        \n        )\n        ,\n        \n        \n          \n            \n              \n                \u03bc\n                ^\n              \n            \n          \n          \n            G\n          \n        \n        \u2208\n        arg\n        \u2061\n        \n          min\n          \n            \n              \u03bc\n              \n                G\n              \n            \n          \n        \n        L\n        (\n        \n          \u03bc\n          \n            G\n          \n        \n        ,\n        \n          \n            \n              \n                \u03bc\n                ^\n              \n            \n          \n          \n            D\n          \n        \n        )\n        ,\n      \n    \n    {\\displaystyle {\\hat {\\mu }}_{D}\\in \\arg \\max _{\\mu _{D}}\\min _{\\mu _{G}}L(\\mu _{G},\\mu _{D}),\\quad {\\hat {\\mu }}_{G}\\in \\arg \\min _{\\mu _{G}}L(\\mu _{G},{\\hat {\\mu }}_{D}),}\n  \n\nNash equilibrium \n  \n    \n      \n        (\n        \n          \n            \n              \n                \u03bc\n                ^\n              \n            \n          \n          \n            D\n          \n        \n        ,\n        \n          \n            \n              \n                \u03bc\n                ^\n              \n            \n          \n          \n            G\n          \n        \n        )\n      \n    \n    {\\displaystyle ({\\hat {\\mu }}_{D},{\\hat {\\mu }}_{G})}\n  \n, which is stable under simultaneous move order:\n  \n    \n      \n        \n          \n            \n              \n                \u03bc\n                ^\n              \n            \n          \n          \n            D\n          \n        \n        \u2208\n        arg\n        \u2061\n        \n          max\n          \n            \n              \u03bc\n              \n                D\n              \n            \n          \n        \n        L\n        (\n        \n          \n            \n              \n                \u03bc\n                ^\n              \n            \n          \n          \n            G\n          \n        \n        ,\n        \n          \u03bc\n          \n            D\n          \n        \n        )\n        ,\n        \n        \n          \n            \n              \n                \u03bc\n                ^\n              \n            \n          \n          \n            G\n          \n        \n        \u2208\n        arg\n        \u2061\n        \n          min\n          \n            \n              \u03bc\n              \n                G\n              \n            \n          \n        \n        L\n        (\n        \n          \u03bc\n          \n            G\n          \n        \n        ,\n        \n          \n            \n              \n                \u03bc\n                ^\n              \n            \n          \n          \n            D\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\hat {\\mu }}_{D}\\in \\arg \\max _{\\mu _{D}}L({\\hat {\\mu }}_{G},\\mu _{D}),\\quad {\\hat {\\mu }}_{G}\\in \\arg \\min _{\\mu _{G}}L(\\mu _{G},{\\hat {\\mu }}_{D})}\n  \n\nFor general games, these equilibria do not have to agree, or even to exist. For the original GAN game, these equilibria all exist, and are all equal. However, for more general GAN games, these do not necessarily exist, or agree.\n\n\n=== Main theorems for GAN game ===\nThe original GAN paper proved the following two theorems:\nInterpretation: For any fixed generator strategy \n  \n    \n      \n        \n          \u03bc\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n, the optimal discriminator keeps track of the likelihood ratio between the reference distribution and the generator distribution:\n  \n    \n      \n        \n          \n            \n              D\n              (\n              x\n              )\n            \n            \n              1\n              \u2212\n              D\n              (\n              x\n              )\n            \n          \n        \n        =\n        \n          \n            \n              d\n              \n                \u03bc\n                \n                  ref\n                \n              \n            \n            \n              d\n              \n                \u03bc\n                \n                  G\n                \n              \n            \n          \n        \n        (\n        x\n        )\n        =\n        \n          \n            \n              \n                \u03bc\n                \n                  ref\n                \n              \n              (\n              d\n              x\n              )\n            \n            \n              \n                \u03bc\n                \n                  G\n                \n              \n              (\n              d\n              x\n              )\n            \n          \n        \n        ;\n        \n        D\n        (\n        x\n        )\n        =\n        \u03c3\n        (\n        ln\n        \u2061\n        \n          \u03bc\n          \n            ref\n          \n        \n        (\n        d\n        x\n        )\n        \u2212\n        ln\n        \u2061\n        \n          \u03bc\n          \n            G\n          \n        \n        (\n        d\n        x\n        )\n        )\n      \n    \n    {\\displaystyle {\\frac {D(x)}{1-D(x)}}={\\frac {d\\mu _{\\text{ref}}}{d\\mu _{G}}}(x)={\\frac {\\mu _{\\text{ref}}(dx)}{\\mu _{G}(dx)}};\\quad D(x)=\\sigma (\\ln \\mu _{\\text{ref}}(dx)-\\ln \\mu _{G}(dx))}\n  \nwhere \n  \n    \n      \n        \u03c3\n      \n    \n    {\\displaystyle \\sigma }\n  \n is the logistic function.\nIn particular, if the prior probability for an image \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n to come from the reference distribution is equal to \n  \n    \n      \n        \n          \n            1\n            2\n          \n        \n      \n    \n    {\\displaystyle {\\frac {1}{2}}}\n  \n, then \n  \n    \n      \n        D\n        (\n        x\n        )\n      \n    \n    {\\displaystyle D(x)}\n  \n is just the posterior probability that \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n came from the reference distribution:\n  \n    \n      \n        D\n        (\n        x\n        )\n        =\n        Pr\n        (\n        x\n        \n           came from reference distribution\n        \n        \u2223\n        x\n        )\n        .\n      \n    \n    {\\displaystyle D(x)=\\Pr(x{\\text{ came from reference distribution}}\\mid x).}\n  \n\n\n== Training and evaluating GAN ==\n\n\n=== Training ===\n\n\n==== Unstable convergence ====\nWhile the GAN game has a unique global equilibrium point when both the generator and discriminator have access to their entire strategy sets, the equilibrium is no longer guaranteed when they have a restricted strategy set.\nIn practice, the generator has access only to measures of form \n  \n    \n      \n        \n          \u03bc\n          \n            Z\n          \n        \n        \u2218\n        \n          G\n          \n            \u03b8\n          \n          \n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle \\mu _{Z}\\circ G_{\\theta }^{-1}}\n  \n, where \n  \n    \n      \n        \n          G\n          \n            \u03b8\n          \n        \n      \n    \n    {\\displaystyle G_{\\theta }}\n  \n is a function computed by a neural network with parameters \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n  \n, and \n  \n    \n      \n        \n          \u03bc\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\mu _{Z}}\n  \n is an easily sampled distribution, such as the uniform or normal distribution. Similarly, the discriminator has access only to functions of form \n  \n    \n      \n        \n          D\n          \n            \u03b6\n          \n        \n      \n    \n    {\\displaystyle D_{\\zeta }}\n  \n, a function computed by a neural network with parameters \n  \n    \n      \n        \u03b6\n      \n    \n    {\\displaystyle \\zeta }\n  \n. These restricted strategy sets take up a vanishingly small proportion of their entire strategy sets.\nFurther, even if an equilibrium still exists, it can only be found by searching in the high-dimensional space of all possible neural network functions. The standard strategy of using gradient descent to find the equilibrium often does not work for GAN, and often the game \"collapses\" into one of several failure modes. To improve the convergence stability, some training strategies start with an easier task, such as generating low-resolution images or simple images (one object with uniform background), and gradually increase the difficulty of the task during training. This essentially translates to applying a curriculum learning scheme.\n\n\n==== Mode collapse ====\n\nGANs often suffer from mode collapse where they fail to generalize properly, missing entire modes from the input data. For example, a GAN trained on the MNIST dataset containing many samples of each digit might only generate pictures of digit 0. This was termed \"the Helvetica scenario\".\nOne way this can happen is if the generator learns too fast compared to the discriminator. If the discriminator \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n is held constant, then the optimal generator would only output elements of \n  \n    \n      \n        arg\n        \u2061\n        \n          max\n          \n            x\n          \n        \n        D\n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\arg \\max _{x}D(x)}\n  \n. So for example, if during GAN training for generating MNIST dataset, for a few epochs, the discriminator somehow prefers the digit 0 slightly more than other digits, the generator may seize the opportunity to generate only digit 0, then be unable to escape the local minimum after the discriminator improves.\nSome researchers perceive the root problem to be a weak discriminative network that fails to notice the pattern of omission, while others assign blame to a bad choice of objective function. Many solutions have been proposed, but it is still an open problem.\nEven the state-of-the-art architecture, BigGAN (2019), could not avoid mode collapse. The authors resorted to \"allowing collapse to occur at the later stages of training, by which time a model is sufficiently trained to achieve good results\".\n\n\n==== Two time-scale update rule ====\nThe two time-scale update rule (TTUR) is proposed to make GAN convergence more stable by making the learning rate of the generator lower than that of the discriminator. The authors argued that the generator should move slower than the discriminator, so that it does not \"drive the discriminator steadily into new regions without capturing its gathered information\".\nThey proved that a general class of games that included the GAN game, when trained under TTUR, \"converges under mild assumptions to a stationary local Nash equilibrium\".\nThey also proposed using the Adam stochastic optimization to avoid mode collapse, as well as the Fr\u00e9chet inception distance for evaluating GAN performances.\n\n\n==== Vanishing gradient ====\nConversely, if the discriminator learns too fast compared to the generator, then the discriminator could almost perfectly distinguish \n  \n    \n      \n        \n          \u03bc\n          \n            \n              G\n              \n                \u03b8\n              \n            \n          \n        \n        ,\n        \n          \u03bc\n          \n            ref\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G_{\\theta }},\\mu _{\\text{ref}}}\n  \n. In such case, the generator \n  \n    \n      \n        \n          G\n          \n            \u03b8\n          \n        \n      \n    \n    {\\displaystyle G_{\\theta }}\n  \n could be stuck with a very high loss no matter which direction it changes its \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n  \n, meaning that the gradient \n  \n    \n      \n        \n          \u2207\n          \n            \u03b8\n          \n        \n        L\n        (\n        \n          G\n          \n            \u03b8\n          \n        \n        ,\n        \n          D\n          \n            \u03b6\n          \n        \n        )\n      \n    \n    {\\displaystyle \\nabla _{\\theta }L(G_{\\theta },D_{\\zeta })}\n  \n would be close to zero. In such case, the generator cannot learn, a case of the vanishing gradient problem.\nIntuitively speaking, the discriminator is too good, and since the generator cannot take any small step (only small steps are considered in gradient descent) to improve its payoff, it does not even try.\nOne important method for solving this problem is the Wasserstein GAN.\n\n\n=== Evaluation ===\nGANs are usually evaluated by Inception score (IS), which measures how varied the generator's outputs are (as classified by an image classifier, usually Inception-v3), or Fr\u00e9chet inception distance (FID), which measures how similar the generator's outputs are to a reference set (as classified by a learned image featurizer, such as Inception-v3 without its final layer). Many papers that propose new GAN architectures for image generation report how their architectures break the state of the art on FID or IS.\nAnother evaluation method is the Learned Perceptual Image Patch Similarity (LPIPS), which starts with a learned image featurizer \n  \n    \n      \n        \n          f\n          \n            \u03b8\n          \n        \n        :\n        \n          Image\n        \n        \u2192\n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle f_{\\theta }:{\\text{Image}}\\to \\mathbb {R} ^{n}}\n  \n, and finetunes it by supervised learning on a set of \n  \n    \n      \n        (\n        x\n        ,\n        \n          x\n          \u2032\n        \n        ,\n        \n          p\n          e\n          r\n          c\n          e\n          p\n          t\n          u\n          a\n          l\n           \n          d\n          i\n          f\n          f\n          e\n          r\n          e\n          n\n          c\n          e\n        \n        \u2061\n        (\n        x\n        ,\n        \n          x\n          \u2032\n        \n        )\n        )\n      \n    \n    {\\displaystyle (x,x',\\operatorname {perceptual~difference} (x,x'))}\n  \n, where \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n is an image, \n  \n    \n      \n        \n          x\n          \u2032\n        \n      \n    \n    {\\displaystyle x'}\n  \n is a perturbed version of it, and \n  \n    \n      \n        \n          p\n          e\n          r\n          c\n          e\n          p\n          t\n          u\n          a\n          l\n           \n          d\n          i\n          f\n          f\n          e\n          r\n          e\n          n\n          c\n          e\n        \n        \u2061\n        (\n        x\n        ,\n        \n          x\n          \u2032\n        \n        )\n      \n    \n    {\\displaystyle \\operatorname {perceptual~difference} (x,x')}\n  \n is how much they differ, as reported by human subjects. The model is finetuned so that it can approximate \n  \n    \n      \n        \u2016\n        \n          f\n          \n            \u03b8\n          \n        \n        (\n        x\n        )\n        \u2212\n        \n          f\n          \n            \u03b8\n          \n        \n        (\n        \n          x\n          \u2032\n        \n        )\n        \u2016\n        \u2248\n        \n          p\n          e\n          r\n          c\n          e\n          p\n          t\n          u\n          a\n          l\n           \n          d\n          i\n          f\n          f\n          e\n          r\n          e\n          n\n          c\n          e\n        \n        \u2061\n        (\n        x\n        ,\n        \n          x\n          \u2032\n        \n        )\n      \n    \n    {\\displaystyle \\|f_{\\theta }(x)-f_{\\theta }(x')\\|\\approx \\operatorname {perceptual~difference} (x,x')}\n  \n. This finetuned model is then used to define \n  \n    \n      \n        LPIPS\n        \u2061\n        (\n        x\n        ,\n        \n          x\n          \u2032\n        \n        )\n        :=\n        \u2016\n        \n          f\n          \n            \u03b8\n          \n        \n        (\n        x\n        )\n        \u2212\n        \n          f\n          \n            \u03b8\n          \n        \n        (\n        \n          x\n          \u2032\n        \n        )\n        \u2016\n      \n    \n    {\\displaystyle \\operatorname {LPIPS} (x,x'):=\\|f_{\\theta }(x)-f_{\\theta }(x')\\|}\n  \n.\nOther evaluation methods are reviewed in.\n\n\n== Variants ==\nThere is a veritable zoo of GAN variants. Some of the most prominent are as follows:\n\n\n=== Conditional GAN ===\nConditional GANs are similar to standard GANs except they allow the model to conditionally generate samples based on additional information. For example, if we want to generate a cat face given a dog picture, we could use a conditional GAN.\nThe generator in a GAN game generates \n  \n    \n      \n        \n          \u03bc\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n, a probability distribution on the probability space \n  \n    \n      \n        \u03a9\n      \n    \n    {\\displaystyle \\Omega }\n  \n. This leads to the idea of a conditional GAN, where instead of generating one probability distribution on \n  \n    \n      \n        \u03a9\n      \n    \n    {\\displaystyle \\Omega }\n  \n, the generator generates a different probability distribution \n  \n    \n      \n        \n          \u03bc\n          \n            G\n          \n        \n        (\n        c\n        )\n      \n    \n    {\\displaystyle \\mu _{G}(c)}\n  \n on \n  \n    \n      \n        \u03a9\n      \n    \n    {\\displaystyle \\Omega }\n  \n, for each given class label \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n.\nFor example, for generating images that look like ImageNet, the generator should be able to generate a picture of cat when given the class label \"cat\".\nIn the original paper, the authors noted that GAN can be trivially extended to conditional GAN by providing the labels to both the generator and the discriminator.\nConcretely, the conditional GAN game is just the GAN game with class labels provided:\n  \n    \n      \n        L\n        (\n        \n          \u03bc\n          \n            G\n          \n        \n        ,\n        D\n        )\n        :=\n        \n          E\n          \n            c\n            \u223c\n            \n              \u03bc\n              \n                C\n              \n            \n            ,\n            x\n            \u223c\n            \n              \u03bc\n              \n                ref\n              \n            \n            (\n            c\n            )\n          \n        \n        \u2061\n        [\n        ln\n        \u2061\n        D\n        (\n        x\n        ,\n        c\n        )\n        ]\n        +\n        \n          E\n          \n            c\n            \u223c\n            \n              \u03bc\n              \n                C\n              \n            \n            ,\n            x\n            \u223c\n            \n              \u03bc\n              \n                G\n              \n            \n            (\n            c\n            )\n          \n        \n        \u2061\n        [\n        ln\n        \u2061\n        (\n        1\n        \u2212\n        D\n        (\n        x\n        ,\n        c\n        )\n        )\n        ]\n      \n    \n    {\\displaystyle L(\\mu _{G},D):=\\operatorname {E} _{c\\sim \\mu _{C},x\\sim \\mu _{\\text{ref}}(c)}[\\ln D(x,c)]+\\operatorname {E} _{c\\sim \\mu _{C},x\\sim \\mu _{G}(c)}[\\ln(1-D(x,c))]}\n  \nwhere \n  \n    \n      \n        \n          \u03bc\n          \n            C\n          \n        \n      \n    \n    {\\displaystyle \\mu _{C}}\n  \n is a probability distribution over classes, \n  \n    \n      \n        \n          \u03bc\n          \n            ref\n          \n        \n        (\n        c\n        )\n      \n    \n    {\\displaystyle \\mu _{\\text{ref}}(c)}\n  \n is the probability distribution of real images of class \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n, and \n  \n    \n      \n        \n          \u03bc\n          \n            G\n          \n        \n        (\n        c\n        )\n      \n    \n    {\\displaystyle \\mu _{G}(c)}\n  \n the probability distribution of images generated by the generator when given class label \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n.\nIn 2017, a conditional GAN learned to generate 1000 image classes of ImageNet.\n\n\n=== GANs with alternative architectures ===\nThe GAN game is a general framework and can be run with any reasonable parametrization of the generator \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n and discriminator \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n. In the original paper, the authors demonstrated it using multilayer perceptron networks and convolutional neural networks. Many alternative architectures have been tried.\nDeep convolutional GAN (DCGAN): For both generator and discriminator, uses only deep networks consisting entirely of convolution-deconvolution layers, that is, fully convolutional networks.\nSelf-attention GAN (SAGAN): Starts with the DCGAN, then adds residually-connected standard self-attention modules to the generator and discriminator.\nVariational autoencoder GAN (VAEGAN): Uses a variational autoencoder (VAE) for the generator.\nTransformer GAN (TransGAN): Uses the pure transformer architecture for both the generator and discriminator, entirely devoid of convolution-deconvolution layers.\nFlow-GAN: Uses flow-based generative model for the generator, allowing efficient computation of the likelihood function.\n\n\n=== GANs with alternative objectives ===\nMany GAN variants are merely obtained by changing the loss functions for the generator and discriminator.\nOriginal GAN:\nWe recast the original GAN objective into a form more convenient for comparison:\n  \n    \n      \n        \n          \n            {\n            \n              \n                \n                  \n                    min\n                    \n                      D\n                    \n                  \n                  \n                    L\n                    \n                      D\n                    \n                  \n                  (\n                  D\n                  ,\n                  \n                    \u03bc\n                    \n                      G\n                    \n                  \n                  )\n                  =\n                  \u2212\n                  \n                    E\n                    \n                      x\n                      \u223c\n                      \n                        \u03bc\n                        \n                          G\n                        \n                      \n                    \n                  \n                  \u2061\n                  [\n                  ln\n                  \u2061\n                  D\n                  (\n                  x\n                  )\n                  ]\n                  \u2212\n                  \n                    E\n                    \n                      x\n                      \u223c\n                      \n                        \u03bc\n                        \n                          ref\n                        \n                      \n                    \n                  \n                  \u2061\n                  [\n                  ln\n                  \u2061\n                  (\n                  1\n                  \u2212\n                  D\n                  (\n                  x\n                  )\n                  )\n                  ]\n                \n              \n              \n                \n                  \n                    min\n                    \n                      G\n                    \n                  \n                  \n                    L\n                    \n                      G\n                    \n                  \n                  (\n                  D\n                  ,\n                  \n                    \u03bc\n                    \n                      G\n                    \n                  \n                  )\n                  =\n                  \u2212\n                  \n                    E\n                    \n                      x\n                      \u223c\n                      \n                        \u03bc\n                        \n                          G\n                        \n                      \n                    \n                  \n                  \u2061\n                  [\n                  ln\n                  \u2061\n                  (\n                  1\n                  \u2212\n                  D\n                  (\n                  x\n                  )\n                  )\n                  ]\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{cases}\\min _{D}L_{D}(D,\\mu _{G})=-\\operatorname {E} _{x\\sim \\mu _{G}}[\\ln D(x)]-\\operatorname {E} _{x\\sim \\mu _{\\text{ref}}}[\\ln(1-D(x))]\\\\\\min _{G}L_{G}(D,\\mu _{G})=-\\operatorname {E} _{x\\sim \\mu _{G}}[\\ln(1-D(x))]\\end{cases}}}\n  \n\nOriginal GAN, non-saturating loss:\nThis objective for generator was recommended in the original paper for faster convergence.\n  \n    \n      \n        \n          L\n          \n            G\n          \n        \n        =\n        \n          E\n          \n            x\n            \u223c\n            \n              \u03bc\n              \n                G\n              \n            \n          \n        \n        \u2061\n        [\n        ln\n        \u2061\n        D\n        (\n        x\n        )\n        ]\n      \n    \n    {\\displaystyle L_{G}=\\operatorname {E} _{x\\sim \\mu _{G}}[\\ln D(x)]}\n  \nThe effect of using this objective is analyzed in Section 2.2.2 of Arjovsky et al.\nOriginal GAN, maximum likelihood:\n\n  \n    \n      \n        \n          L\n          \n            G\n          \n        \n        =\n        \n          E\n          \n            x\n            \u223c\n            \n              \u03bc\n              \n                G\n              \n            \n          \n        \n        \u2061\n        [\n        (\n        \n          exp\n        \n        \u2218\n        \n          \u03c3\n          \n            \u2212\n            1\n          \n        \n        \u2218\n        D\n        )\n        (\n        x\n        )\n        ]\n      \n    \n    {\\displaystyle L_{G}=\\operatorname {E} _{x\\sim \\mu _{G}}[({\\exp }\\circ \\sigma ^{-1}\\circ D)(x)]}\n  \nwhere \n  \n    \n      \n        \u03c3\n      \n    \n    {\\displaystyle \\sigma }\n  \n is the logistic function. When the discriminator is optimal, the generator gradient is the same as in maximum likelihood estimation, even though GAN cannot perform maximum likelihood estimation itself.\nHinge loss GAN:\n  \n    \n      \n        \n          L\n          \n            D\n          \n        \n        =\n        \u2212\n        \n          E\n          \n            x\n            \u223c\n            \n              p\n              \n                ref\n              \n            \n          \n        \n        \u2061\n        \n          [\n          \n            min\n            \n              (\n              \n                0\n                ,\n                \u2212\n                1\n                +\n                D\n                (\n                x\n                )\n              \n              )\n            \n          \n          ]\n        \n        \u2212\n        \n          E\n          \n            x\n            \u223c\n            \n              \u03bc\n              \n                G\n              \n            \n          \n        \n        \u2061\n        \n          [\n          \n            min\n            \n              (\n              \n                0\n                ,\n                \u2212\n                1\n                \u2212\n                D\n                \n                  (\n                  x\n                  )\n                \n              \n              )\n            \n          \n          ]\n        \n      \n    \n    {\\displaystyle L_{D}=-\\operatorname {E} _{x\\sim p_{\\text{ref}}}\\left[\\min \\left(0,-1+D(x)\\right)\\right]-\\operatorname {E} _{x\\sim \\mu _{G}}\\left[\\min \\left(0,-1-D\\left(x\\right)\\right)\\right]}\n  \n\n  \n    \n      \n        \n          L\n          \n            G\n          \n        \n        =\n        \u2212\n        \n          E\n          \n            x\n            \u223c\n            \n              \u03bc\n              \n                G\n              \n            \n          \n        \n        \u2061\n        [\n        D\n        (\n        x\n        )\n        ]\n      \n    \n    {\\displaystyle L_{G}=-\\operatorname {E} _{x\\sim \\mu _{G}}[D(x)]}\n  \nLeast squares GAN:\n  \n    \n      \n        \n          L\n          \n            D\n          \n        \n        =\n        \n          E\n          \n            x\n            \u223c\n            \n              \u03bc\n              \n                ref\n              \n            \n          \n        \n        \u2061\n        [\n        (\n        D\n        (\n        x\n        )\n        \u2212\n        b\n        \n          )\n          \n            2\n          \n        \n        ]\n        +\n        \n          E\n          \n            x\n            \u223c\n            \n              \u03bc\n              \n                G\n              \n            \n          \n        \n        \u2061\n        [\n        (\n        D\n        (\n        x\n        )\n        \u2212\n        a\n        \n          )\n          \n            2\n          \n        \n        ]\n      \n    \n    {\\displaystyle L_{D}=\\operatorname {E} _{x\\sim \\mu _{\\text{ref}}}[(D(x)-b)^{2}]+\\operatorname {E} _{x\\sim \\mu _{G}}[(D(x)-a)^{2}]}\n  \n\n  \n    \n      \n        \n          L\n          \n            G\n          \n        \n        =\n        \n          E\n          \n            x\n            \u223c\n            \n              \u03bc\n              \n                G\n              \n            \n          \n        \n        \u2061\n        [\n        (\n        D\n        (\n        x\n        )\n        \u2212\n        c\n        \n          )\n          \n            2\n          \n        \n        ]\n      \n    \n    {\\displaystyle L_{G}=\\operatorname {E} _{x\\sim \\mu _{G}}[(D(x)-c)^{2}]}\n  \nwhere \n  \n    \n      \n        a\n        ,\n        b\n        ,\n        c\n      \n    \n    {\\displaystyle a,b,c}\n  \n are parameters to be chosen. The authors recommended \n  \n    \n      \n        a\n        =\n        \u2212\n        1\n        ,\n        b\n        =\n        1\n        ,\n        c\n        =\n        0\n      \n    \n    {\\displaystyle a=-1,b=1,c=0}\n  \n.\n\n\n=== Wasserstein GAN (WGAN) ===\n\nThe Wasserstein GAN modifies the GAN game at two points:\n\nThe discriminator's strategy set is the set of measurable functions of type \n  \n    \n      \n        D\n        :\n        \u03a9\n        \u2192\n        \n          R\n        \n      \n    \n    {\\displaystyle D:\\Omega \\to \\mathbb {R} }\n  \n with bounded Lipschitz norm: \n  \n    \n      \n        \u2016\n        D\n        \n          \u2016\n          \n            L\n          \n        \n        \u2264\n        K\n      \n    \n    {\\displaystyle \\|D\\|_{L}\\leq K}\n  \n, where \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n is a fixed positive constant.\nThe objective is\n  \n    \n      \n        \n          L\n          \n            W\n            G\n            A\n            N\n          \n        \n        (\n        \n          \u03bc\n          \n            G\n          \n        \n        ,\n        D\n        )\n        :=\n        \n          E\n          \n            x\n            \u223c\n            \n              \u03bc\n              \n                G\n              \n            \n          \n        \n        \u2061\n        [\n        D\n        (\n        x\n        )\n        ]\n        \u2212\n        \n          \n            E\n          \n          \n            x\n            \u223c\n            \n              \u03bc\n              \n                ref\n              \n            \n          \n        \n        [\n        D\n        (\n        x\n        )\n        ]\n      \n    \n    {\\displaystyle L_{WGAN}(\\mu _{G},D):=\\operatorname {E} _{x\\sim \\mu _{G}}[D(x)]-\\mathbb {E} _{x\\sim \\mu _{\\text{ref}}}[D(x)]}\n  \n\nOne of its purposes is to solve the problem of mode collapse (see above). The authors claim \"In no experiment did we see evidence of mode collapse for the WGAN algorithm\".\n\n\n=== GANs with more than two players ===\n\n\n==== Adversarial autoencoder ====\nAn adversarial autoencoder (AAE) is more autoencoder than GAN. The idea is to start with a plain autoencoder, but train a discriminator to discriminate the latent vectors from a reference distribution (often the normal distribution).\n\n\n==== InfoGAN ====\nIn conditional GAN, the generator receives both a noise vector \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n and a label \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n, and produces an image \n  \n    \n      \n        G\n        (\n        z\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle G(z,c)}\n  \n. The discriminator receives image-label pairs \n  \n    \n      \n        (\n        x\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle (x,c)}\n  \n, and computes \n  \n    \n      \n        D\n        (\n        x\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle D(x,c)}\n  \n.\nWhen the training dataset is unlabeled, conditional GAN does not work directly.\nThe idea of InfoGAN is to decree that every latent vector in the latent space can be decomposed as \n  \n    \n      \n        (\n        z\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle (z,c)}\n  \n: an incompressible noise part \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n, and an informative label part \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n, and encourage the generator to comply with the decree, by encouraging it to maximize \n  \n    \n      \n        I\n        (\n        c\n        ,\n        G\n        (\n        z\n        ,\n        c\n        )\n        )\n      \n    \n    {\\displaystyle I(c,G(z,c))}\n  \n, the mutual information between \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n and \n  \n    \n      \n        G\n        (\n        z\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle G(z,c)}\n  \n, while making no demands on the mutual information \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n between \n  \n    \n      \n        G\n        (\n        z\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle G(z,c)}\n  \n.\nUnfortunately, \n  \n    \n      \n        I\n        (\n        c\n        ,\n        G\n        (\n        z\n        ,\n        c\n        )\n        )\n      \n    \n    {\\displaystyle I(c,G(z,c))}\n  \n is intractable in general, The key idea of InfoGAN is Variational Mutual Information Maximization: indirectly maximize it by maximizing a lower bound\n  \n    \n      \n        \n          \n            \n              I\n              ^\n            \n          \n        \n        (\n        G\n        ,\n        Q\n        )\n        =\n        \n          \n            E\n          \n          \n            z\n            \u223c\n            \n              \u03bc\n              \n                Z\n              \n            \n            ,\n            c\n            \u223c\n            \n              \u03bc\n              \n                C\n              \n            \n          \n        \n        [\n        ln\n        \u2061\n        Q\n        (\n        c\n        \u2223\n        G\n        (\n        z\n        ,\n        c\n        )\n        )\n        ]\n        ;\n        \n        I\n        (\n        c\n        ,\n        G\n        (\n        z\n        ,\n        c\n        )\n        )\n        \u2265\n        \n          sup\n          \n            Q\n          \n        \n        \n          \n            \n              I\n              ^\n            \n          \n        \n        (\n        G\n        ,\n        Q\n        )\n      \n    \n    {\\displaystyle {\\hat {I}}(G,Q)=\\mathbb {E} _{z\\sim \\mu _{Z},c\\sim \\mu _{C}}[\\ln Q(c\\mid G(z,c))];\\quad I(c,G(z,c))\\geq \\sup _{Q}{\\hat {I}}(G,Q)}\n  \nwhere \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  \n ranges over all Markov kernels of type \n  \n    \n      \n        Q\n        :\n        \n          \u03a9\n          \n            Y\n          \n        \n        \u2192\n        \n          \n            P\n          \n        \n        (\n        \n          \u03a9\n          \n            C\n          \n        \n        )\n      \n    \n    {\\displaystyle Q:\\Omega _{Y}\\to {\\mathcal {P}}(\\Omega _{C})}\n  \n.\n\nThe InfoGAN game is defined as follows:Three probability spaces define an InfoGAN game:\n\n  \n    \n      \n        (\n        \n          \u03a9\n          \n            X\n          \n        \n        ,\n        \n          \u03bc\n          \n            ref\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{X},\\mu _{\\text{ref}})}\n  \n, the space of reference images.\n\n  \n    \n      \n        (\n        \n          \u03a9\n          \n            Z\n          \n        \n        ,\n        \n          \u03bc\n          \n            Z\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{Z},\\mu _{Z})}\n  \n, the fixed random noise generator.\n\n  \n    \n      \n        (\n        \n          \u03a9\n          \n            C\n          \n        \n        ,\n        \n          \u03bc\n          \n            C\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{C},\\mu _{C})}\n  \n, the fixed random information generator.\nThere are 3 players in 2 teams: generator, Q, and discriminator. The generator and Q are on one team, and the discriminator on the other team.\nThe objective function is\n  \n    \n      \n        L\n        (\n        G\n        ,\n        Q\n        ,\n        D\n        )\n        =\n        \n          L\n          \n            G\n            A\n            N\n          \n        \n        (\n        G\n        ,\n        D\n        )\n        \u2212\n        \u03bb\n        \n          \n            \n              I\n              ^\n            \n          \n        \n        (\n        G\n        ,\n        Q\n        )\n      \n    \n    {\\displaystyle L(G,Q,D)=L_{GAN}(G,D)-\\lambda {\\hat {I}}(G,Q)}\n  \nwhere \n  \n    \n      \n        \n          L\n          \n            G\n            A\n            N\n          \n        \n        (\n        G\n        ,\n        D\n        )\n        =\n        \n          E\n          \n            x\n            \u223c\n            \n              \u03bc\n              \n                ref\n              \n            \n            ,\n          \n        \n        \u2061\n        [\n        ln\n        \u2061\n        D\n        (\n        x\n        )\n        ]\n        +\n        \n          E\n          \n            z\n            \u223c\n            \n              \u03bc\n              \n                Z\n              \n            \n          \n        \n        \u2061\n        [\n        ln\n        \u2061\n        (\n        1\n        \u2212\n        D\n        (\n        G\n        (\n        z\n        ,\n        c\n        )\n        )\n        )\n        ]\n      \n    \n    {\\displaystyle L_{GAN}(G,D)=\\operatorname {E} _{x\\sim \\mu _{\\text{ref}},}[\\ln D(x)]+\\operatorname {E} _{z\\sim \\mu _{Z}}[\\ln(1-D(G(z,c)))]}\n  \n is the original GAN game objective, and \n  \n    \n      \n        \n          \n            \n              I\n              ^\n            \n          \n        \n        (\n        G\n        ,\n        Q\n        )\n        =\n        \n          \n            E\n          \n          \n            z\n            \u223c\n            \n              \u03bc\n              \n                Z\n              \n            \n            ,\n            c\n            \u223c\n            \n              \u03bc\n              \n                C\n              \n            \n          \n        \n        [\n        ln\n        \u2061\n        Q\n        (\n        c\n        \u2223\n        G\n        (\n        z\n        ,\n        c\n        )\n        )\n        ]\n      \n    \n    {\\displaystyle {\\hat {I}}(G,Q)=\\mathbb {E} _{z\\sim \\mu _{Z},c\\sim \\mu _{C}}[\\ln Q(c\\mid G(z,c))]}\n  \n\nGenerator-Q team aims to minimize the objective, and discriminator aims to maximize it:\n  \n    \n      \n        \n          min\n          \n            G\n            ,\n            Q\n          \n        \n        \n          max\n          \n            D\n          \n        \n        L\n        (\n        G\n        ,\n        Q\n        ,\n        D\n        )\n      \n    \n    {\\displaystyle \\min _{G,Q}\\max _{D}L(G,Q,D)}\n  \n\n\n==== Bidirectional GAN (BiGAN) ====\nThe standard GAN generator is a function of type \n  \n    \n      \n        G\n        :\n        \n          \u03a9\n          \n            Z\n          \n        \n        \u2192\n        \n          \u03a9\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle G:\\Omega _{Z}\\to \\Omega _{X}}\n  \n, that is, it is a mapping from a latent space \n  \n    \n      \n        \n          \u03a9\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\Omega _{Z}}\n  \n to the image space \n  \n    \n      \n        \n          \u03a9\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle \\Omega _{X}}\n  \n. This can be understood as a \"decoding\" process, whereby every latent vector \n  \n    \n      \n        z\n        \u2208\n        \n          \u03a9\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle z\\in \\Omega _{Z}}\n  \n is a code for an image \n  \n    \n      \n        x\n        \u2208\n        \n          \u03a9\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle x\\in \\Omega _{X}}\n  \n, and the generator performs the decoding. This naturally leads to the idea of training another network that performs \"encoding\", creating an autoencoder out of the encoder-generator pair.\nAlready in the original paper, the authors noted that \"Learned approximate inference can be performed by training an auxiliary network to predict \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n given \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n\". The bidirectional GAN architecture performs exactly this.\n\nThe BiGAN is defined as follows: Two probability spaces define a BiGAN game:\n\n  \n    \n      \n        (\n        \n          \u03a9\n          \n            X\n          \n        \n        ,\n        \n          \u03bc\n          \n            X\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{X},\\mu _{X})}\n  \n, the space of reference images.\n\n  \n    \n      \n        (\n        \n          \u03a9\n          \n            Z\n          \n        \n        ,\n        \n          \u03bc\n          \n            Z\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{Z},\\mu _{Z})}\n  \n, the latent space.\nThere are 3 players in 2 teams: generator, encoder, and discriminator. The generator and encoder are on one team, and the discriminator on the other team.\nThe generator's strategies are functions \n  \n    \n      \n        G\n        :\n        \n          \u03a9\n          \n            Z\n          \n        \n        \u2192\n        \n          \u03a9\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle G:\\Omega _{Z}\\to \\Omega _{X}}\n  \n, and the encoder's strategies are functions \n  \n    \n      \n        E\n        :\n        \n          \u03a9\n          \n            X\n          \n        \n        \u2192\n        \n          \u03a9\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle E:\\Omega _{X}\\to \\Omega _{Z}}\n  \n. The discriminator's strategies are functions \n  \n    \n      \n        D\n        :\n        \n          \u03a9\n          \n            X\n          \n        \n        \u2192\n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle D:\\Omega _{X}\\to [0,1]}\n  \n.\nThe objective function is\n  \n    \n      \n        L\n        (\n        G\n        ,\n        E\n        ,\n        D\n        )\n        =\n        \n          \n            E\n          \n          \n            x\n            \u223c\n            \n              \u03bc\n              \n                X\n              \n            \n          \n        \n        [\n        ln\n        \u2061\n        D\n        (\n        x\n        ,\n        E\n        (\n        x\n        )\n        )\n        ]\n        +\n        \n          \n            E\n          \n          \n            z\n            \u223c\n            \n              \u03bc\n              \n                Z\n              \n            \n          \n        \n        [\n        ln\n        \u2061\n        (\n        1\n        \u2212\n        D\n        (\n        G\n        (\n        z\n        )\n        ,\n        z\n        )\n        )\n        ]\n      \n    \n    {\\displaystyle L(G,E,D)=\\mathbb {E} _{x\\sim \\mu _{X}}[\\ln D(x,E(x))]+\\mathbb {E} _{z\\sim \\mu _{Z}}[\\ln(1-D(G(z),z))]}\n  \n\nGenerator-encoder team aims to minimize the objective, and discriminator aims to maximize it:\n  \n    \n      \n        \n          min\n          \n            G\n            ,\n            E\n          \n        \n        \n          max\n          \n            D\n          \n        \n        L\n        (\n        G\n        ,\n        E\n        ,\n        D\n        )\n      \n    \n    {\\displaystyle \\min _{G,E}\\max _{D}L(G,E,D)}\n  \n In the paper, they gave a more abstract definition of the objective as:\n  \n    \n      \n        L\n        (\n        G\n        ,\n        E\n        ,\n        D\n        )\n        =\n        \n          \n            E\n          \n          \n            (\n            x\n            ,\n            z\n            )\n            \u223c\n            \n              \u03bc\n              \n                E\n                ,\n                X\n              \n            \n          \n        \n        [\n        ln\n        \u2061\n        D\n        (\n        x\n        ,\n        z\n        )\n        ]\n        +\n        \n          \n            E\n          \n          \n            (\n            x\n            ,\n            z\n            )\n            \u223c\n            \n              \u03bc\n              \n                G\n                ,\n                Z\n              \n            \n          \n        \n        [\n        ln\n        \u2061\n        (\n        1\n        \u2212\n        D\n        (\n        x\n        ,\n        z\n        )\n        )\n        ]\n      \n    \n    {\\displaystyle L(G,E,D)=\\mathbb {E} _{(x,z)\\sim \\mu _{E,X}}[\\ln D(x,z)]+\\mathbb {E} _{(x,z)\\sim \\mu _{G,Z}}[\\ln(1-D(x,z))]}\n  \nwhere \n  \n    \n      \n        \n          \u03bc\n          \n            E\n            ,\n            X\n          \n        \n        (\n        d\n        x\n        ,\n        d\n        z\n        )\n        =\n        \n          \u03bc\n          \n            X\n          \n        \n        (\n        d\n        x\n        )\n        \u22c5\n        \n          \u03b4\n          \n            E\n            (\n            x\n            )\n          \n        \n        (\n        d\n        z\n        )\n      \n    \n    {\\displaystyle \\mu _{E,X}(dx,dz)=\\mu _{X}(dx)\\cdot \\delta _{E(x)}(dz)}\n  \n is the probability distribution on \n  \n    \n      \n        \n          \u03a9\n          \n            X\n          \n        \n        \u00d7\n        \n          \u03a9\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\Omega _{X}\\times \\Omega _{Z}}\n  \n obtained by pushing \n  \n    \n      \n        \n          \u03bc\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle \\mu _{X}}\n  \n forward via \n  \n    \n      \n        x\n        \u21a6\n        (\n        x\n        ,\n        E\n        (\n        x\n        )\n        )\n      \n    \n    {\\displaystyle x\\mapsto (x,E(x))}\n  \n, and \n  \n    \n      \n        \n          \u03bc\n          \n            G\n            ,\n            Z\n          \n        \n        (\n        d\n        x\n        ,\n        d\n        z\n        )\n        =\n        \n          \u03b4\n          \n            G\n            (\n            z\n            )\n          \n        \n        (\n        d\n        x\n        )\n        \u22c5\n        \n          \u03bc\n          \n            Z\n          \n        \n        (\n        d\n        z\n        )\n      \n    \n    {\\displaystyle \\mu _{G,Z}(dx,dz)=\\delta _{G(z)}(dx)\\cdot \\mu _{Z}(dz)}\n  \n is the probability distribution on \n  \n    \n      \n        \n          \u03a9\n          \n            X\n          \n        \n        \u00d7\n        \n          \u03a9\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\Omega _{X}\\times \\Omega _{Z}}\n  \n obtained by pushing \n  \n    \n      \n        \n          \u03bc\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\mu _{Z}}\n  \n forward via \n  \n    \n      \n        z\n        \u21a6\n        (\n        G\n        (\n        x\n        )\n        ,\n        z\n        )\n      \n    \n    {\\displaystyle z\\mapsto (G(x),z)}\n  \n.\nApplications of bidirectional models include semi-supervised learning, interpretable machine learning, and neural machine translation.\n\n\n==== CycleGAN ====\nCycleGAN is an architecture for performing translations between two domains, such as between photos of horses and photos of zebras, or photos of night cities and photos of day cities.\n\nThe CycleGAN game is defined as follows:There are two probability spaces \n  \n    \n      \n        (\n        \n          \u03a9\n          \n            X\n          \n        \n        ,\n        \n          \u03bc\n          \n            X\n          \n        \n        )\n        ,\n        (\n        \n          \u03a9\n          \n            Y\n          \n        \n        ,\n        \n          \u03bc\n          \n            Y\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{X},\\mu _{X}),(\\Omega _{Y},\\mu _{Y})}\n  \n, corresponding to the two domains needed for translations fore-and-back.\nThere are 4 players in 2 teams: generators \n  \n    \n      \n        \n          G\n          \n            X\n          \n        \n        :\n        \n          \u03a9\n          \n            X\n          \n        \n        \u2192\n        \n          \u03a9\n          \n            Y\n          \n        \n        ,\n        \n          G\n          \n            Y\n          \n        \n        :\n        \n          \u03a9\n          \n            Y\n          \n        \n        \u2192\n        \n          \u03a9\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle G_{X}:\\Omega _{X}\\to \\Omega _{Y},G_{Y}:\\Omega _{Y}\\to \\Omega _{X}}\n  \n, and discriminators \n  \n    \n      \n        \n          D\n          \n            X\n          \n        \n        :\n        \n          \u03a9\n          \n            X\n          \n        \n        \u2192\n        [\n        0\n        ,\n        1\n        ]\n        ,\n        \n          D\n          \n            Y\n          \n        \n        :\n        \n          \u03a9\n          \n            Y\n          \n        \n        \u2192\n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle D_{X}:\\Omega _{X}\\to [0,1],D_{Y}:\\Omega _{Y}\\to [0,1]}\n  \n.\nThe objective function is\n  \n    \n      \n        L\n        (\n        \n          G\n          \n            X\n          \n        \n        ,\n        \n          G\n          \n            Y\n          \n        \n        ,\n        \n          D\n          \n            X\n          \n        \n        ,\n        \n          D\n          \n            Y\n          \n        \n        )\n        =\n        \n          L\n          \n            G\n            A\n            N\n          \n        \n        (\n        \n          G\n          \n            X\n          \n        \n        ,\n        \n          D\n          \n            X\n          \n        \n        )\n        +\n        \n          L\n          \n            G\n            A\n            N\n          \n        \n        (\n        \n          G\n          \n            Y\n          \n        \n        ,\n        \n          D\n          \n            Y\n          \n        \n        )\n        +\n        \u03bb\n        \n          L\n          \n            c\n            y\n            c\n            l\n            e\n          \n        \n        (\n        \n          G\n          \n            X\n          \n        \n        ,\n        \n          G\n          \n            Y\n          \n        \n        )\n      \n    \n    {\\displaystyle L(G_{X},G_{Y},D_{X},D_{Y})=L_{GAN}(G_{X},D_{X})+L_{GAN}(G_{Y},D_{Y})+\\lambda L_{cycle}(G_{X},G_{Y})}\n  \n\nwhere \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n  \n is a positive adjustable parameter, \n  \n    \n      \n        \n          L\n          \n            G\n            A\n            N\n          \n        \n      \n    \n    {\\displaystyle L_{GAN}}\n  \n is the GAN game objective, and \n  \n    \n      \n        \n          L\n          \n            c\n            y\n            c\n            l\n            e\n          \n        \n      \n    \n    {\\displaystyle L_{cycle}}\n  \n is the cycle consistency loss:\n  \n    \n      \n        \n          L\n          \n            c\n            y\n            c\n            l\n            e\n          \n        \n        (\n        \n          G\n          \n            X\n          \n        \n        ,\n        \n          G\n          \n            Y\n          \n        \n        )\n        =\n        \n          E\n          \n            x\n            \u223c\n            \n              \u03bc\n              \n                X\n              \n            \n          \n        \n        \u2016\n        \n          G\n          \n            X\n          \n        \n        (\n        \n          G\n          \n            Y\n          \n        \n        (\n        x\n        )\n        )\n        \u2212\n        x\n        \u2016\n        +\n        \n          E\n          \n            y\n            \u223c\n            \n              \u03bc\n              \n                Y\n              \n            \n          \n        \n        \u2016\n        \n          G\n          \n            Y\n          \n        \n        (\n        \n          G\n          \n            X\n          \n        \n        (\n        y\n        )\n        )\n        \u2212\n        y\n        \u2016\n      \n    \n    {\\displaystyle L_{cycle}(G_{X},G_{Y})=E_{x\\sim \\mu _{X}}\\|G_{X}(G_{Y}(x))-x\\|+E_{y\\sim \\mu _{Y}}\\|G_{Y}(G_{X}(y))-y\\|}\n  \nThe generators aim to minimize the objective, and the discriminators aim to maximize it:\n  \n    \n      \n        \n          min\n          \n            \n              G\n              \n                X\n              \n            \n            ,\n            \n              G\n              \n                Y\n              \n            \n          \n        \n        \n          max\n          \n            \n              D\n              \n                X\n              \n            \n            ,\n            \n              D\n              \n                Y\n              \n            \n          \n        \n        L\n        (\n        \n          G\n          \n            X\n          \n        \n        ,\n        \n          G\n          \n            Y\n          \n        \n        ,\n        \n          D\n          \n            X\n          \n        \n        ,\n        \n          D\n          \n            Y\n          \n        \n        )\n      \n    \n    {\\displaystyle \\min _{G_{X},G_{Y}}\\max _{D_{X},D_{Y}}L(G_{X},G_{Y},D_{X},D_{Y})}\n  \n  Unlike previous work like pix2pix, which requires paired training data, cycleGAN requires no paired data. For example, to train a pix2pix model to turn a summer scenery photo to winter scenery photo and back, the dataset must contain pairs of the same place in summer and winter, shot at the same angle; cycleGAN would only need a set of summer scenery photos, and an unrelated set of winter scenery photos.\n\n\n=== GANs with particularly large or small scales ===\n\n\n==== BigGAN ====\nThe BigGAN is essentially a self-attention GAN trained on a large scale (up to 80 million parameters) to generate large images of ImageNet (up to 512 x 512 resolution), with numerous engineering tricks to make it converge.\n\n\n==== Invertible data augmentation ====\nWhen there is insufficient training data, the reference distribution \n  \n    \n      \n        \n          \u03bc\n          \n            ref\n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\text{ref}}}\n  \n cannot be well-approximated by the empirical distribution given by the training dataset. In such cases, data augmentation can be applied, to allow training GAN on smaller datasets. Na\u00efve data augmentation, however, brings its problems.\nConsider the original GAN game, slightly reformulated as follows:\n  \n    \n      \n        \n          \n            {\n            \n              \n                \n                  \n                    min\n                    \n                      D\n                    \n                  \n                  \n                    L\n                    \n                      D\n                    \n                  \n                  (\n                  D\n                  ,\n                  \n                    \u03bc\n                    \n                      G\n                    \n                  \n                  )\n                  =\n                  \u2212\n                  \n                    E\n                    \n                      x\n                      \u223c\n                      \n                        \u03bc\n                        \n                          ref\n                        \n                      \n                    \n                  \n                  \u2061\n                  [\n                  ln\n                  \u2061\n                  D\n                  (\n                  x\n                  )\n                  ]\n                  \u2212\n                  \n                    E\n                    \n                      x\n                      \u223c\n                      \n                        \u03bc\n                        \n                          G\n                        \n                      \n                    \n                  \n                  \u2061\n                  [\n                  ln\n                  \u2061\n                  (\n                  1\n                  \u2212\n                  D\n                  (\n                  x\n                  )\n                  )\n                  ]\n                \n              \n              \n                \n                  \n                    min\n                    \n                      G\n                    \n                  \n                  \n                    L\n                    \n                      G\n                    \n                  \n                  (\n                  D\n                  ,\n                  \n                    \u03bc\n                    \n                      G\n                    \n                  \n                  )\n                  =\n                  \u2212\n                  \n                    E\n                    \n                      x\n                      \u223c\n                      \n                        \u03bc\n                        \n                          G\n                        \n                      \n                    \n                  \n                  \u2061\n                  [\n                  ln\n                  \u2061\n                  (\n                  1\n                  \u2212\n                  D\n                  (\n                  x\n                  )\n                  )\n                  ]\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{cases}\\min _{D}L_{D}(D,\\mu _{G})=-\\operatorname {E} _{x\\sim \\mu _{\\text{ref}}}[\\ln D(x)]-\\operatorname {E} _{x\\sim \\mu _{G}}[\\ln(1-D(x))]\\\\\\min _{G}L_{G}(D,\\mu _{G})=-\\operatorname {E} _{x\\sim \\mu _{G}}[\\ln(1-D(x))]\\end{cases}}}\n  \nNow we use data augmentation by randomly sampling semantic-preserving transforms \n  \n    \n      \n        T\n        :\n        \u03a9\n        \u2192\n        \u03a9\n      \n    \n    {\\displaystyle T:\\Omega \\to \\Omega }\n  \n and applying them to the dataset, to obtain the reformulated GAN game:\n  \n    \n      \n        \n          \n            {\n            \n              \n                \n                  \n                    min\n                    \n                      D\n                    \n                  \n                  \n                    L\n                    \n                      D\n                    \n                  \n                  (\n                  D\n                  ,\n                  \n                    \u03bc\n                    \n                      G\n                    \n                  \n                  )\n                  =\n                  \u2212\n                  \n                    E\n                    \n                      x\n                      \u223c\n                      \n                        \u03bc\n                        \n                          ref\n                        \n                      \n                      ,\n                      T\n                      \u223c\n                      \n                        \u03bc\n                        \n                          trans\n                        \n                      \n                    \n                  \n                  \u2061\n                  [\n                  ln\n                  \u2061\n                  D\n                  (\n                  T\n                  (\n                  x\n                  )\n                  )\n                  ]\n                  \u2212\n                  \n                    E\n                    \n                      x\n                      \u223c\n                      \n                        \u03bc\n                        \n                          G\n                        \n                      \n                    \n                  \n                  \u2061\n                  [\n                  ln\n                  \u2061\n                  (\n                  1\n                  \u2212\n                  D\n                  (\n                  x\n                  )\n                  )\n                  ]\n                \n              \n              \n                \n                  \n                    min\n                    \n                      G\n                    \n                  \n                  \n                    L\n                    \n                      G\n                    \n                  \n                  (\n                  D\n                  ,\n                  \n                    \u03bc\n                    \n                      G\n                    \n                  \n                  )\n                  =\n                  \u2212\n                  \n                    E\n                    \n                      x\n                      \u223c\n                      \n                        \u03bc\n                        \n                          G\n                        \n                      \n                    \n                  \n                  \u2061\n                  [\n                  ln\n                  \u2061\n                  (\n                  1\n                  \u2212\n                  D\n                  (\n                  x\n                  )\n                  )\n                  ]\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{cases}\\min _{D}L_{D}(D,\\mu _{G})=-\\operatorname {E} _{x\\sim \\mu _{\\text{ref}},T\\sim \\mu _{\\text{trans}}}[\\ln D(T(x))]-\\operatorname {E} _{x\\sim \\mu _{G}}[\\ln(1-D(x))]\\\\\\min _{G}L_{G}(D,\\mu _{G})=-\\operatorname {E} _{x\\sim \\mu _{G}}[\\ln(1-D(x))]\\end{cases}}}\n  \nThis is equivalent to a GAN game with a different distribution \n  \n    \n      \n        \n          \u03bc\n          \n            ref\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\mu _{\\text{ref}}'}\n  \n, sampled by \n  \n    \n      \n        T\n        (\n        x\n        )\n      \n    \n    {\\displaystyle T(x)}\n  \n, with \n  \n    \n      \n        x\n        \u223c\n        \n          \u03bc\n          \n            ref\n          \n        \n        ,\n        T\n        \u223c\n        \n          \u03bc\n          \n            trans\n          \n        \n      \n    \n    {\\displaystyle x\\sim \\mu _{\\text{ref}},T\\sim \\mu _{\\text{trans}}}\n  \n. For example, if \n  \n    \n      \n        \n          \u03bc\n          \n            ref\n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\text{ref}}}\n  \n is the distribution of images in ImageNet, and \n  \n    \n      \n        \n          \u03bc\n          \n            trans\n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\text{trans}}}\n  \n samples identity-transform with probability 0.5, and horizontal-reflection with probability 0.5, then \n  \n    \n      \n        \n          \u03bc\n          \n            ref\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\mu _{\\text{ref}}'}\n  \n is the distribution of images in ImageNet and horizontally-reflected ImageNet, combined.\nThe result of such training would be a generator that mimics \n  \n    \n      \n        \n          \u03bc\n          \n            ref\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\mu _{\\text{ref}}'}\n  \n. For example, it would generate images that look like they are randomly cropped, if the data augmentation uses random cropping.\nThe solution is to apply data augmentation to both generated and real images:\n  \n    \n      \n        \n          \n            {\n            \n              \n                \n                  \n                    min\n                    \n                      D\n                    \n                  \n                  \n                    L\n                    \n                      D\n                    \n                  \n                  (\n                  D\n                  ,\n                  \n                    \u03bc\n                    \n                      G\n                    \n                  \n                  )\n                  =\n                  \u2212\n                  \n                    E\n                    \n                      x\n                      \u223c\n                      \n                        \u03bc\n                        \n                          ref\n                        \n                      \n                      ,\n                      T\n                      \u223c\n                      \n                        \u03bc\n                        \n                          trans\n                        \n                      \n                    \n                  \n                  \u2061\n                  [\n                  ln\n                  \u2061\n                  D\n                  (\n                  T\n                  (\n                  x\n                  )\n                  )\n                  ]\n                  \u2212\n                  \n                    E\n                    \n                      x\n                      \u223c\n                      \n                        \u03bc\n                        \n                          G\n                        \n                      \n                      ,\n                      T\n                      \u223c\n                      \n                        \u03bc\n                        \n                          trans\n                        \n                      \n                    \n                  \n                  \u2061\n                  [\n                  ln\n                  \u2061\n                  (\n                  1\n                  \u2212\n                  D\n                  (\n                  T\n                  (\n                  x\n                  )\n                  )\n                  )\n                  ]\n                \n              \n              \n                \n                  \n                    min\n                    \n                      G\n                    \n                  \n                  \n                    L\n                    \n                      G\n                    \n                  \n                  (\n                  D\n                  ,\n                  \n                    \u03bc\n                    \n                      G\n                    \n                  \n                  )\n                  =\n                  \u2212\n                  \n                    E\n                    \n                      x\n                      \u223c\n                      \n                        \u03bc\n                        \n                          G\n                        \n                      \n                      ,\n                      T\n                      \u223c\n                      \n                        \u03bc\n                        \n                          trans\n                        \n                      \n                    \n                  \n                  \u2061\n                  [\n                  ln\n                  \u2061\n                  (\n                  1\n                  \u2212\n                  D\n                  (\n                  T\n                  (\n                  x\n                  )\n                  )\n                  )\n                  ]\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{cases}\\min _{D}L_{D}(D,\\mu _{G})=-\\operatorname {E} _{x\\sim \\mu _{\\text{ref}},T\\sim \\mu _{\\text{trans}}}[\\ln D(T(x))]-\\operatorname {E} _{x\\sim \\mu _{G},T\\sim \\mu _{\\text{trans}}}[\\ln(1-D(T(x)))]\\\\\\min _{G}L_{G}(D,\\mu _{G})=-\\operatorname {E} _{x\\sim \\mu _{G},T\\sim \\mu _{\\text{trans}}}[\\ln(1-D(T(x)))]\\end{cases}}}\n  \nThe authors demonstrated high-quality generation using just 100-picture-large datasets.\nThe StyleGAN-2-ADA paper points out a further point on data augmentation: it must be invertible. Continue with the example of generating ImageNet pictures. If the data augmentation is \"randomly rotate the picture by 0, 90, 180, 270 degrees with equal probability\", then there is no way for the generator to know which is the true orientation: Consider two generators \n  \n    \n      \n        G\n        ,\n        \n          G\n          \u2032\n        \n      \n    \n    {\\displaystyle G,G'}\n  \n, such that for any latent \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n, the generated image \n  \n    \n      \n        G\n        (\n        z\n        )\n      \n    \n    {\\displaystyle G(z)}\n  \n is a 90-degree rotation of \n  \n    \n      \n        \n          G\n          \u2032\n        \n        (\n        z\n        )\n      \n    \n    {\\displaystyle G'(z)}\n  \n. They would have exactly the same expected loss, and so neither is preferred over the other.\nThe solution is to only use invertible data augmentation: instead of \"randomly rotate the picture by 0, 90, 180, 270 degrees with equal probability\", use \"randomly rotate the picture by 90, 180, 270 degrees with 0.1 probability, and keep the picture as it is with 0.7 probability\". This way, the generator is still rewarded  to keep images oriented the same way as un-augmented ImageNet pictures.\nAbstractly, the effect of randomly sampling transformations \n  \n    \n      \n        T\n        :\n        \u03a9\n        \u2192\n        \u03a9\n      \n    \n    {\\displaystyle T:\\Omega \\to \\Omega }\n  \n from the distribution \n  \n    \n      \n        \n          \u03bc\n          \n            trans\n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\text{trans}}}\n  \n is to define a Markov kernel \n  \n    \n      \n        \n          K\n          \n            trans\n          \n        \n        :\n        \u03a9\n        \u2192\n        \n          \n            P\n          \n        \n        (\n        \u03a9\n        )\n      \n    \n    {\\displaystyle K_{\\text{trans}}:\\Omega \\to {\\mathcal {P}}(\\Omega )}\n  \n. Then, the data-augmented GAN game pushes the generator to find some \n  \n    \n      \n        \n          \n            \n              \n                \u03bc\n                ^\n              \n            \n          \n          \n            G\n          \n        \n        \u2208\n        \n          \n            P\n          \n        \n        (\n        \u03a9\n        )\n      \n    \n    {\\displaystyle {\\hat {\\mu }}_{G}\\in {\\mathcal {P}}(\\Omega )}\n  \n, such that \n  \n    \n      \n        \n          K\n          \n            trans\n          \n        \n        \u2217\n        \n          \u03bc\n          \n            ref\n          \n        \n        =\n        \n          K\n          \n            trans\n          \n        \n        \u2217\n        \n          \n            \n              \n                \u03bc\n                ^\n              \n            \n          \n          \n            G\n          \n        \n      \n    \n    {\\displaystyle K_{\\text{trans}}*\\mu _{\\text{ref}}=K_{\\text{trans}}*{\\hat {\\mu }}_{G}}\n  \nwhere \n  \n    \n      \n        \u2217\n      \n    \n    {\\displaystyle *}\n  \n is the Markov kernel convolution.\nA data-augmentation method is defined to be invertible if its Markov kernel \n  \n    \n      \n        \n          K\n          \n            trans\n          \n        \n      \n    \n    {\\displaystyle K_{\\text{trans}}}\n  \n satisfies\n  \n    \n      \n        \n          K\n          \n            trans\n          \n        \n        \u2217\n        \u03bc\n        =\n        \n          K\n          \n            trans\n          \n        \n        \u2217\n        \n          \u03bc\n          \u2032\n        \n        \n        \u27f9\n        \n        \u03bc\n        =\n        \n          \u03bc\n          \u2032\n        \n        \n        \u2200\n        \u03bc\n        ,\n        \n          \u03bc\n          \u2032\n        \n        \u2208\n        \n          \n            P\n          \n        \n        (\n        \u03a9\n        )\n      \n    \n    {\\displaystyle K_{\\text{trans}}*\\mu =K_{\\text{trans}}*\\mu '\\implies \\mu =\\mu '\\quad \\forall \\mu ,\\mu '\\in {\\mathcal {P}}(\\Omega )}\n  \nImmediately by definition, we see that composing multiple invertible data-augmentation methods results in yet another invertible method. Also by definition, if the data-augmentation method is invertible, then using it in a GAN game does not change the optimal strategy \n  \n    \n      \n        \n          \n            \n              \n                \u03bc\n                ^\n              \n            \n          \n          \n            G\n          \n        \n      \n    \n    {\\displaystyle {\\hat {\\mu }}_{G}}\n  \n for the generator, which is still \n  \n    \n      \n        \n          \u03bc\n          \n            ref\n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\text{ref}}}\n  \n.\nThere are two prototypical examples of invertible Markov kernels:\nDiscrete case: Invertible stochastic matrices, when \n  \n    \n      \n        \u03a9\n      \n    \n    {\\displaystyle \\Omega }\n  \n is finite.\nFor example, if \n  \n    \n      \n        \u03a9\n        =\n        {\n        \u2191\n        ,\n        \u2193\n        ,\n        \u2190\n        ,\n        \u2192\n        }\n      \n    \n    {\\displaystyle \\Omega =\\{\\uparrow ,\\downarrow ,\\leftarrow ,\\rightarrow \\}}\n  \n is the set of four images of an arrow, pointing in 4 directions, and the data augmentation is \"randomly rotate the picture by 90, 180, 270 degrees with probability \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n, and keep the picture as it is with probability \n  \n    \n      \n        (\n        1\n        \u2212\n        3\n        p\n        )\n      \n    \n    {\\displaystyle (1-3p)}\n  \n\", then the Markov kernel \n  \n    \n      \n        \n          K\n          \n            trans\n          \n        \n      \n    \n    {\\displaystyle K_{\\text{trans}}}\n  \n can be represented as a stochastic matrix:\n  \n    \n      \n        [\n        \n          K\n          \n            trans\n          \n        \n        ]\n        =\n        \n          \n            [\n            \n              \n                \n                  (\n                  1\n                  \u2212\n                  3\n                  p\n                  )\n                \n                \n                  p\n                \n                \n                  p\n                \n                \n                  p\n                \n              \n              \n                \n                  p\n                \n                \n                  (\n                  1\n                  \u2212\n                  3\n                  p\n                  )\n                \n                \n                  p\n                \n                \n                  p\n                \n              \n              \n                \n                  p\n                \n                \n                  p\n                \n                \n                  (\n                  1\n                  \u2212\n                  3\n                  p\n                  )\n                \n                \n                  p\n                \n              \n              \n                \n                  p\n                \n                \n                  p\n                \n                \n                  p\n                \n                \n                  (\n                  1\n                  \u2212\n                  3\n                  p\n                  )\n                \n              \n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle [K_{\\text{trans}}]={\\begin{bmatrix}(1-3p)&p&p&p\\\\p&(1-3p)&p&p\\\\p&p&(1-3p)&p\\\\p&p&p&(1-3p)\\end{bmatrix}}}\n  \n and \n  \n    \n      \n        \n          K\n          \n            trans\n          \n        \n      \n    \n    {\\displaystyle K_{\\text{trans}}}\n  \n is an invertible kernel iff \n  \n    \n      \n        [\n        \n          K\n          \n            trans\n          \n        \n        ]\n      \n    \n    {\\displaystyle [K_{\\text{trans}}]}\n  \n is an invertible matrix, that is, \n  \n    \n      \n        p\n        \u2260\n        1\n        \n          /\n        \n        4\n      \n    \n    {\\displaystyle p\\neq 1/4}\n  \n.\nContinuous case: The gaussian kernel, when \n  \n    \n      \n        \u03a9\n        =\n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\Omega =\\mathbb {R} ^{n}}\n  \n for some \n  \n    \n      \n        n\n        \u2265\n        1\n      \n    \n    {\\displaystyle n\\geq 1}\n  \n.\nFor example, if \n  \n    \n      \n        \u03a9\n        =\n        \n          \n            R\n          \n          \n            \n              256\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\Omega =\\mathbb {R} ^{256^{2}}}\n  \n is the space of 256x256 images, and the data-augmentation method is \"generate a gaussian noise \n  \n    \n      \n        z\n        \u223c\n        \n          \n            N\n          \n        \n        (\n        0\n        ,\n        \n          I\n          \n            \n              256\n              \n                2\n              \n            \n          \n        \n        )\n      \n    \n    {\\displaystyle z\\sim {\\mathcal {N}}(0,I_{256^{2}})}\n  \n, then add \n  \n    \n      \n        \u03f5\n        z\n      \n    \n    {\\displaystyle \\epsilon z}\n  \n to the image\", then \n  \n    \n      \n        \n          K\n          \n            trans\n          \n        \n      \n    \n    {\\displaystyle K_{\\text{trans}}}\n  \n is just convolution by the density function of \n  \n    \n      \n        \n          \n            N\n          \n        \n        (\n        0\n        ,\n        \n          \u03f5\n          \n            2\n          \n        \n        \n          I\n          \n            \n              256\n              \n                2\n              \n            \n          \n        \n        )\n      \n    \n    {\\displaystyle {\\mathcal {N}}(0,\\epsilon ^{2}I_{256^{2}})}\n  \n. This is invertible, because convolution by a gaussian is just convolution by the heat kernel, so given any \n  \n    \n      \n        \u03bc\n        \u2208\n        \n          \n            P\n          \n        \n        (\n        \n          \n            R\n          \n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mu \\in {\\mathcal {P}}(\\mathbb {R} ^{n})}\n  \n, the convolved distribution \n  \n    \n      \n        \n          K\n          \n            trans\n          \n        \n        \u2217\n        \u03bc\n      \n    \n    {\\displaystyle K_{\\text{trans}}*\\mu }\n  \n can be obtained by heating up \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n precisely according to \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n  \n, then wait for time \n  \n    \n      \n        \n          \u03f5\n          \n            2\n          \n        \n        \n          /\n        \n        4\n      \n    \n    {\\displaystyle \\epsilon ^{2}/4}\n  \n. With that, we can recover \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n  \n by running the heat equation backwards in time for \n  \n    \n      \n        \n          \u03f5\n          \n            2\n          \n        \n        \n          /\n        \n        4\n      \n    \n    {\\displaystyle \\epsilon ^{2}/4}\n  \n.\nMore examples of invertible data augmentations are found in the paper.\n\n\n==== SinGAN ====\nSinGAN pushes data augmentation to the limit, by using only a single image as training data and performing data augmentation on it. The GAN architecture is adapted to this training method by using a multi-scale pipeline.\nThe generator \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n is decomposed into a pyramid of generators \n  \n    \n      \n        G\n        =\n        \n          G\n          \n            1\n          \n        \n        \u2218\n        \n          G\n          \n            2\n          \n        \n        \u2218\n        \u22ef\n        \u2218\n        \n          G\n          \n            N\n          \n        \n      \n    \n    {\\displaystyle G=G_{1}\\circ G_{2}\\circ \\cdots \\circ G_{N}}\n  \n, with the lowest one generating the image \n  \n    \n      \n        \n          G\n          \n            N\n          \n        \n        (\n        \n          z\n          \n            N\n          \n        \n        )\n      \n    \n    {\\displaystyle G_{N}(z_{N})}\n  \n at the lowest resolution, then the generated image is scaled up to \n  \n    \n      \n        r\n        (\n        \n          G\n          \n            N\n          \n        \n        (\n        \n          z\n          \n            N\n          \n        \n        )\n        )\n      \n    \n    {\\displaystyle r(G_{N}(z_{N}))}\n  \n, and fed to the next level to generate an image \n  \n    \n      \n        \n          G\n          \n            N\n            \u2212\n            1\n          \n        \n        (\n        \n          z\n          \n            N\n            \u2212\n            1\n          \n        \n        +\n        r\n        (\n        \n          G\n          \n            N\n          \n        \n        (\n        \n          z\n          \n            N\n          \n        \n        )\n        )\n        )\n      \n    \n    {\\displaystyle G_{N-1}(z_{N-1}+r(G_{N}(z_{N})))}\n  \n at a higher resolution, and so on. The discriminator is decomposed into a pyramid as well.\n\n\n=== StyleGAN series ===\n\nThe StyleGAN family is a series of architectures published by Nvidia's research division.\n\n\n==== Progressive GAN ====\nProgressive GAN is a method for training GAN for large-scale image generation stably, by growing a GAN generator from small to large scale in a pyramidal fashion. Like SinGAN, it decomposes the generator as\n  \n    \n      \n        G\n        =\n        \n          G\n          \n            1\n          \n        \n        \u2218\n        \n          G\n          \n            2\n          \n        \n        \u2218\n        \u22ef\n        \u2218\n        \n          G\n          \n            N\n          \n        \n      \n    \n    {\\displaystyle G=G_{1}\\circ G_{2}\\circ \\cdots \\circ G_{N}}\n  \n, and the discriminator as \n  \n    \n      \n        D\n        =\n        \n          D\n          \n            1\n          \n        \n        \u2218\n        \n          D\n          \n            2\n          \n        \n        \u2218\n        \u22ef\n        \u2218\n        \n          D\n          \n            N\n          \n        \n      \n    \n    {\\displaystyle D=D_{1}\\circ D_{2}\\circ \\cdots \\circ D_{N}}\n  \n.\nDuring training, at first only \n  \n    \n      \n        \n          G\n          \n            N\n          \n        \n        ,\n        \n          D\n          \n            N\n          \n        \n      \n    \n    {\\displaystyle G_{N},D_{N}}\n  \n are used in a GAN game to generate 4x4 images. Then \n  \n    \n      \n        \n          G\n          \n            N\n            \u2212\n            1\n          \n        \n        ,\n        \n          D\n          \n            N\n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle G_{N-1},D_{N-1}}\n  \n are added to reach the second stage of GAN game, to generate 8x8 images, and so on, until we reach a GAN game to generate 1024x1024 images.\nTo avoid shock between stages of the GAN game, each new layer is \"blended in\" (Figure 2 of the paper). For example, this is how the second stage GAN game starts:\n\nJust before, the GAN game consists of the pair \n  \n    \n      \n        \n          G\n          \n            N\n          \n        \n        ,\n        \n          D\n          \n            N\n          \n        \n      \n    \n    {\\displaystyle G_{N},D_{N}}\n  \n generating and discriminating 4x4 images.\nJust after, the GAN game consists of the pair \n  \n    \n      \n        (\n        (\n        1\n        \u2212\n        \u03b1\n        )\n        +\n        \u03b1\n        \u22c5\n        \n          G\n          \n            N\n            \u2212\n            1\n          \n        \n        )\n        \u2218\n        u\n        \u2218\n        \n          G\n          \n            N\n          \n        \n        ,\n        \n          D\n          \n            N\n          \n        \n        \u2218\n        d\n        \u2218\n        (\n        (\n        1\n        \u2212\n        \u03b1\n        )\n        +\n        \u03b1\n        \u22c5\n        \n          D\n          \n            N\n            \u2212\n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle ((1-\\alpha )+\\alpha \\cdot G_{N-1})\\circ u\\circ G_{N},D_{N}\\circ d\\circ ((1-\\alpha )+\\alpha \\cdot D_{N-1})}\n  \n generating and discriminating 8x8 images. Here, the functions \n  \n    \n      \n        u\n        ,\n        d\n      \n    \n    {\\displaystyle u,d}\n  \n are image up- and down-sampling functions, and \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n  \n is a blend-in factor (much like an alpha in image composing) that smoothly glides from 0 to 1.\n\n\n==== StyleGAN-1 ====\n\nStyleGAN-1 is designed as a combination of Progressive GAN with neural style transfer.\nThe key architectural choice of StyleGAN-1 is a progressive growth mechanism, similar to Progressive GAN. Each generated image starts as a constant \n  \n    \n      \n        4\n        \u00d7\n        4\n        \u00d7\n        512\n      \n    \n    {\\displaystyle 4\\times 4\\times 512}\n  \n array, and repeatedly passed through style blocks. Each style block applies a \"style latent vector\" via affine transform (\"adaptive instance normalization\"), similar to how neural style transfer uses Gramian matrix. It then adds noise, and normalize (subtract the mean, then divide by the variance).\nAt training time, usually only one style latent vector is used per image generated, but sometimes two (\"mixing regularization\") in order to encourage each style block to independently perform its stylization without expecting help from other style blocks (since they might receive an entirely different style latent vector).\nAfter training, multiple style latent vectors can be fed into each style block. Those fed to the lower layers control the large-scale styles, and those fed to the higher layers control the fine-detail styles.\nStyle-mixing between two images \n  \n    \n      \n        x\n        ,\n        \n          x\n          \u2032\n        \n      \n    \n    {\\displaystyle x,x'}\n  \n can be performed as well. First, run a gradient descent to find \n  \n    \n      \n        z\n        ,\n        \n          z\n          \u2032\n        \n      \n    \n    {\\displaystyle z,z'}\n  \n such that \n  \n    \n      \n        G\n        (\n        z\n        )\n        \u2248\n        x\n        ,\n        G\n        (\n        \n          z\n          \u2032\n        \n        )\n        \u2248\n        \n          x\n          \u2032\n        \n      \n    \n    {\\displaystyle G(z)\\approx x,G(z')\\approx x'}\n  \n. This is called \"projecting an image back to style latent space\". Then, \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n can be fed to the lower style blocks, and \n  \n    \n      \n        \n          z\n          \u2032\n        \n      \n    \n    {\\displaystyle z'}\n  \n to the higher style blocks, to generate a composite image that has the large-scale style of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n, and the fine-detail style of \n  \n    \n      \n        \n          x\n          \u2032\n        \n      \n    \n    {\\displaystyle x'}\n  \n. Multiple images can also be composed this way.\n\n\n==== StyleGAN-2 ====\nStyleGAN-2 improves upon StyleGAN-1, by using the style latent vector to transform the convolution layer's weights instead, thus solving the \"blob\" problem.\nThis was updated by the StyleGAN-2-ADA (\"ADA\" stands for \"adaptive\"), which uses invertible data augmentation as described above. It also tunes the amount of data augmentation applied by starting at zero, and gradually increasing it until an \"overfitting heuristic\" reaches a target level, thus the name \"adaptive\".\n\n\n==== StyleGAN-3 ====\nStyleGAN-3 improves upon StyleGAN-2 by solving the \"texture sticking\" problem, which can be seen in the official videos. They analyzed the problem by the Nyquist\u2013Shannon sampling theorem, and argued that the layers in the generator learned to exploit the high-frequency signal in the pixels they operate upon.\nTo solve this, they proposed imposing strict lowpass filters between each generator's layers, so that the generator is forced to operate on the pixels in a way faithful to the continuous signals they represent, rather than operate on them as merely discrete signals. They further imposed rotational and translational invariance by using more signal filters. The resulting StyleGAN-3 is able to solve the texture sticking problem, as well as generating images that rotate and translate smoothly.\n\n\n== Other uses ==\nOther than for generative and discriminative modelling of data, GANs have been used for other things.\nGANs have been used for transfer learning to enforce the alignment of the latent feature space, such as in deep reinforcement learning. This works by feeding the embeddings of the source and target task to the discriminator which tries to guess the context. The resulting loss is then (inversely) backpropagated through the encoder.\n\n\n== Applications ==\n\n\n=== Science ===\nIteratively reconstruct astronomical images\nSimulate gravitational lensing for dark matter research.\nModel the distribution of dark matter in a particular direction in space and to predict the gravitational lensing that will occur.\nModel high energy jet formation and showers through calorimeters of high-energy physics experiments.\nApproximate bottlenecks in computationally expensive simulations of particle physics experiments. Applications in the context of present and proposed CERN experiments have demonstrated the potential of these methods for accelerating simulation and/or improving simulation fidelity.\nReconstruct velocity and scalar fields in turbulent flows.\nGAN-generated molecules were validated experimentally in mice.\n\n\n=== Medical ===\nOne of the major concerns in medical imaging is preserving patient privacy. Due to these reasons, researchers often face difficulties in obtaining medical images for their research purposes. GAN has been used for generating synthetic medical images, such as MRI and PET images to address this challenge.\nGAN can be used to detect glaucomatous images helping the early diagnosis which is essential to avoid partial or total loss of vision.\nGANs have been used to create forensic facial reconstructions of deceased historical figures.\n\n\n=== Malicious ===\n\nConcerns have been raised about the potential use of GAN-based human image synthesis for sinister purposes, e.g., to produce fake, possibly incriminating, photographs and videos.\nGANs can be used to generate unique, realistic profile photos of people who do not exist, in order to automate creation of fake social media profiles.\nIn 2019 the state of California considered and passed on October 3, 2019, the bill AB-602, which bans the use of human image synthesis technologies to make fake pornography without the consent of the people depicted, and bill AB-730, which prohibits distribution of manipulated videos of a political candidate within 60 days of an election. Both bills were authored by Assembly member Marc Berman and signed by Governor Gavin Newsom. The laws went into effect in 2020.\nDARPA's Media Forensics program studies ways to counteract fake media, including fake media produced using GANs.\n\n\n=== Fashion, art and advertising ===\nGANs can be used to generate art; The Verge wrote in March 2019 that \"The images created by GANs have become the defining look of contemporary AI art.\" GANs can also be used to\n\ninpaint photographs\ngenerate fashion models, shadows, photorealistic renders of interior design, industrial design, shoes, etc. Such networks were reported to be used by Facebook.\nSome have worked with using GAN for artistic creativity, as \"creative adversarial network\". A GAN, trained on a set of 15,000 portraits from WikiArt from the 14th to the 19th century, created the 2018 painting Edmond de Belamy, which sold for US$432,500.\nGANs were used by the video game modding community to up-scale low-resolution 2D textures in old video games by recreating them in 4k or higher resolutions via image training, and then down-sampling them to fit the game's native resolution (resembling supersampling anti-aliasing).\nIn 2020, Artbreeder was used to create the main antagonist in the sequel to the psychological web horror series Ben Drowned. The author would later go on to praise GAN applications for their ability to help generate assets for independent artists who are short on budget and manpower.\nIn May 2020, Nvidia researchers taught an AI system (termed \"GameGAN\") to recreate the game of Pac-Man simply by watching it being played.\nIn August 2019, a large dataset consisting of 12,197 MIDI songs each with paired lyrics and melody alignment was created for neural melody generation from lyrics using conditional GAN-LSTM (refer to sources at GitHub AI Melody Generation from Lyrics).\n\n\n=== Miscellaneous ===\nGANs have been used to \n\nshow how an individual's appearance might change with age.\nreconstruct 3D models of objects from images,\ngenerate novel objects as 3D point clouds,\nmodel patterns of motion in video.\ninpaint missing features in maps, transfer map styles in cartography or augment street view imagery.\nuse feedback to generate images and replace image search systems.\nvisualize the effect that climate change will have on specific houses.\nreconstruct an image of a person's face after listening to their voice.\nproduces videos of a person speaking, given only a single photo of that person.\nrecurrent sequence generation.\n\n\n== History ==\nIn 1991, Juergen Schmidhuber published \"artificial curiosity\", neural networks in a zero-sum game. The first network is a generative model that models a probability distribution over output patterns. The second network learns by gradient descent to predict the reactions of the environment to these patterns. GANs can be regarded as a case where the environmental reaction is 1 or 0 depending on whether the first network's output is in a given set.\nOther people had similar ideas but did not develop them similarly. An idea involving adversarial networks was published in a 2010 blog post by Olli Niemitalo. This idea was never implemented and did not involve stochasticity in the generator and thus was not a generative model. It is now known as a conditional GAN or cGAN. An idea similar to GANs was used to model animal behavior by Wei Li, Melvin Gauci and Roderich Gross in 2013.\nAnother inspiration for GANs was noise-contrastive estimation, which uses the same loss function as GANs and which Goodfellow studied during his PhD in 2010\u20132014.\nAdversarial machine learning has other uses besides generative modeling and can be applied to models other than neural networks. In control theory, adversarial learning based on neural networks was used in 2006 to train robust controllers in a game theoretic sense, by alternating the iterations between a minimizer policy, the controller, and a maximizer policy, the disturbance.\nIn 2017, a GAN was used for image enhancement focusing on realistic textures rather than pixel-accuracy, producing a higher image quality at high magnification. In 2017, the first faces were generated. These were exhibited in February 2018 at the Grand Palais. Faces generated by StyleGAN in 2019 drew comparisons with Deepfakes.\n\n\n== See also ==\nArtificial intelligence art \u2013 Visual media created with AIPages displaying short descriptions of redirect targets\nDeepfake \u2013 Realistic artificially generated media\nDeep learning \u2013 Branch of machine learning\nDiffusion model \u2013 Deep learning algorithm\nGenerative artificial intelligence \u2013 Subset of AI using generative models\nSynthetic media \u2013 Artificial production of media by automated means\n\n\n== References ==\n\n\n== External links ==\n\nKnight, Will. \"5 Big Predictions for Artificial Intelligence in 2017\". MIT Technology Review. Retrieved January 5, 2017.\nKarras, Tero; Laine, Samuli; Aila, Timo (2018). \"A Style-Based Generator Architecture for Generative Adversarial Networks\". arXiv:1812.04948 [cs.NE].\nThis Person Does Not Exist \u2013  photorealistic images of people who do not exist, generated by StyleGAN\nThis Cat Does Not Exist Archived March 5, 2019, at the Wayback Machine \u2013  photorealistic images of cats who do not exist, generated by StyleGAN\nWang, Zhengwei; She, Qi; Ward, Tomas E. (2019). \"Generative Adversarial Networks in Computer Vision: A Survey and Taxonomy\". arXiv:1906.01529 [cs.LG].",
  "summary": "A generative adversarial network (GAN) is a class of machine learning frameworks and a prominent framework for approaching generative artificial intelligence. The concept was initially developed by Ian Goodfellow and his colleagues in June 2014. In a GAN, two neural networks compete with each other in the form of a zero-sum game, where one agent's gain is another agent's loss.\nGiven a training set, this technique learns to generate new data with the same statistics as the training set. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics. Though originally proposed as a form of generative model for unsupervised learning, GANs have also proved useful for semi-supervised learning, fully supervised learning, and reinforcement learning.\nThe core idea of a GAN is based on the \"indirect\" training through the discriminator, another neural network that can tell how \"realistic\" the input seems, which itself is also being updated dynamically. This means that the generator is not trained to minimize the distance to a specific image, but rather to fool the discriminator. This enables the model to learn in an unsupervised manner.\nGANs are similar to mimicry in evolutionary biology, with an evolutionary arms race between both networks.\n\n",
  "content_length": 115794
}