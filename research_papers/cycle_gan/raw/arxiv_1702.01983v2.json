{
  "source": "arxiv",
  "query": "Cycle Generative Adversarial Networks",
  "fetched_at": "2025-11-21T18:06:49.436944",
  "title": "Face Aging With Conditional Generative Adversarial Networks",
  "url": "http://arxiv.org/abs/1702.01983v2",
  "content": "FACE AGING WITH CONDITIONAL GENERATIVE ADVERSARIAL NETWORKS\nGrigory Antipov\u22c6\u2020 Moez Baccouche\u22c6 Jean-Luc Dugelay\u2020\n\u22c6 Orange Labs, 4 rue Clos Courtel, 35512 Cesson-S\u00b4evign\u00b4e, France\n\u2020 Eurecom, 450 route des Chappes, 06410 Biot, France\nABSTRACT\nIt has been recently shown that Generative Adversarial\nNetworks (GANs) can produce synthetic images of excep-\ntional visual \ufb01delity. In this work, we propose the GAN-based\nmethod for automatic face aging. Contrary to previous works\nemploying GANs for altering of facial attributes, we make a\nparticular emphasize on preserving the original person\u2019s iden-\ntity in the aged version of his/her face. To this end, we intro-\nduce a novel approach for \u201cIdentity-Preserving\u201d optimization\nof GAN\u2019s latent vectors. The objective evaluation of the re-\nsulting aged and rejuvenated face images by the state-of-the-\nart face recognition and age estimation solutions demonstrate\nthe high potential of the proposed method.\nIndex Terms\u2014\nFace Aging, GAN, Deep Learning, Face Synthesis\n1. INTRODUCTION\nFace aging, also known as age synthesis [1] and age progres-\nsion [2], is de\ufb01ned as aesthetically rendering a face image\nwith natural aging and rejuvenating effects on the individual\nface [1]. It has plenty of applications in various domains in-\ncluding cross-age face recognition [3], \ufb01nding lost children\nand entertainment [4]. Traditional face aging approaches can\nbe roughly split between the prototyping ones [5, 6] and the\nmodeling ones [7, 8]. Prototyping approaches estimate av-\nerage faces within prede\ufb01ned age groups. The differences\nbetween these faces constitute the aging patterns which are\nfurther used to transform an input face image into the tar-\nget age group. The prototype approaches are simple and fast,\nbut since they are based on general rules, they totally discard\nthe personalized information which results in unrealistic im-\nages. On the contrary, modeling approaches employ para-\nmetric models to simulate the aging mechanisms of muscles,\nskin and skull of a particular individual. However, these ap-\nproaches often require face aging sequences of the same per-\nson with wide range of ages which are very costly to collect.\nThe presented traditional face aging approaches are lim-\nited to modeling of the aging patterns missing the global com-\nprehension of a human face (its personality traits, facial ex-\npression, possible facial accessories etc.) However, in many\nreal-life use cases, face aging must be combined with other\nface alterations, such as adding sunglasses or beard. These\nnon-trivial modi\ufb01cations require global generative models of\nhuman faces. Natural image generation has been thoroughly\nstudied for years, but it has not been until 2014 when ad-\nvances in deep learning has allowed to produce image sam-\nples and interpolations of very high visual \ufb01delity. The key\nmodel which has made it possible is called Generative Adver-\nsarial Network (GAN) [9] and is presented in Subsection 2.1.\nContrary to autoencoders (for example, variational autoen-\ncoders [10]) which optimize the L2 reconstruction loss and\nhence produce blurry images, GANs are explicitly trained to\ngenerate the most plausible and realistic images which are\nhard to distinguish from real data. GANs have already been\nemployed to perform modi\ufb01cations on human faces, such as\nchanging the hair color, adding sunglasses or even binary ag-\ning (i.e. simply making face look older or younger with-\nout precising particular age categories) [11, 12]. A common\nproblem of previous GAN-based methods of face modi\ufb01ca-\ntion [11, 12] is the fact that the original person\u2019s identity is\noften lost in the modi\ufb01ed image. Therefore, in the present\nstudy, we focus on identity-preserving face aging. In particu-\nlar, our contributions are as following:\n1. We design Age-cGAN (Age Conditional Generative\nAdversarial Network), the \ufb01rst GAN to generate high\nquality synthetic images within required age categories.\n2. We propose a novel latent vector optimization approach\nwhich allows Age-cGAN to reconstruct an input face\nimage preserving the original person\u2019s identity.\nThe rest of the paper is composed of Section 2 where we\npresent our face aging method, Section 3 where we evalu-\nate the proposed identity-preserving face reconstruction and\nage synthesis approaches, and Section 4 which concludes this\nstudy and gives the directions for the future work.\n2. PROPOSED METHOD\nOur face aging method is based on Age-cGAN, a genera-\ntive model for synthesis of human faces within required age\ncategories. The design of Age-cGAN is detailed in Subsec-\ntion 2.1. Once Age-cGAN is trained, the face aging is done\nin two steps (cf. Figure 1):\narXiv:1702.01983v2  [cs.CV]  30 May 2017\n\nEncoder\nE\n\ufffd0\nGenerator\nG\ufffd0\nIdentity \nPreserving \nOptimization\n\ufffd\u2217\nGenerator\nG\ufffd0\nGenerator\nG\n\ufffd\u2217\n(a) (b)\nLatent Vector Approximation Face Aging\n\"60+\"\nInput face\ufffd\nof age\ufffd 0\nInitial reconstruction\n\ufffd0 of age\ufffd 0\nOptimized reconstruction\n\ufffdof age\ufffd 0\nResulting face\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\nof age \u201c60+\u201d\nFig. 1. Our face aging method. (a) approximation of the latent vector to reconstruct the input image; (b) switching the age\ncondition at the input of the generator Gto perform face aging.\n1. Given an input face image x of age y0, \ufb01nd an opti-\nmal latent vector z\u2217 which allows to generate a recon-\nstructed face \u00afx = G(z\u2217,y0) as close as possible to the\ninitial one (cf. Figure 1-(a)).\n2. Given the target age ytarget, generate the resulting face\nimage xtarget = G(z\u2217,ytarget) by simply switching\nthe age at the input of the generator (cf. Figure 1-(b)).\nThe \ufb01rst step of the presented face aging method (i.e. in-\nput face reconstruction) is the key one. Therefore, in Sub-\nsection 2.2, we present our approach to approximately recon-\nstruct an input face making a particular emphasize on preserv-\ning the original person\u2019s identity in the reconstructed image.\n2.1. Age Conditional Generative Adversarial Network\nIntroduced in [9], GAN is a pair of neural networks (G,D):\nthe generator Gand the discriminator D. Gmaps vectors z\nfrom the noise space Nz with a known distribution pz to the\nimage space Nx. The generator\u2019s goal is to model the distri-\nbution pdata of the image space Nx (in this work, pdata is the\ndistribution of all possible face images). The discriminator\u2019s\ngoal is to distinguish real face images coming from the image\ndistribution pdata and synthetic images produced by the gen-\nerator. Both networks are iteratively optimized against each\nother in a minimax game (hence the name \u201cadversarial\u201d).\nConditional GAN (cGAN) [13, 14] extends the GAN\nmodel allowing the generation of images with certain at-\ntributes (\u201cconditions\u201d). In practice, conditions y \u2208Ny can\nbe any information related to the target face image: level of\nillumination, facial pose or facial attribute. More formally,\ncGAN training can be expressed as an optimization of the\nfunction v(\u03b8G,\u03b8D), where \u03b8G and \u03b8D are parameters of G\nand D, respectively:\nmin\n\u03b8G\nmax\n\u03b8D\nv(\u03b8G,\u03b8D) = Ex,y\u223cpdata[log D(x,y)]\n+ Ez\u223cpz(z),\u02dcy\u223cpy [log (1\u2212D(G(z,\u02dcy),\u02dcy))]\n(1)\nThe Age-cGAN model proposed in this work uses the\nsame design for the generator Gand the discriminator D as\nin [15]. Following [12], we inject the conditional informa-\ntion at the input of G and at the \ufb01rst convolutional layer of\nD. Age-cGAN is optimized using the ADAM algorithm [16]\nduring 100 epochs. In order to encode person\u2019s age, we have\nde\ufb01ned six age categories: 0-18, 19-29, 30-39, 40-49, 50-59\nand 60+ years old. They have been selected so that the train-\ning dataset (cf. Subsection 3.1) contains at least 5,000 exam-\nples in each age category. Thus, the conditions of Age-cGAN\nare six-dimensional one-hot vectors.\n2.2. Approximative Face Reconstruction with Age-cGAN\n2.2.1. Initial Latent Vector Approximation\nContrary to autoencoders, cGANs do not have an explicit\nmechanism for inverse mapping of an input image xwith at-\ntributes y to a latent vector z which is necessary for image\nreconstruction: x = G(z,y). As in [12, 17], we circum-\nvent this problem by training an encoder E, a neural network\nwhich approximates the inverse mapping.\nIn order to train E, we generate a synthetic dataset of\n100K pairs (xi,G(zi,yi)), i = 1 ,..., 105, where zi \u223c\nN(0,I) are random latent vectors, yi \u223cU are random age\nconditions uniformly distributed between six age categories,\nG(z,y) is the generator of the priorly trained Age-cGAN,\nand xi = G(zi,yi) are the synthetic face images. Eis trained\nto minimize the Euclidean distances between estimated latent\nvectors E(xi) and the ground truth latent vectors zi.\nDespite GANs are arguably the most powerful generative\nmodels today, they cannot exactly reproduce the details of all\nreal-life face images with their in\ufb01nite possibilities of minor\nfacial details, accessories, backgrounds etc. In general, a nat-\nural input face image can be ratherapproximated than exactly\nreconstructed with Age-cGAN. Thus,Eproduce initial latent\napproximations z0 which are good enough to serve as initial-\nizations of our optimization algorithm explained hereafter.\n\n2.2.2. Latent Vector Optimization\nFace aging task, which is the ultimate goal of this work, as-\nsumes that while the age of a person must be changed, his/her\nidentity should remain intact. In Subsection 3.3, it is shown\nthat though initial latent approximationsz0 produced by Ere-\nsult in visually plausible face reconstructions, the identity of\nthe original person is lost in about 50% of cases (cf. Table 1).\nTherefore, initial latent approximations z0 must be improved.\nIn [17], the similar problem of image reconstruction en-\nhancement is solved by optimizing the latent vector zto min-\nimize the pixelwise Euclidean distance between the ground\ntruth image x and the reconstructed image \u00afx. However, in\nthe context of face reconstruction, the described \u201cPixelwise\u201d\nlatent vector optimization has two clear downsides: \ufb01rstly, it\nincreases the blurriness of reconstructions and secondly (and\nmore importantly), it focuses on unnecessary details of input\nface images which have a strong impact on pixel level, but\nhave nothing to do with a person\u2019s identity (like background,\nsunglasses, hairstyle, moustache etc.)\nTherefore, in this paper, we propose a novel \u201cIdentity-\nPreserving\u201d latent vector optimization approach. The key idea\nis simple: given a face recognition neural network FR able\nto recognize a person\u2019s identity in an input face image x, the\ndifference between the identities in the original and recon-\nstructed images x and \u00afx can be expressed as the Euclidean\ndistance between the corresponding embeddings FR(x) and\nFR(\u00afx). Hence, minimizing this distance should improve the\nidentity preservation in the reconstructed image \u00afx:\nz\u2217\nIP = arg min\nz\n||FR(x) \u2212FR(\u00afx)||L2 (2)\nIn this paper, FR is an internal implementation of the\n\u201cFaceNet\u201d CNN [18]. The generator G(z,y) and the face\nrecognition network FR(x) are differentiable with respect\nto their inputs, so the optimization problem 2 can be solved\nusing the L-BFGS-B algorithm [19] with backtracking line\nsearch. The L-BFGS-B algorithm is initialized with initial la-\ntent approximations z0. Here and below in this work, we re-\nfer to the results of \u201cPixelwise\u201d and \u201cIdentity-Preserving\u201d la-\ntent vector optimizations as optimized latent approximations\nand denote them respectively as z\u2217pixel and z\u2217IP. In Sub-\nsection 3.3, it is shown both subjectively and objectively that\nz\u2217IP better preserves a person\u2019s identity thanz\u2217pixel.\n3. EXPERIMENTS\n3.1. Dataset\nAge-cGAN has been trained on the IMDB-Wiki cleaned\ndataset [20] of about 120K images which is a subset of the\npublic IMDB-Wiki dataset [21]. More precisely, 110K images\nhave been used for training of Age-cGAN and the remaining\n10K have been used for the evaluation of identity-preserving\nface reconstruction (cf. Subsection 3.3).\n3.2. Age-Conditioned Face Generation\nFigure 2 illustrates synthetic faces of different ages generated\nwith our Age-cGAN. Each row corresponds to a random la-\ntent vector zand six columns correspond to six age conditions\ny. Age-cGAN perfectly disentangles image information en-\ncoded by latent vectors z and by conditions y making them\nindependent. More precisely, we observe that latent vectors z\nencode person\u2019s identity, facial pose, hair style, etc., while y\nencodes uniquely the age.\n0-18 19-29 30-39 40-49 50-59 60+\nFig. 2. Examples of synthetic images generated by our Age-\ncGAN using two random latent vectors z (rows) and condi-\ntioned on the respective age categories y(columns).\nIn order to objectively measure how well Age-cGAN\nmanages to generate faces belonging to precise age cate-\ngories, we have used the state-of-the-art age estimation CNN\ndescribed in [20]. We compare the performances of the age\nestimation CNN on real images from the test part of IMDB-\nWiki cleaned and on 10K synthetic images generated by\nAge-cGAN. Despite the age estimation CNN has never seen\nsynthetic images during the training, the resulting mean age\nestimation accuracy on synthetic images is just 17% lower\nthan on natural ones. It proves that our model can be used for\ngeneration of realistic face images with the required age.\n3.3. Identity-Preserving Face Reconstruction and Aging\nAs explained in Subsection 2.2, we perform face reconstruc-\ntion (i.e. the \ufb01rst step of our face aging method) in two\niterations: \ufb01rstly, (1) using initial latent approximations ob-\ntained from the encoderEand then (2) using optimized latent\napproximations obtained by either \u201cPixelwise\u201d or \u201cIdentity-\nPreserving\u201d optimization approaches. Some examples of\noriginal test images, their initial and optimized reconstruc-\ntions are presented in Figure 3 ((a), (b) and (c), respectively).\nIt can be seen in Figure 3 that the optimized reconstruc-\ntions are closer to the original images than the initial ones.\nHowever, the choice is more complicated when it comes to the\ncomparison of the two latent vector optimization approaches.\nOn the one hand, \u201cPixelwise\u201d optimization better re\ufb02ects su-\nper\ufb01cial face details: such as the hair color in the \ufb01rst line\nand the beard in the last line. On the other hand, the identity\ntraits (like the form of the head in the second line or the form\n\nOriginal Initial \nReconstruction\nPixelwiseIP\nReconstruction\nOptimization\n(a) (b) (c)\nFace Aging\n0-18 19-29 30-39 40-49 50-59 60+\n(d)\nFig. 3. Examples of face reconstruction and aging. (a) original test images, (b) reconstructed images generated using the initial\nlatent approximations: z0, (c) reconstructed images generated using the \u201cPixelwise\u201d and \u201cIdentity-Preserving\u201d optimized latent\napproximations: z\u2217pixel and z\u2217IP, and (d) aging of the reconstructed images generated using the identity-preserving z\u2217IP\nlatent approximations and conditioned on the respective age categories y(one per column).\nReconstruction type FR score\nInitial Reconstruction (z0) 53.2%\n\u201cPixelwise\u201d Optimization (z\u2217\npixel) 59.8%\n\u201cIdentity-Preserving\u201d Optimization (z\u2217\nIP ) 82.9%\nTable 1. \u201cOpenFace\u201d Face Recognition (FR) scores on three\ncompared types of face reconstruction.\nof the eyes in the \ufb01rst and last lines) are better represented by\n\u201cIdentity-Preserving\u201d optimization.\nFor the sake of objective comparison of the two ap-\nproaches for the identity-preserving face reconstruction, we\nemploy \u201cOpenFace\u201d [22] software which is currently one\nof the best open-source face recognition solutions. Given\ntwo face images, \u201cOpenFace\u201d decides whether they belong\nto the same person or not. Using both approaches, we have\nreconstructed 10K test images of the IMDB-Wiki cleaned\ndataset and fed the resulting images alongside corresponding\noriginals to \u201cOpenFace\u201d. Table 1 presents the percentages\nof \u201cOpenFace\u201d positive outputs (i.e. when the software be-\nlieved that a face image and its reconstruction belong to the\nsame person). The results con\ufb01rm the visual observations\npresented above. Initial reconstructions allow \u201cOpenFace\u201d to\nrecognize the original person only in half of test examples.\nThis percentage is slightly increased by \u201cPixelwise\u201d opti-\nmization but the improvement is marginal. On the contrary,\n\u201cIdentity-Preserving\u201d optimization approach preserves the\nperson\u2019s identities much better demonstrating by far the best\nface recognition performance of 82.9%.\nFinally, once an identity-preserving face reconstruction\n\u00afx= G(z\u2217IP,y0) of the original image xis obtained, we can\nsimply substitute the initial age category y0 by the target age\ncategory ytarget in order to obtain the output of our face aging\nmethod: xtarget = G(z\u2217IP,ytarget). Figure 3-(d) illustrates\nhow it works in practice. Our method manages both to realis-\ntically age an originally young face into a senior one as in the\n2nd line of Figure 3 and vice-versa as in the last line.\n4. CONCLUSIONS AND FUTURE WORK\nIn this work, we have proposed a new effective method for\nsynthetic aging of human faces based on Age Conditional\nGenerative Adversarial Network (Age-cGAN). The method\nis composed of two steps: (1) input face reconstruction re-\nquiring the solution of an optimization problem in order to\n\ufb01nd an optimal latent approximation z\u2217, (2) and face aging it-\nself performed by a simple change of condition yat the input\nof the generator. The cornerstone of our method is the novel\n\u201cIdentity-Preserving\u201d latent vector optimization approach al-\nlowing to preserve the original person\u2019s identity in the recon-\nstruction. This approach is universal meaning that it can be\nused to preserve identity not only for face aging but also for\nother face alterations (e.g. adding a beard, sunglasses etc.)\nOur face aging method can be used for synthetic augmen-\ntation of face datasets and for improving the robustness of\nface recognition solutions in cross-age scenarios. It is part of\nour future work. Moreover, we believe that the face recon-\nstruction part of our method can be further improved by com-\nbining \u201cPixelwise\u201d and \u201cIdentity-Preserving\u201d approaches into\none optimization objective. We are also planning to explore\nthis path in our further studies.\n\n5. REFERENCES\n[1] Yun Fu, Guodong Guo, and Thomas S Huang, \u201cAge\nsynthesis and estimation via faces: A survey,\u201d IEEE\nTransactions on Pattern Analysis and Machine Intelli-\ngence, vol. 32, no. 11, pp. 1955\u20131976, 2010.\n[2] Xiangbo Shu, Jinhui Tang, Hanjiang Lai, Luoqi Liu, and\nShuicheng Yan, \u201cPersonalized age progression with ag-\ning dictionary,\u201d inProceedings of International Confer-\nence on Computer Vision, Santiago, Chile, 2015.\n[3] Unsang Park, Yiying Tong, and Anil K Jain, \u201cAge-\ninvariant face recognition,\u201d IEEE Transactions on Pat-\ntern Analysis and Machine Intelligence , vol. 32, no. 5,\npp. 947\u2013954, 2010.\n[4] Wei Wang, Zhen Cui, Yan Yan, Jiashi Feng, Shuicheng\nYan, Xiangbo Shu, and Nicu Sebe, \u201cRecurrent face ag-\ning,\u201d in Proceedings of Computer Vision and Pattern\nRecognition, Las Vegas, USA, 2016.\n[5] Bernard Tiddeman, Michael Burt, and David Perrett,\n\u201cPrototyping and transforming facial textures for per-\nception research,\u201d IEEE Computer Graphics and Ap-\nplications, vol. 21, no. 5, pp. 42\u201350, 2001.\n[6] Ira Kemelmacher-Shlizerman, Supasorn Suwajanakorn,\nand Steven M Seitz, \u201cIllumination-aware age progres-\nsion,\u201d in Proceedings of Computer Vision and Pattern\nRecognition, Columbus, USA, 2014.\n[7] Jinli Suo, Song-Chun Zhu, Shiguang Shan, and Xilin\nChen, \u201cA compositional and dynamic model for face\naging,\u201d IEEE Transactions on Pattern Analysis and Ma-\nchine Intelligence, vol. 32, no. 3, pp. 385\u2013401, 2010.\n[8] Yusuke Tazoe, Hiroaki Gohara, Akinobu Maejima, and\nShigeo Morishima, \u201cFacial aging simulator consider-\ning geometry and patch-tiled texture,\u201d inProceedings of\nACM SIGGRAPH, Los Angeles, USA, 2012.\n[9] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,\nBing Xu, David Warde-Farley, Sherjil Ozair, Aaron\nCourville, and Yoshua Bengio, \u201cGenerative adversarial\nnets,\u201d inProceedings of advances in Neural Information\nProcessing Systems, Montreal, Canada, 2015.\n[10] Diederik P Kingma and Max Welling, \u201cAuto-encoding\nvariational bayes,\u201d inProceedings of International Con-\nference on Learning Representations , Banff, Canada,\n2014.\n[11] Anders Boesen Lindbo Larsen, S\u00f8ren Kaae S\u00f8nderby,\nHugo Larochelle, and Ole Winther, \u201cAutoencoding\nbeyond pixels using a learned similarity metric,\u201d in\nProceedings of International Conference on Machine\nLearning, New York, USA, 2016.\n[12] Guim Perarnau, Joost van de Weijer, Bogdan Raducanu,\nand Jose M \u00b4Alvarez, \u201cInvertible conditional gans for\nimage editing,\u201d in Proceedings of advances in Neural\nInformation Processing Systems Workshops, Barcelona,\nSpain, 2016.\n[13] Mehdi Mirza and Simon Osindero, \u201cConditional gen-\nerative adversarial nets,\u201d in Proceedings of advances\nin Neural Information Processing Systems , Montreal,\nCanada, 2014.\n[14] Jon Gauthier, \u201cConditional generative adversarial nets\nfor convolutional face generation,\u201d Class Project for\nStanford CS231N: Convolutional Neural Networks for\nVisual Recognition, 2014.\n[15] Alec Radford, Luke Metz, and Soumith Chintala, \u201cUn-\nsupervised representation learning with deep convolu-\ntional generative adversarial networks,\u201d in Proceedings\nof International Conference on Learning Representa-\ntions, San Juan, Puerto Rico, 2016.\n[16] Diederik Kingma and Jimmy Ba, \u201cAdam: A\nmethod for stochastic optimization,\u201d arXiv preprint\narXiv:1412.6980, 2014.\n[17] Jun-Yan Zhu, Philipp Kr \u00a8ahenb\u00a8uhl, Eli Shechtman, and\nAlexei A Efros, \u201cGenerative visual manipulation on the\nnatural image manifold,\u201d in Proceedings of European\nConference on Computer Vision , Amsterdam, Nether-\nlands, 2016.\n[18] Florian Schroff, Dmitry Kalenichenko, and James\nPhilbin, \u201cFacenet: A uni\ufb01ed embedding for face recog-\nnition and clustering,\u201d in Proceedings of Computer Vi-\nsion and Pattern Recognition, Boston, USA, 2015.\n[19] Richard H Byrd, Peihuang Lu, Jorge Nocedal, and\nCiyou Zhu, \u201cA limited memory algorithm for bound\nconstrained optimization,\u201d SIAM Journal on Scienti\ufb01c\nComputing, vol. 16, no. 5, pp. 1190\u20131208, 1995.\n[20] Grigory Antipov, Moez Baccouche, Sid-Ahmed\nBerrani, and Jean-Luc Dugelay, \u201cApparent age es-\ntimation from face images combining general and\nchildren-specialized deep learning models,\u201d in Pro-\nceedings of Computer Vision and Pattern Recognition\nWorkshops, Las Vegas, USA, 2016.\n[21] Rasmus Rothe, Radu Timofte, and Luc Van Gool, \u201cDex:\nDeep expectation of apparent age from a single image,\u201d\nin Proceedings of International Conference on Com-\nputer Vision Workshops, Santiago, Chile, 2015.\n[22] Brandon Amos, Bartosz Ludwiczuk, and Mahadev\nSatyanarayanan, \u201cOpenface: A general-purpose face\nrecognition library with mobile applications,\u201d Tech.\nRep., CMU-CS-16-118, CMU School of Computer Sci-\nence, 2016.",
  "authors": [
    "Grigory Antipov",
    "Moez Baccouche",
    "Jean-Luc Dugelay"
  ],
  "summary": "It has been recently shown that Generative Adversarial Networks (GANs) can produce synthetic images of exceptional visual fidelity. In this work, we propose the GAN-based method for automatic face aging. Contrary to previous works employing GANs for altering of facial attributes, we make a particular emphasize on preserving the original person's identity in the aged version of his/her face. To this end, we introduce a novel approach for \"Identity-Preserving\" optimization of GAN's latent vectors. The objective evaluation of the resulting aged and rejuvenated face images by the state-of-the-art face recognition and age estimation solutions demonstrate the high potential of the proposed method.",
  "pdf_url": "https://arxiv.org/pdf/1702.01983v2",
  "entry_id": "http://arxiv.org/abs/1702.01983v2",
  "published": "2017-02-07",
  "updated": "2017-05-30",
  "comment": "5 pages, 3 figures, accepted at ICIP 2017. With respect to v1: (1) changed the abbreviation of the main model from \"acGAN\" to \"Age-cGAN\" in order to avoid confusion with \"Auxiliary Classifier Generative Adversarial Networks\" introduced by Odena et al.; (2) corrected a typo in Formula 1",
  "journal_ref": null,
  "doi": null,
  "primary_category": "cs.CV",
  "categories": [
    "cs.CV"
  ],
  "links": [
    {
      "href": "https://arxiv.org/abs/1702.01983v2",
      "rel": "alternate",
      "title": null
    },
    {
      "href": "https://arxiv.org/pdf/1702.01983v2",
      "rel": "related",
      "title": "pdf"
    }
  ],
  "full_text": "FACE AGING WITH CONDITIONAL GENERATIVE ADVERSARIAL NETWORKS\nGrigory Antipov\u22c6\u2020 Moez Baccouche\u22c6 Jean-Luc Dugelay\u2020\n\u22c6 Orange Labs, 4 rue Clos Courtel, 35512 Cesson-S\u00b4evign\u00b4e, France\n\u2020 Eurecom, 450 route des Chappes, 06410 Biot, France\nABSTRACT\nIt has been recently shown that Generative Adversarial\nNetworks (GANs) can produce synthetic images of excep-\ntional visual \ufb01delity. In this work, we propose the GAN-based\nmethod for automatic face aging. Contrary to previous works\nemploying GANs for altering of facial attributes, we make a\nparticular emphasize on preserving the original person\u2019s iden-\ntity in the aged version of his/her face. To this end, we intro-\nduce a novel approach for \u201cIdentity-Preserving\u201d optimization\nof GAN\u2019s latent vectors. The objective evaluation of the re-\nsulting aged and rejuvenated face images by the state-of-the-\nart face recognition and age estimation solutions demonstrate\nthe high potential of the proposed method.\nIndex Terms\u2014\nFace Aging, GAN, Deep Learning, Face Synthesis\n1. INTRODUCTION\nFace aging, also known as age synthesis [1] and age progres-\nsion [2], is de\ufb01ned as aesthetically rendering a face image\nwith natural aging and rejuvenating effects on the individual\nface [1]. It has plenty of applications in various domains in-\ncluding cross-age face recognition [3], \ufb01nding lost children\nand entertainment [4]. Traditional face aging approaches can\nbe roughly split between the prototyping ones [5, 6] and the\nmodeling ones [7, 8]. Prototyping approaches estimate av-\nerage faces within prede\ufb01ned age groups. The differences\nbetween these faces constitute the aging patterns which are\nfurther used to transform an input face image into the tar-\nget age group. The prototype approaches are simple and fast,\nbut since they are based on general rules, they totally discard\nthe personalized information which results in unrealistic im-\nages. On the contrary, modeling approaches employ para-\nmetric models to simulate the aging mechanisms of muscles,\nskin and skull of a particular individual. However, these ap-\nproaches often require face aging sequences of the same per-\nson with wide range of ages which are very costly to collect.\nThe presented traditional face aging approaches are lim-\nited to modeling of the aging patterns missing the global com-\nprehension of a human face (its personality traits, facial ex-\npression, possible facial accessories etc.) However, in many\nreal-life use cases, face aging must be combined with other\nface alterations, such as adding sunglasses or beard. These\nnon-trivial modi\ufb01cations require global generative models of\nhuman faces. Natural image generation has been thoroughly\nstudied for years, but it has not been until 2014 when ad-\nvances in deep learning has allowed to produce image sam-\nples and interpolations of very high visual \ufb01delity. The key\nmodel which has made it possible is called Generative Adver-\nsarial Network (GAN) [9] and is presented in Subsection 2.1.\nContrary to autoencoders (for example, variational autoen-\ncoders [10]) which optimize the L2 reconstruction loss and\nhence produce blurry images, GANs are explicitly trained to\ngenerate the most plausible and realistic images which are\nhard to distinguish from real data. GANs have already been\nemployed to perform modi\ufb01cations on human faces, such as\nchanging the hair color, adding sunglasses or even binary ag-\ning (i.e. simply making face look older or younger with-\nout precising particular age categories) [11, 12]. A common\nproblem of previous GAN-based methods of face modi\ufb01ca-\ntion [11, 12] is the fact that the original person\u2019s identity is\noften lost in the modi\ufb01ed image. Therefore, in the present\nstudy, we focus on identity-preserving face aging. In particu-\nlar, our contributions are as following:\n1. We design Age-cGAN (Age Conditional Generative\nAdversarial Network), the \ufb01rst GAN to generate high\nquality synthetic images within required age categories.\n2. We propose a novel latent vector optimization approach\nwhich allows Age-cGAN to reconstruct an input face\nimage preserving the original person\u2019s identity.\nThe rest of the paper is composed of Section 2 where we\npresent our face aging method, Section 3 where we evalu-\nate the proposed identity-preserving face reconstruction and\nage synthesis approaches, and Section 4 which concludes this\nstudy and gives the directions for the future work.\n2. PROPOSED METHOD\nOur face aging method is based on Age-cGAN, a genera-\ntive model for synthesis of human faces within required age\ncategories. The design of Age-cGAN is detailed in Subsec-\ntion 2.1. Once Age-cGAN is trained, the face aging is done\nin two steps (cf. Figure 1):\narXiv:1702.01983v2  [cs.CV]  30 May 2017\n\nEncoder\nE\n\ufffd0\nGenerator\nG\ufffd0\nIdentity \nPreserving \nOptimization\n\ufffd\u2217\nGenerator\nG\ufffd0\nGenerator\nG\n\ufffd\u2217\n(a) (b)\nLatent Vector Approximation Face Aging\n\"60+\"\nInput face\ufffd\nof age\ufffd 0\nInitial reconstruction\n\ufffd0 of age\ufffd 0\nOptimized reconstruction\n\ufffdof age\ufffd 0\nResulting face\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\nof age \u201c60+\u201d\nFig. 1. Our face aging method. (a) approximation of the latent vector to reconstruct the input image; (b) switching the age\ncondition at the input of the generator Gto perform face aging.\n1. Given an input face image x of age y0, \ufb01nd an opti-\nmal latent vector z\u2217 which allows to generate a recon-\nstructed face \u00afx = G(z\u2217,y0) as close as possible to the\ninitial one (cf. Figure 1-(a)).\n2. Given the target age ytarget, generate the resulting face\nimage xtarget = G(z\u2217,ytarget) by simply switching\nthe age at the input of the generator (cf. Figure 1-(b)).\nThe \ufb01rst step of the presented face aging method (i.e. in-\nput face reconstruction) is the key one. Therefore, in Sub-\nsection 2.2, we present our approach to approximately recon-\nstruct an input face making a particular emphasize on preserv-\ning the original person\u2019s identity in the reconstructed image.\n2.1. Age Conditional Generative Adversarial Network\nIntroduced in [9], GAN is a pair of neural networks (G,D):\nthe generator Gand the discriminator D. Gmaps vectors z\nfrom the noise space Nz with a known distribution pz to the\nimage space Nx. The generator\u2019s goal is to model the distri-\nbution pdata of the image space Nx (in this work, pdata is the\ndistribution of all possible face images). The discriminator\u2019s\ngoal is to distinguish real face images coming from the image\ndistribution pdata and synthetic images produced by the gen-\nerator. Both networks are iteratively optimized against each\nother in a minimax game (hence the name \u201cadversarial\u201d).\nConditional GAN (cGAN) [13, 14] extends the GAN\nmodel allowing the generation of images with certain at-\ntributes (\u201cconditions\u201d). In practice, conditions y \u2208Ny can\nbe any information related to the target face image: level of\nillumination, facial pose or facial attribute. More formally,\ncGAN training can be expressed as an optimization of the\nfunction v(\u03b8G,\u03b8D), where \u03b8G and \u03b8D are parameters of G\nand D, respectively:\nmin\n\u03b8G\nmax\n\u03b8D\nv(\u03b8G,\u03b8D) = Ex,y\u223cpdata[log D(x,y)]\n+ Ez\u223cpz(z),\u02dcy\u223cpy [log (1\u2212D(G(z,\u02dcy),\u02dcy))]\n(1)\nThe Age-cGAN model proposed in this work uses the\nsame design for the generator Gand the discriminator D as\nin [15]. Following [12], we inject the conditional informa-\ntion at the input of G and at the \ufb01rst convolutional layer of\nD. Age-cGAN is optimized using the ADAM algorithm [16]\nduring 100 epochs. In order to encode person\u2019s age, we have\nde\ufb01ned six age categories: 0-18, 19-29, 30-39, 40-49, 50-59\nand 60+ years old. They have been selected so that the train-\ning dataset (cf. Subsection 3.1) contains at least 5,000 exam-\nples in each age category. Thus, the conditions of Age-cGAN\nare six-dimensional one-hot vectors.\n2.2. Approximative Face Reconstruction with Age-cGAN\n2.2.1. Initial Latent Vector Approximation\nContrary to autoencoders, cGANs do not have an explicit\nmechanism for inverse mapping of an input image xwith at-\ntributes y to a latent vector z which is necessary for image\nreconstruction: x = G(z,y). As in [12, 17], we circum-\nvent this problem by training an encoder E, a neural network\nwhich approximates the inverse mapping.\nIn order to train E, we generate a synthetic dataset of\n100K pairs (xi,G(zi,yi)), i = 1 ,..., 105, where zi \u223c\nN(0,I) are random latent vectors, yi \u223cU are random age\nconditions uniformly distributed between six age categories,\nG(z,y) is the generator of the priorly trained Age-cGAN,\nand xi = G(zi,yi) are the synthetic face images. Eis trained\nto minimize the Euclidean distances between estimated latent\nvectors E(xi) and the ground truth latent vectors zi.\nDespite GANs are arguably the most powerful generative\nmodels today, they cannot exactly reproduce the details of all\nreal-life face images with their in\ufb01nite possibilities of minor\nfacial details, accessories, backgrounds etc. In general, a nat-\nural input face image can be ratherapproximated than exactly\nreconstructed with Age-cGAN. Thus,Eproduce initial latent\napproximations z0 which are good enough to serve as initial-\nizations of our optimization algorithm explained hereafter.\n\n2.2.2. Latent Vector Optimization\nFace aging task, which is the ultimate goal of this work, as-\nsumes that while the age of a person must be changed, his/her\nidentity should remain intact. In Subsection 3.3, it is shown\nthat though initial latent approximationsz0 produced by Ere-\nsult in visually plausible face reconstructions, the identity of\nthe original person is lost in about 50% of cases (cf. Table 1).\nTherefore, initial latent approximations z0 must be improved.\nIn [17], the similar problem of image reconstruction en-\nhancement is solved by optimizing the latent vector zto min-\nimize the pixelwise Euclidean distance between the ground\ntruth image x and the reconstructed image \u00afx. However, in\nthe context of face reconstruction, the described \u201cPixelwise\u201d\nlatent vector optimization has two clear downsides: \ufb01rstly, it\nincreases the blurriness of reconstructions and secondly (and\nmore importantly), it focuses on unnecessary details of input\nface images which have a strong impact on pixel level, but\nhave nothing to do with a person\u2019s identity (like background,\nsunglasses, hairstyle, moustache etc.)\nTherefore, in this paper, we propose a novel \u201cIdentity-\nPreserving\u201d latent vector optimization approach. The key idea\nis simple: given a face recognition neural network FR able\nto recognize a person\u2019s identity in an input face image x, the\ndifference between the identities in the original and recon-\nstructed images x and \u00afx can be expressed as the Euclidean\ndistance between the corresponding embeddings FR(x) and\nFR(\u00afx). Hence, minimizing this distance should improve the\nidentity preservation in the reconstructed image \u00afx:\nz\u2217\nIP = arg min\nz\n||FR(x) \u2212FR(\u00afx)||L2 (2)\nIn this paper, FR is an internal implementation of the\n\u201cFaceNet\u201d CNN [18]. The generator G(z,y) and the face\nrecognition network FR(x) are differentiable with respect\nto their inputs, so the optimization problem 2 can be solved\nusing the L-BFGS-B algorithm [19] with backtracking line\nsearch. The L-BFGS-B algorithm is initialized with initial la-\ntent approximations z0. Here and below in this work, we re-\nfer to the results of \u201cPixelwise\u201d and \u201cIdentity-Preserving\u201d la-\ntent vector optimizations as optimized latent approximations\nand denote them respectively as z\u2217pixel and z\u2217IP. In Sub-\nsection 3.3, it is shown both subjectively and objectively that\nz\u2217IP better preserves a person\u2019s identity thanz\u2217pixel.\n3. EXPERIMENTS\n3.1. Dataset\nAge-cGAN has been trained on the IMDB-Wiki cleaned\ndataset [20] of about 120K images which is a subset of the\npublic IMDB-Wiki dataset [21]. More precisely, 110K images\nhave been used for training of Age-cGAN and the remaining\n10K have been used for the evaluation of identity-preserving\nface reconstruction (cf. Subsection 3.3).\n3.2. Age-Conditioned Face Generation\nFigure 2 illustrates synthetic faces of different ages generated\nwith our Age-cGAN. Each row corresponds to a random la-\ntent vector zand six columns correspond to six age conditions\ny. Age-cGAN perfectly disentangles image information en-\ncoded by latent vectors z and by conditions y making them\nindependent. More precisely, we observe that latent vectors z\nencode person\u2019s identity, facial pose, hair style, etc., while y\nencodes uniquely the age.\n0-18 19-29 30-39 40-49 50-59 60+\nFig. 2. Examples of synthetic images generated by our Age-\ncGAN using two random latent vectors z (rows) and condi-\ntioned on the respective age categories y(columns).\nIn order to objectively measure how well Age-cGAN\nmanages to generate faces belonging to precise age cate-\ngories, we have used the state-of-the-art age estimation CNN\ndescribed in [20]. We compare the performances of the age\nestimation CNN on real images from the test part of IMDB-\nWiki cleaned and on 10K synthetic images generated by\nAge-cGAN. Despite the age estimation CNN has never seen\nsynthetic images during the training, the resulting mean age\nestimation accuracy on synthetic images is just 17% lower\nthan on natural ones. It proves that our model can be used for\ngeneration of realistic face images with the required age.\n3.3. Identity-Preserving Face Reconstruction and Aging\nAs explained in Subsection 2.2, we perform face reconstruc-\ntion (i.e. the \ufb01rst step of our face aging method) in two\niterations: \ufb01rstly, (1) using initial latent approximations ob-\ntained from the encoderEand then (2) using optimized latent\napproximations obtained by either \u201cPixelwise\u201d or \u201cIdentity-\nPreserving\u201d optimization approaches. Some examples of\noriginal test images, their initial and optimized reconstruc-\ntions are presented in Figure 3 ((a), (b) and (c), respectively).\nIt can be seen in Figure 3 that the optimized reconstruc-\ntions are closer to the original images than the initial ones.\nHowever, the choice is more complicated when it comes to the\ncomparison of the two latent vector optimization approaches.\nOn the one hand, \u201cPixelwise\u201d optimization better re\ufb02ects su-\nper\ufb01cial face details: such as the hair color in the \ufb01rst line\nand the beard in the last line. On the other hand, the identity\ntraits (like the form of the head in the second line or the form\n\nOriginal Initial \nReconstruction\nPixelwiseIP\nReconstruction\nOptimization\n(a) (b) (c)\nFace Aging\n0-18 19-29 30-39 40-49 50-59 60+\n(d)\nFig. 3. Examples of face reconstruction and aging. (a) original test images, (b) reconstructed images generated using the initial\nlatent approximations: z0, (c) reconstructed images generated using the \u201cPixelwise\u201d and \u201cIdentity-Preserving\u201d optimized latent\napproximations: z\u2217pixel and z\u2217IP, and (d) aging of the reconstructed images generated using the identity-preserving z\u2217IP\nlatent approximations and conditioned on the respective age categories y(one per column).\nReconstruction type FR score\nInitial Reconstruction (z0) 53.2%\n\u201cPixelwise\u201d Optimization (z\u2217\npixel) 59.8%\n\u201cIdentity-Preserving\u201d Optimization (z\u2217\nIP ) 82.9%\nTable 1. \u201cOpenFace\u201d Face Recognition (FR) scores on three\ncompared types of face reconstruction.\nof the eyes in the \ufb01rst and last lines) are better represented by\n\u201cIdentity-Preserving\u201d optimization.\nFor the sake of objective comparison of the two ap-\nproaches for the identity-preserving face reconstruction, we\nemploy \u201cOpenFace\u201d [22] software which is currently one\nof the best open-source face recognition solutions. Given\ntwo face images, \u201cOpenFace\u201d decides whether they belong\nto the same person or not. Using both approaches, we have\nreconstructed 10K test images of the IMDB-Wiki cleaned\ndataset and fed the resulting images alongside corresponding\noriginals to \u201cOpenFace\u201d. Table 1 presents the percentages\nof \u201cOpenFace\u201d positive outputs (i.e. when the software be-\nlieved that a face image and its reconstruction belong to the\nsame person). The results con\ufb01rm the visual observations\npresented above. Initial reconstructions allow \u201cOpenFace\u201d to\nrecognize the original person only in half of test examples.\nThis percentage is slightly increased by \u201cPixelwise\u201d opti-\nmization but the improvement is marginal. On the contrary,\n\u201cIdentity-Preserving\u201d optimization approach preserves the\nperson\u2019s identities much better demonstrating by far the best\nface recognition performance of 82.9%.\nFinally, once an identity-preserving face reconstruction\n\u00afx= G(z\u2217IP,y0) of the original image xis obtained, we can\nsimply substitute the initial age category y0 by the target age\ncategory ytarget in order to obtain the output of our face aging\nmethod: xtarget = G(z\u2217IP,ytarget). Figure 3-(d) illustrates\nhow it works in practice. Our method manages both to realis-\ntically age an originally young face into a senior one as in the\n2nd line of Figure 3 and vice-versa as in the last line.\n4. CONCLUSIONS AND FUTURE WORK\nIn this work, we have proposed a new effective method for\nsynthetic aging of human faces based on Age Conditional\nGenerative Adversarial Network (Age-cGAN). The method\nis composed of two steps: (1) input face reconstruction re-\nquiring the solution of an optimization problem in order to\n\ufb01nd an optimal latent approximation z\u2217, (2) and face aging it-\nself performed by a simple change of condition yat the input\nof the generator. The cornerstone of our method is the novel\n\u201cIdentity-Preserving\u201d latent vector optimization approach al-\nlowing to preserve the original person\u2019s identity in the recon-\nstruction. This approach is universal meaning that it can be\nused to preserve identity not only for face aging but also for\nother face alterations (e.g. adding a beard, sunglasses etc.)\nOur face aging method can be used for synthetic augmen-\ntation of face datasets and for improving the robustness of\nface recognition solutions in cross-age scenarios. It is part of\nour future work. Moreover, we believe that the face recon-\nstruction part of our method can be further improved by com-\nbining \u201cPixelwise\u201d and \u201cIdentity-Preserving\u201d approaches into\none optimization objective. We are also planning to explore\nthis path in our further studies.\n\n5. REFERENCES\n[1] Yun Fu, Guodong Guo, and Thomas S Huang, \u201cAge\nsynthesis and estimation via faces: A survey,\u201d IEEE\nTransactions on Pattern Analysis and Machine Intelli-\ngence, vol. 32, no. 11, pp. 1955\u20131976, 2010.\n[2] Xiangbo Shu, Jinhui Tang, Hanjiang Lai, Luoqi Liu, and\nShuicheng Yan, \u201cPersonalized age progression with ag-\ning dictionary,\u201d inProceedings of International Confer-\nence on Computer Vision, Santiago, Chile, 2015.\n[3] Unsang Park, Yiying Tong, and Anil K Jain, \u201cAge-\ninvariant face recognition,\u201d IEEE Transactions on Pat-\ntern Analysis and Machine Intelligence , vol. 32, no. 5,\npp. 947\u2013954, 2010.\n[4] Wei Wang, Zhen Cui, Yan Yan, Jiashi Feng, Shuicheng\nYan, Xiangbo Shu, and Nicu Sebe, \u201cRecurrent face ag-\ning,\u201d in Proceedings of Computer Vision and Pattern\nRecognition, Las Vegas, USA, 2016.\n[5] Bernard Tiddeman, Michael Burt, and David Perrett,\n\u201cPrototyping and transforming facial textures for per-\nception research,\u201d IEEE Computer Graphics and Ap-\nplications, vol. 21, no. 5, pp. 42\u201350, 2001.\n[6] Ira Kemelmacher-Shlizerman, Supasorn Suwajanakorn,\nand Steven M Seitz, \u201cIllumination-aware age progres-\nsion,\u201d in Proceedings of Computer Vision and Pattern\nRecognition, Columbus, USA, 2014.\n[7] Jinli Suo, Song-Chun Zhu, Shiguang Shan, and Xilin\nChen, \u201cA compositional and dynamic model for face\naging,\u201d IEEE Transactions on Pattern Analysis and Ma-\nchine Intelligence, vol. 32, no. 3, pp. 385\u2013401, 2010.\n[8] Yusuke Tazoe, Hiroaki Gohara, Akinobu Maejima, and\nShigeo Morishima, \u201cFacial aging simulator consider-\ning geometry and patch-tiled texture,\u201d inProceedings of\nACM SIGGRAPH, Los Angeles, USA, 2012.\n[9] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,\nBing Xu, David Warde-Farley, Sherjil Ozair, Aaron\nCourville, and Yoshua Bengio, \u201cGenerative adversarial\nnets,\u201d inProceedings of advances in Neural Information\nProcessing Systems, Montreal, Canada, 2015.\n[10] Diederik P Kingma and Max Welling, \u201cAuto-encoding\nvariational bayes,\u201d inProceedings of International Con-\nference on Learning Representations , Banff, Canada,\n2014.\n[11] Anders Boesen Lindbo Larsen, S\u00f8ren Kaae S\u00f8nderby,\nHugo Larochelle, and Ole Winther, \u201cAutoencoding\nbeyond pixels using a learned similarity metric,\u201d in\nProceedings of International Conference on Machine\nLearning, New York, USA, 2016.\n[12] Guim Perarnau, Joost van de Weijer, Bogdan Raducanu,\nand Jose M \u00b4Alvarez, \u201cInvertible conditional gans for\nimage editing,\u201d in Proceedings of advances in Neural\nInformation Processing Systems Workshops, Barcelona,\nSpain, 2016.\n[13] Mehdi Mirza and Simon Osindero, \u201cConditional gen-\nerative adversarial nets,\u201d in Proceedings of advances\nin Neural Information Processing Systems , Montreal,\nCanada, 2014.\n[14] Jon Gauthier, \u201cConditional generative adversarial nets\nfor convolutional face generation,\u201d Class Project for\nStanford CS231N: Convolutional Neural Networks for\nVisual Recognition, 2014.\n[15] Alec Radford, Luke Metz, and Soumith Chintala, \u201cUn-\nsupervised representation learning with deep convolu-\ntional generative adversarial networks,\u201d in Proceedings\nof International Conference on Learning Representa-\ntions, San Juan, Puerto Rico, 2016.\n[16] Diederik Kingma and Jimmy Ba, \u201cAdam: A\nmethod for stochastic optimization,\u201d arXiv preprint\narXiv:1412.6980, 2014.\n[17] Jun-Yan Zhu, Philipp Kr \u00a8ahenb\u00a8uhl, Eli Shechtman, and\nAlexei A Efros, \u201cGenerative visual manipulation on the\nnatural image manifold,\u201d in Proceedings of European\nConference on Computer Vision , Amsterdam, Nether-\nlands, 2016.\n[18] Florian Schroff, Dmitry Kalenichenko, and James\nPhilbin, \u201cFacenet: A uni\ufb01ed embedding for face recog-\nnition and clustering,\u201d in Proceedings of Computer Vi-\nsion and Pattern Recognition, Boston, USA, 2015.\n[19] Richard H Byrd, Peihuang Lu, Jorge Nocedal, and\nCiyou Zhu, \u201cA limited memory algorithm for bound\nconstrained optimization,\u201d SIAM Journal on Scienti\ufb01c\nComputing, vol. 16, no. 5, pp. 1190\u20131208, 1995.\n[20] Grigory Antipov, Moez Baccouche, Sid-Ahmed\nBerrani, and Jean-Luc Dugelay, \u201cApparent age es-\ntimation from face images combining general and\nchildren-specialized deep learning models,\u201d in Pro-\nceedings of Computer Vision and Pattern Recognition\nWorkshops, Las Vegas, USA, 2016.\n[21] Rasmus Rothe, Radu Timofte, and Luc Van Gool, \u201cDex:\nDeep expectation of apparent age from a single image,\u201d\nin Proceedings of International Conference on Com-\nputer Vision Workshops, Santiago, Chile, 2015.\n[22] Brandon Amos, Bartosz Ludwiczuk, and Mahadev\nSatyanarayanan, \u201cOpenface: A general-purpose face\nrecognition library with mobile applications,\u201d Tech.\nRep., CMU-CS-16-118, CMU School of Computer Sci-\nence, 2016.",
  "full_text_length": 22539,
  "link_pdf": "https://arxiv.org/pdf/1702.01983v2",
  "paper_id": "1702.01983v2"
}